{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrainement sur  cpu\n",
      "Nombre de chansons anglaises traitées: ALink       3\n",
      "SName       3\n",
      "SLink       3\n",
      "Lyric       3\n",
      "language    3\n",
      "dtype: int64\n",
      "-------- > epoch 0 lot 0 :  coût = 5.3679986000061035\n",
      "Temps écoulé : 0m 0s\n",
      "-------- > epoch 1 lot 0 :  coût = 5.044381141662598\n",
      "Temps écoulé : 0m 0s\n",
      "-------- > epoch 2 lot 0 :  coût = 4.843021869659424\n",
      "Temps écoulé : 0m 0s\n",
      "-------- > epoch 3 lot 0 :  coût = 4.542413234710693\n",
      "Temps écoulé : 0m 1s\n",
      "-------- > epoch 4 lot 0 :  coût = 4.203429222106934\n",
      "Temps écoulé : 0m 1s\n",
      "Texte stochastique 1 : ['we', 'could', 'lived', 'now', 'na', 'and', 'gonna', 'tonight', 'easy', 'know', 'i', 'let', 'music', 'just', 'no', 'pretend', 'not', 'got', 'have', 'other', 'want', 'got']\n",
      "Texte stochastique 2 : ['we', 'could', 'this', 'to', 'good', 'than', 'rhythm', 'be', 'let', 'change', 'please', 'with', 'together', 'that', 'rhythm', 'could', 'you', 'be', 'loved', 'and', 'all', 'be']\n",
      "Texte stochastique 3 : ['we', 'could', 'of', 'take', 'let', 'only', 'you', 'pretend', 'live', 'not', 'its', 'oh', 'something', 'away', 'ayin', 'here', 'hurt', 'now', 'what', 'youre', 'though', 'se']\n",
      "Texte max : ['we', 'could', 'you', 'be', 'loved', 'and', 'you', 'be', 'loved', 'and', 'you', 'be', 'loved', 'and', 'you', 'be', 'loved', 'and', 'you', 'be', 'loved', 'and']\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Réseau de neurones récurrent, modèle de langue par mot, pour paroles de chansons\n",
    "Fichier lyrics-data.csv de https://www.kaggle.com/datasets/deepshah16/song-lyrics-dataset\n",
    "Version avec couche vectorisation de mots et RNN\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(0) # Pour résultats reproductibles\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "taille_sequence = 8\n",
    "nombre_textes = 100\n",
    "\n",
    "# Déterminer si un GPU est disponible\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Entrainement sur ',device)\n",
    "\n",
    "class DatasetParolesLyricsDataEn(torch.utils.data.Dataset):\n",
    "    \"\"\" Créer un Dataset avec les paroles de la colonne Lyric du fichier nom_fichier\n",
    "    taille_sequence : taille d'une séquence de mots pour le modèle de langue\n",
    "    Le texte est découpé en séquences de la taille taille_sequence\n",
    "    \"\"\"\n",
    "    def __init__(self, nombre_textes=100, taille_sequence=4,):\n",
    "        self.nombre_textes = nombre_textes\n",
    "        self.taille_sequence = taille_sequence\n",
    "        self.mots = self.charger_mots()\n",
    "        self.mots_uniques = self.chercher_mots_uniques()\n",
    "\n",
    "        self.index_a_mot = {index: mot for index, mot in enumerate(self.mots_uniques)}\n",
    "        self.mot_a_index = {mot: index for index, mot in enumerate(self.mots_uniques)}\n",
    "\n",
    "        self.mots_indexes = [self.mot_a_index[w] for w in self.mots]\n",
    "\n",
    "    def charger_mots(self):\n",
    "        dataframe_entrainement = pd.read_csv('lyrics-data.csv',nrows=self.nombre_textes)\n",
    "        textes_anglais = dataframe_entrainement[(dataframe_entrainement['language'] == 'en')]\n",
    "        print(\"Nombre de chansons anglaises traitées:\", textes_anglais.count())\n",
    "        texte_concatene = dataframe_entrainement[(dataframe_entrainement['language'] == 'en')].iloc[0:self.nombre_textes]['Lyric'].str.cat(sep=' ')\n",
    "        return re.sub(r'[^\\w\\s]', '', texte_concatene).lower().split()\n",
    "\n",
    "    def chercher_mots_uniques(self):\n",
    "        frequence_mot = Counter(self.mots)\n",
    "        return sorted(frequence_mot, key=frequence_mot.get, reverse=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mots_indexes) - self.taille_sequence\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            torch.tensor(self.mots_indexes[index:index+self.taille_sequence]),\n",
    "            torch.tensor(self.mots_indexes[index+1:index+self.taille_sequence+1]),\n",
    "        )\n",
    "    \n",
    "class Modele(nn.Module):\n",
    "    \"\"\"Modèle de RNR avec une couche vectorisation, suivie d'une couche RNN et d'une couche linéaire\"\"\"\n",
    "    def __init__(self, ds_paroles):\n",
    "        super(Modele, self).__init__()\n",
    "        self.taille_H_RNN = 128\n",
    "        self.taille_vectorisation_mots = 64\n",
    "        self.nombre_couches_RNR = 1\n",
    "\n",
    "        taille_vocabulaire = len(ds_paroles.mots_uniques)\n",
    "        self.vectorisation_mots = nn.Embedding(num_embeddings=taille_vocabulaire,\n",
    "            embedding_dim=self.taille_vectorisation_mots)\n",
    "        self.rnn = nn.GRU(input_size=self.taille_vectorisation_mots,hidden_size=self.taille_H_RNN,\n",
    "            num_layers=self.nombre_couches_RNR,batch_first=True)\n",
    "        self.dense_linaire = nn.Linear(self.taille_H_RNN, taille_vocabulaire)\n",
    "\n",
    "    def forward(self, lot_X, etat_0):\n",
    "        vectorisation = self.vectorisation_mots(lot_X)\n",
    "        lot_Ht, etat = self.rnn(vectorisation, etat_0)\n",
    "        lot_Yt = self.dense_linaire(lot_Ht)\n",
    "        return lot_Yt, etat\n",
    "\n",
    "    def initializer_etat(self, taille_sequence):\n",
    "        return (torch.zeros(self.nombre_couches_RNR, taille_sequence, self.taille_H_RNN))\n",
    "\n",
    "ds_paroles = DatasetParolesLyricsDataEn(nombre_textes = nombre_textes, taille_sequence=taille_sequence)\n",
    "modele = Modele(ds_paroles)\n",
    "# Placer le modèle en mode GPU si possible\n",
    "modele = modele.to(device)\n",
    "    \n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "def entrainer_RNR(ds_paroles, modele, taille_lot=32, epochs=5, taille_sequence=6):\n",
    "    debut = time.time()\n",
    "    modele.train()\n",
    "    dl_paroles = DataLoader(ds_paroles,batch_size=taille_lot)\n",
    "\n",
    "    fonction_cout = nn.CrossEntropyLoss()\n",
    "    optimizeur = optim.Adam(modele.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        for lot, (lot_X, lot_Y) in enumerate(dl_paroles):\n",
    "            lot_X = lot_X.to(device)\n",
    "            lot_Y = lot_Y.to(device)\n",
    "            etat = modele.initializer_etat(lot_X.shape[0])\n",
    "            etat = etat.to(device)\n",
    "            optimizeur.zero_grad()\n",
    "            \n",
    "            lot_Y_predictions, etat = modele(lot_X, etat)\n",
    "            cout = fonction_cout(lot_Y_predictions.transpose(1, 2), lot_Y)\n",
    "            \n",
    "            cout.backward()\n",
    "            optimizeur.step()\n",
    "            if lot%100 == 0:\n",
    "                print(f'-------- > epoch {epoch} lot {lot} :  coût = {cout.item()}')\n",
    "                temps_ecoule = time.time() - debut\n",
    "                print('Temps écoulé : {:.0f}m {:.0f}s'.format(temps_ecoule // 60, temps_ecoule % 60))\n",
    "\n",
    "\n",
    "def predire(ds, modele, debut_texte, nb_mots=20, mode =0):\n",
    "    \"\"\" Prédire une suite de nb_mots à partir de debut_texte selon le modele\"\"\"\n",
    "\n",
    "    mots = debut_texte.split(' ')\n",
    "    modele.eval()\n",
    "    etat = modele.initializer_etat(1)\n",
    "    etat = etat.to(device)\n",
    "    for i in range(0, nb_mots):\n",
    "        lot_X = torch.tensor([[ds.mot_a_index[m] for m in mots[i:]]])\n",
    "        lot_X = lot_X.to(device)\n",
    "        lot_Y_predictions, etat = modele(lot_X, etat)\n",
    "        dernier_mot_Yt = lot_Y_predictions[0][-1]\n",
    "        probs_dernier_mot = torch.nn.functional.softmax(dernier_mot_Yt, dim=0).data\n",
    "        if mode == 0 :\n",
    "            index_mot_choisi = torch.max(probs_dernier_mot, dim=0)[1].item()\n",
    "        else :\n",
    "            index_mot_choisi = torch.multinomial(probs_dernier_mot, 1)[0].item()\n",
    "        mots.append(ds.index_a_mot[index_mot_choisi])\n",
    "    return mots\n",
    "\n",
    "entrainer_RNR(ds_paroles, modele, taille_lot=32, epochs=5, taille_sequence=taille_sequence)\n",
    "print(\"Texte stochastique 1 :\",predire(ds_paroles, modele, debut_texte='we could', mode = 1))\n",
    "print(\"Texte stochastique 2 :\",predire(ds_paroles, modele, debut_texte='we could', mode = 1))\n",
    "print(\"Texte stochastique 3 :\",predire(ds_paroles, modele, debut_texte='we could', mode = 1))\n",
    "print(\"Texte max :\",predire(ds_paroles, modele, debut_texte='we could', mode = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   ALink     100 non-null    object\n",
      " 1   SName     100 non-null    object\n",
      " 2   SLink     100 non-null    object\n",
      " 3   Lyric     100 non-null    object\n",
      " 4   language  100 non-null    object\n",
      "dtypes: object(5)\n",
      "memory usage: 4.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataframe_entrainement = pd.read_csv('lyrics-data.csv',nrows=100)\n",
    "print(dataframe_entrainement.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALink</th>\n",
       "      <th>SName</th>\n",
       "      <th>SLink</th>\n",
       "      <th>Lyric</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Careless Whisper</td>\n",
       "      <td>/ivete-sangalo/careless-whisper.html</td>\n",
       "      <td>I feel so unsure\\nAs I take your hand and lead...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Could You Be Loved / Citação Musical do Rap: S...</td>\n",
       "      <td>/ivete-sangalo/could-you-be-loved-citacao-musi...</td>\n",
       "      <td>Don't let them fool, ya\\nOr even try to school...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Cruisin' (Part. Saulo)</td>\n",
       "      <td>/ivete-sangalo/cruisin-part-saulo.html</td>\n",
       "      <td>Baby, let's cruise, away from here\\nDon't be c...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ALink                                              SName  \\\n",
       "69  /ivete-sangalo/                                   Careless Whisper   \n",
       "86  /ivete-sangalo/  Could You Be Loved / Citação Musical do Rap: S...   \n",
       "88  /ivete-sangalo/                             Cruisin' (Part. Saulo)   \n",
       "\n",
       "                                                SLink  \\\n",
       "69               /ivete-sangalo/careless-whisper.html   \n",
       "86  /ivete-sangalo/could-you-be-loved-citacao-musi...   \n",
       "88             /ivete-sangalo/cruisin-part-saulo.html   \n",
       "\n",
       "                                                Lyric language  \n",
       "69  I feel so unsure\\nAs I take your hand and lead...       en  \n",
       "86  Don't let them fool, ya\\nOr even try to school...       en  \n",
       "88  Baby, let's cruise, away from here\\nDon't be c...       en  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_entrainement[(dataframe_entrainement['language'] == 'en')].iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I feel so unsure\n",
      "As I take your hand and lead you to the dance floor\n",
      "As the music dies, something in your eyes\n",
      "Calls to mind a silver screen\n",
      "And all those sad goodbyes\n",
      "\n",
      "I'm never gonna dance again\n",
      "Guilty feet have got no rhythm\n",
      "Though it's easy to pretend\n",
      "I know you're not a fool\n",
      "\n",
      "Should've known better than to cheat a friend\n",
      "And waste the chance that I've been given\n",
      "So I'm never gonna dance again\n",
      "The way I danced with you\n",
      "\n",
      "Time can never mend\n",
      "The careless whispers of a good friend\n",
      "To the heart and mind\n",
      "Ignorance is kind\n",
      "There's no comfort in the truth\n",
      "Pain is all you'll find\n",
      "\n",
      "I'm never gonna dance again\n",
      "Guilty feet have got no rhythm\n",
      "Though it's easy to pretend\n",
      "I know you're not a fool\n",
      "\n",
      "Should've known better than to cheat a friend\n",
      "And waste this chance that I've been given\n",
      "So I'm never gonna dance again\n",
      "The way I danced with you\n",
      "\n",
      "Never without your love\n",
      "\n",
      "Tonight the music seems so loud\n",
      "I wish that we could lose this crowd\n",
      "Maybe it's better this way\n",
      "We'd hurt each other with the things we'd want to say\n",
      "\n",
      "We could have been so good together\n",
      "We could have lived this dance forever\n",
      "But now who's gonna dance with me?\n",
      "Please stay\n",
      "\n",
      "And I'm never gonna dance again\n",
      "Guilty feet have got no rhythm\n",
      "Though it's easy to pretend\n",
      "I know you're not a fool\n",
      "\n",
      "Should've known better than to cheat a friend\n",
      "And waste the chance that I've been given\n",
      "So I'm never gonna dance again\n",
      "The way I danced with you\n",
      "\n",
      "(Now that you're gone) Now that you're gone\n",
      "(Now that you're gone) What I did's so wrong, so wrong\n",
      "That you had to leave me alone? Don't let them fool, ya\n",
      "Or even try to school, ya! Oh, no!\n",
      "We've got a mind of our own\n",
      "So go to hell if what you? re thinking is not right!\n",
      "Love would never leave us alone\n",
      "A-yin the darkness there must come out to light\n",
      "\n",
      "Could you be loved and be loved?\n",
      "Could you be loved and be loved?\n",
      "\n",
      "Don't let them change ya, oh!\n",
      "Or even rearrange ya! Oh, no!\n",
      "We've got a life to live\n",
      "They say: only, only\n",
      "Only the fittest of the fittest shall survive\n",
      "Stay alive! Oh!\n",
      "\n",
      "Could you be loved and be loved?\n",
      "Could you be loved, wo now! And be loved?\n",
      "\n",
      "Could you be\n",
      "Could you be\n",
      "Could you be loved?\n",
      "\n",
      "Say something!\n",
      "\n",
      "Se ligue na ternura\n",
      "Se ligue no amor\n",
      "Se ligue na ternura\n",
      "Se ligue na cor\n",
      "Se ligue na alegria\n",
      "Se ligue no prazer\n",
      "Se ligue, fique atento, se ligue, fique astral\n",
      "\n",
      "Could you be loved and be loved?\n"
     ]
    }
   ],
   "source": [
    "texte_concatene = dataframe_entrainement[(dataframe_entrainement['language'] == 'en')].iloc[0:2]['Lyric'].str.cat(sep=' ')\n",
    "print(texte_concatene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I feel so unsure\n",
      "As I take your hand and lead you to the dance floor\n",
      "As the music dies something in your eyes\n",
      "Calls to mind a silver screen\n",
      "And all those sad goodbyes\n",
      "\n",
      "Im never gonna dance again\n",
      "Guilty feet have got no rhythm\n",
      "Though its easy to pretend\n",
      "I know youre not a fool\n",
      "\n",
      "Shouldve known better than to cheat a friend\n",
      "And waste the chance that Ive been given\n",
      "So Im never gonna dance again\n",
      "The way I danced with you\n",
      "\n",
      "Time can never mend\n",
      "The careless whispers of a good friend\n",
      "To the heart and mind\n",
      "Ignorance is kind\n",
      "Theres no comfort in the truth\n",
      "Pain is all youll find\n",
      "\n",
      "Im never gonna dance again\n",
      "Guilty feet have got no rhythm\n",
      "Though its easy to pretend\n",
      "I know youre not a fool\n",
      "\n",
      "Shouldve known better than to cheat a friend\n",
      "And waste this chance that Ive been given\n",
      "So Im never gonna dance again\n",
      "The way I danced with you\n",
      "\n",
      "Never without your love\n",
      "\n",
      "Tonight the music seems so loud\n",
      "I wish that we could lose this crowd\n",
      "Maybe its better this way\n",
      "Wed hurt each other with the things wed want to say\n",
      "\n",
      "We could have been so good together\n",
      "We could have lived this dance forever\n",
      "But now whos gonna dance with me\n",
      "Please stay\n",
      "\n",
      "And Im never gonna dance again\n",
      "Guilty feet have got no rhythm\n",
      "Though its easy to pretend\n",
      "I know youre not a fool\n",
      "\n",
      "Shouldve known better than to cheat a friend\n",
      "And waste the chance that Ive been given\n",
      "So Im never gonna dance again\n",
      "The way I danced with you\n",
      "\n",
      "Now that youre gone Now that youre gone\n",
      "Now that youre gone What I dids so wrong so wrong\n",
      "That you had to leave me alone Dont let them fool ya\n",
      "Or even try to school ya Oh no\n",
      "Weve got a mind of our own\n",
      "So go to hell if what you re thinking is not right\n",
      "Love would never leave us alone\n",
      "Ayin the darkness there must come out to light\n",
      "\n",
      "Could you be loved and be loved\n",
      "Could you be loved and be loved\n",
      "\n",
      "Dont let them change ya oh\n",
      "Or even rearrange ya Oh no\n",
      "Weve got a life to live\n",
      "They say only only\n",
      "Only the fittest of the fittest shall survive\n",
      "Stay alive Oh\n",
      "\n",
      "Could you be loved and be loved\n",
      "Could you be loved wo now And be loved\n",
      "\n",
      "Could you be\n",
      "Could you be\n",
      "Could you be loved\n",
      "\n",
      "Say something\n",
      "\n",
      "Se ligue na ternura\n",
      "Se ligue no amor\n",
      "Se ligue na ternura\n",
      "Se ligue na cor\n",
      "Se ligue na alegria\n",
      "Se ligue no prazer\n",
      "Se ligue fique atento se ligue fique astral\n",
      "\n",
      "Could you be loved and be loved\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "texte_concatene=re.sub(r'[^\\w\\s]', '', texte_concatene)\n",
    "print(texte_concatene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'feel', 'so', 'unsure', 'as', 'i', 'take', 'your', 'hand', 'and', 'lead', 'you', 'to', 'the', 'dance', 'floor', 'as', 'the', 'music', 'dies', 'something', 'in', 'your', 'eyes', 'calls', 'to', 'mind', 'a', 'silver', 'screen', 'and', 'all', 'those', 'sad', 'goodbyes', 'im', 'never', 'gonna', 'dance', 'again', 'guilty', 'feet', 'have', 'got', 'no', 'rhythm', 'though', 'its', 'easy', 'to', 'pretend', 'i', 'know', 'youre', 'not', 'a', 'fool', 'shouldve', 'known', 'better', 'than', 'to', 'cheat', 'a', 'friend', 'and', 'waste', 'the', 'chance', 'that', 'ive', 'been', 'given', 'so', 'im', 'never', 'gonna', 'dance', 'again', 'the', 'way', 'i', 'danced', 'with', 'you', 'time', 'can', 'never', 'mend', 'the', 'careless', 'whispers', 'of', 'a', 'good', 'friend', 'to', 'the', 'heart', 'and', 'mind', 'ignorance', 'is', 'kind', 'theres', 'no', 'comfort', 'in', 'the', 'truth', 'pain', 'is', 'all', 'youll', 'find', 'im', 'never', 'gonna', 'dance', 'again', 'guilty', 'feet', 'have', 'got', 'no', 'rhythm', 'though', 'its', 'easy', 'to', 'pretend', 'i', 'know', 'youre', 'not', 'a', 'fool', 'shouldve', 'known', 'better', 'than', 'to', 'cheat', 'a', 'friend', 'and', 'waste', 'this', 'chance', 'that', 'ive', 'been', 'given', 'so', 'im', 'never', 'gonna', 'dance', 'again', 'the', 'way', 'i', 'danced', 'with', 'you', 'never', 'without', 'your', 'love', 'tonight', 'the', 'music', 'seems', 'so', 'loud', 'i', 'wish', 'that', 'we', 'could', 'lose', 'this', 'crowd', 'maybe', 'its', 'better', 'this', 'way', 'wed', 'hurt', 'each', 'other', 'with', 'the', 'things', 'wed', 'want', 'to', 'say', 'we', 'could', 'have', 'been', 'so', 'good', 'together', 'we', 'could', 'have', 'lived', 'this', 'dance', 'forever', 'but', 'now', 'whos', 'gonna', 'dance', 'with', 'me', 'please', 'stay', 'and', 'im', 'never', 'gonna', 'dance', 'again', 'guilty', 'feet', 'have', 'got', 'no', 'rhythm', 'though', 'its', 'easy', 'to', 'pretend', 'i', 'know', 'youre', 'not', 'a', 'fool', 'shouldve', 'known', 'better', 'than', 'to', 'cheat', 'a', 'friend', 'and', 'waste', 'the', 'chance', 'that', 'ive', 'been', 'given', 'so', 'im', 'never', 'gonna', 'dance', 'again', 'the', 'way', 'i', 'danced', 'with', 'you', 'now', 'that', 'youre', 'gone', 'now', 'that', 'youre', 'gone', 'now', 'that', 'youre', 'gone', 'what', 'i', 'dids', 'so', 'wrong', 'so', 'wrong', 'that', 'you', 'had', 'to', 'leave', 'me', 'alone', 'dont', 'let', 'them', 'fool', 'ya', 'or', 'even', 'try', 'to', 'school', 'ya', 'oh', 'no', 'weve', 'got', 'a', 'mind', 'of', 'our', 'own', 'so', 'go', 'to', 'hell', 'if', 'what', 'you', 're', 'thinking', 'is', 'not', 'right', 'love', 'would', 'never', 'leave', 'us', 'alone', 'ayin', 'the', 'darkness', 'there', 'must', 'come', 'out', 'to', 'light', 'could', 'you', 'be', 'loved', 'and', 'be', 'loved', 'could', 'you', 'be', 'loved', 'and', 'be', 'loved', 'dont', 'let', 'them', 'change', 'ya', 'oh', 'or', 'even', 'rearrange', 'ya', 'oh', 'no', 'weve', 'got', 'a', 'life', 'to', 'live', 'they', 'say', 'only', 'only', 'only', 'the', 'fittest', 'of', 'the', 'fittest', 'shall', 'survive', 'stay', 'alive', 'oh', 'could', 'you', 'be', 'loved', 'and', 'be', 'loved', 'could', 'you', 'be', 'loved', 'wo', 'now', 'and', 'be', 'loved', 'could', 'you', 'be', 'could', 'you', 'be', 'could', 'you', 'be', 'loved', 'say', 'something', 'se', 'ligue', 'na', 'ternura', 'se', 'ligue', 'no', 'amor', 'se', 'ligue', 'na', 'ternura', 'se', 'ligue', 'na', 'cor', 'se', 'ligue', 'na', 'alegria', 'se', 'ligue', 'no', 'prazer', 'se', 'ligue', 'fique', 'atento', 'se', 'ligue', 'fique', 'astral', 'could', 'you', 'be', 'loved', 'and', 'be', 'loved']\n"
     ]
    }
   ],
   "source": [
    "print(texte_concatene.lower().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'feel',\n",
       " 'so',\n",
       " 'unsure',\n",
       " 'as',\n",
       " 'i',\n",
       " 'take',\n",
       " 'your',\n",
       " 'hand',\n",
       " 'and',\n",
       " 'lead',\n",
       " 'you',\n",
       " 'to',\n",
       " 'the',\n",
       " 'dance',\n",
       " 'floor',\n",
       " 'as',\n",
       " 'the',\n",
       " 'music',\n",
       " 'dies',\n",
       " 'something',\n",
       " 'in',\n",
       " 'your',\n",
       " 'eyes',\n",
       " 'calls',\n",
       " 'to',\n",
       " 'mind',\n",
       " 'a',\n",
       " 'silver',\n",
       " 'screen',\n",
       " 'and',\n",
       " 'all',\n",
       " 'those',\n",
       " 'sad',\n",
       " 'goodbyes',\n",
       " 'im',\n",
       " 'never',\n",
       " 'gonna',\n",
       " 'dance',\n",
       " 'again',\n",
       " 'guilty',\n",
       " 'feet',\n",
       " 'have',\n",
       " 'got',\n",
       " 'no',\n",
       " 'rhythm',\n",
       " 'though',\n",
       " 'its',\n",
       " 'easy',\n",
       " 'to',\n",
       " 'pretend',\n",
       " 'i',\n",
       " 'know',\n",
       " 'youre',\n",
       " 'not',\n",
       " 'a',\n",
       " 'fool',\n",
       " 'shouldve',\n",
       " 'known',\n",
       " 'better',\n",
       " 'than',\n",
       " 'to',\n",
       " 'cheat',\n",
       " 'a',\n",
       " 'friend',\n",
       " 'and',\n",
       " 'waste',\n",
       " 'the',\n",
       " 'chance',\n",
       " 'that',\n",
       " 'ive',\n",
       " 'been',\n",
       " 'given',\n",
       " 'so',\n",
       " 'im',\n",
       " 'never',\n",
       " 'gonna',\n",
       " 'dance',\n",
       " 'again',\n",
       " 'the',\n",
       " 'way',\n",
       " 'i',\n",
       " 'danced',\n",
       " 'with',\n",
       " 'you',\n",
       " 'time',\n",
       " 'can',\n",
       " 'never',\n",
       " 'mend',\n",
       " 'the',\n",
       " 'careless',\n",
       " 'whispers',\n",
       " 'of',\n",
       " 'a',\n",
       " 'good',\n",
       " 'friend',\n",
       " 'to',\n",
       " 'the',\n",
       " 'heart',\n",
       " 'and',\n",
       " 'mind',\n",
       " 'ignorance',\n",
       " 'is',\n",
       " 'kind',\n",
       " 'theres',\n",
       " 'no',\n",
       " 'comfort',\n",
       " 'in',\n",
       " 'the',\n",
       " 'truth',\n",
       " 'pain',\n",
       " 'is',\n",
       " 'all',\n",
       " 'youll',\n",
       " 'find',\n",
       " 'im',\n",
       " 'never',\n",
       " 'gonna',\n",
       " 'dance',\n",
       " 'again',\n",
       " 'guilty',\n",
       " 'feet',\n",
       " 'have',\n",
       " 'got',\n",
       " 'no',\n",
       " 'rhythm',\n",
       " 'though',\n",
       " 'its',\n",
       " 'easy',\n",
       " 'to',\n",
       " 'pretend',\n",
       " 'i',\n",
       " 'know',\n",
       " 'youre',\n",
       " 'not',\n",
       " 'a',\n",
       " 'fool',\n",
       " 'shouldve',\n",
       " 'known',\n",
       " 'better',\n",
       " 'than',\n",
       " 'to',\n",
       " 'cheat',\n",
       " 'a',\n",
       " 'friend',\n",
       " 'and',\n",
       " 'waste',\n",
       " 'this',\n",
       " 'chance',\n",
       " 'that',\n",
       " 'ive',\n",
       " 'been',\n",
       " 'given',\n",
       " 'so',\n",
       " 'im',\n",
       " 'never',\n",
       " 'gonna',\n",
       " 'dance',\n",
       " 'again',\n",
       " 'the',\n",
       " 'way',\n",
       " 'i',\n",
       " 'danced',\n",
       " 'with',\n",
       " 'you',\n",
       " 'never',\n",
       " 'without',\n",
       " 'your',\n",
       " 'love',\n",
       " 'tonight',\n",
       " 'the',\n",
       " 'music',\n",
       " 'seems',\n",
       " 'so',\n",
       " 'loud',\n",
       " 'i',\n",
       " 'wish',\n",
       " 'that',\n",
       " 'we',\n",
       " 'could',\n",
       " 'lose',\n",
       " 'this',\n",
       " 'crowd',\n",
       " 'maybe',\n",
       " 'its',\n",
       " 'better',\n",
       " 'this',\n",
       " 'way',\n",
       " 'wed',\n",
       " 'hurt',\n",
       " 'each',\n",
       " 'other',\n",
       " 'with',\n",
       " 'the',\n",
       " 'things',\n",
       " 'wed',\n",
       " 'want',\n",
       " 'to',\n",
       " 'say',\n",
       " 'we',\n",
       " 'could',\n",
       " 'have',\n",
       " 'been',\n",
       " 'so',\n",
       " 'good',\n",
       " 'together',\n",
       " 'we',\n",
       " 'could',\n",
       " 'have',\n",
       " 'lived',\n",
       " 'this',\n",
       " 'dance',\n",
       " 'forever',\n",
       " 'but',\n",
       " 'now',\n",
       " 'whos',\n",
       " 'gonna',\n",
       " 'dance',\n",
       " 'with',\n",
       " 'me',\n",
       " 'please',\n",
       " 'stay',\n",
       " 'and',\n",
       " 'im',\n",
       " 'never',\n",
       " 'gonna',\n",
       " 'dance',\n",
       " 'again',\n",
       " 'guilty',\n",
       " 'feet',\n",
       " 'have',\n",
       " 'got',\n",
       " 'no',\n",
       " 'rhythm',\n",
       " 'though',\n",
       " 'its',\n",
       " 'easy',\n",
       " 'to',\n",
       " 'pretend',\n",
       " 'i',\n",
       " 'know',\n",
       " 'youre',\n",
       " 'not',\n",
       " 'a',\n",
       " 'fool',\n",
       " 'shouldve',\n",
       " 'known',\n",
       " 'better',\n",
       " 'than',\n",
       " 'to',\n",
       " 'cheat',\n",
       " 'a',\n",
       " 'friend',\n",
       " 'and',\n",
       " 'waste',\n",
       " 'the',\n",
       " 'chance',\n",
       " 'that',\n",
       " 'ive',\n",
       " 'been',\n",
       " 'given',\n",
       " 'so',\n",
       " 'im',\n",
       " 'never',\n",
       " 'gonna',\n",
       " 'dance',\n",
       " 'again',\n",
       " 'the',\n",
       " 'way',\n",
       " 'i',\n",
       " 'danced',\n",
       " 'with',\n",
       " 'you',\n",
       " 'now',\n",
       " 'that',\n",
       " 'youre',\n",
       " 'gone',\n",
       " 'now',\n",
       " 'that',\n",
       " 'youre',\n",
       " 'gone',\n",
       " 'now',\n",
       " 'that',\n",
       " 'youre',\n",
       " 'gone',\n",
       " 'what',\n",
       " 'i',\n",
       " 'dids',\n",
       " 'so',\n",
       " 'wrong',\n",
       " 'so',\n",
       " 'wrong',\n",
       " 'that',\n",
       " 'you',\n",
       " 'had',\n",
       " 'to',\n",
       " 'leave',\n",
       " 'me',\n",
       " 'alone',\n",
       " 'dont',\n",
       " 'let',\n",
       " 'them',\n",
       " 'fool',\n",
       " 'ya',\n",
       " 'or',\n",
       " 'even',\n",
       " 'try',\n",
       " 'to',\n",
       " 'school',\n",
       " 'ya',\n",
       " 'oh',\n",
       " 'no',\n",
       " 'weve',\n",
       " 'got',\n",
       " 'a',\n",
       " 'mind',\n",
       " 'of',\n",
       " 'our',\n",
       " 'own',\n",
       " 'so',\n",
       " 'go',\n",
       " 'to',\n",
       " 'hell',\n",
       " 'if',\n",
       " 'what',\n",
       " 'you',\n",
       " 're',\n",
       " 'thinking',\n",
       " 'is',\n",
       " 'not',\n",
       " 'right',\n",
       " 'love',\n",
       " 'would',\n",
       " 'never',\n",
       " 'leave',\n",
       " 'us',\n",
       " 'alone',\n",
       " 'ayin',\n",
       " 'the',\n",
       " 'darkness',\n",
       " 'there',\n",
       " 'must',\n",
       " 'come',\n",
       " 'out',\n",
       " 'to',\n",
       " 'light',\n",
       " 'could',\n",
       " 'you',\n",
       " 'be',\n",
       " 'loved',\n",
       " 'and',\n",
       " 'be',\n",
       " 'loved',\n",
       " 'could',\n",
       " 'you',\n",
       " 'be',\n",
       " 'loved',\n",
       " 'and',\n",
       " 'be',\n",
       " 'loved',\n",
       " 'dont',\n",
       " 'let',\n",
       " 'them',\n",
       " 'change',\n",
       " 'ya',\n",
       " 'oh',\n",
       " 'or',\n",
       " 'even',\n",
       " 'rearrange',\n",
       " 'ya',\n",
       " 'oh',\n",
       " 'no',\n",
       " 'weve',\n",
       " 'got',\n",
       " 'a',\n",
       " 'life',\n",
       " 'to',\n",
       " 'live',\n",
       " 'they',\n",
       " 'say',\n",
       " 'only',\n",
       " 'only',\n",
       " 'only',\n",
       " 'the',\n",
       " 'fittest',\n",
       " 'of',\n",
       " 'the',\n",
       " 'fittest',\n",
       " 'shall',\n",
       " 'survive',\n",
       " 'stay',\n",
       " 'alive',\n",
       " 'oh',\n",
       " 'could',\n",
       " 'you',\n",
       " 'be',\n",
       " 'loved',\n",
       " 'and',\n",
       " 'be',\n",
       " 'loved',\n",
       " 'could',\n",
       " 'you',\n",
       " 'be',\n",
       " 'loved',\n",
       " 'wo',\n",
       " 'now',\n",
       " 'and',\n",
       " 'be',\n",
       " 'loved',\n",
       " 'could',\n",
       " 'you',\n",
       " 'be',\n",
       " 'could',\n",
       " 'you',\n",
       " 'be',\n",
       " 'could',\n",
       " 'you',\n",
       " 'be',\n",
       " 'loved',\n",
       " 'say',\n",
       " 'something',\n",
       " 'se',\n",
       " 'ligue',\n",
       " 'na',\n",
       " 'ternura',\n",
       " 'se',\n",
       " 'ligue',\n",
       " 'no',\n",
       " 'amor',\n",
       " 'se',\n",
       " 'ligue',\n",
       " 'na',\n",
       " 'ternura',\n",
       " 'se',\n",
       " 'ligue',\n",
       " 'na',\n",
       " 'cor',\n",
       " 'se',\n",
       " 'ligue',\n",
       " 'na',\n",
       " 'alegria',\n",
       " 'se',\n",
       " 'ligue',\n",
       " 'no',\n",
       " 'prazer',\n",
       " 'se',\n",
       " 'ligue',\n",
       " 'fique',\n",
       " 'atento',\n",
       " 'se',\n",
       " 'ligue',\n",
       " 'fique',\n",
       " 'astral',\n",
       " 'could',\n",
       " 'you',\n",
       " 'be',\n",
       " 'loved',\n",
       " 'and',\n",
       " 'be',\n",
       " 'loved']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texte_concatene = dataframe_entrainement[(dataframe_entrainement['language'] == 'en')].iloc[0:2]['Lyric'].str.cat(sep=' ')\n",
    "re.sub(r'[^\\w\\s]', '', texte_concatene).lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de chansons anglaises traitées: ALink       3\n",
      "SName       3\n",
      "SLink       3\n",
      "Lyric       3\n",
      "language    3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "ds_paroles = DatasetParolesLyricsDataEn(nombre_textes = nombre_textes, taille_sequence=taille_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  3, 112,  10, 113,  76,   3,  51,  28]),\n",
       " tensor([112,  10, 113,  76,   3,  51,  28, 114]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_paroles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
