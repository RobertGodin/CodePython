{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- > epoch 1:  coût moyen entraînement = 2.305981159210205\n",
      "-------- > epoch 1:  taux moyen entraînement = 0.10650002956390381\n",
      "-------- > epoch 1:  coût moyen validation = 2.303502082824707\n",
      "-------- > epoch 1:  taux moyen validation = 0.10429999232292175\n",
      "-------- > epoch 2:  coût moyen entraînement = 2.303818941116333\n",
      "-------- > epoch 2:  taux moyen entraînement = 0.10708004236221313\n",
      "-------- > epoch 2:  coût moyen validation = 2.3016316890716553\n",
      "-------- > epoch 2:  taux moyen validation = 0.10940001159906387\n",
      "-------- > epoch 3:  coût moyen entraînement = 2.3042993545532227\n",
      "-------- > epoch 3:  taux moyen entraînement = 0.10724001377820969\n",
      "-------- > epoch 3:  coût moyen validation = 2.301755666732788\n",
      "-------- > epoch 3:  taux moyen validation = 0.10559998452663422\n",
      "-------- > epoch 4:  coût moyen entraînement = 2.3034722805023193\n",
      "-------- > epoch 4:  taux moyen entraînement = 0.1092400774359703\n",
      "-------- > epoch 4:  coût moyen validation = 2.305629014968872\n",
      "-------- > epoch 4:  taux moyen validation = 0.09549997001886368\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-92f55d87a403>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m \u001b[0mentrainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodele\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdl_ent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdl_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimiseur\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-92f55d87a403>\u001b[0m in \u001b[0;36mentrainer\u001b[1;34m(modele, dl_ent, dl_valid, optimiseur, nb_epochs)\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mlot_Y_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodele\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlot_X\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Appel de la méthode forward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[0mcout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfonction_cout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlot_Y_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlot_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m             \u001b[0mcout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Calcul des gradiants par rétropropagation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[0mcout_total_ent\u001b[0m \u001b[1;33m+=\u001b[0m\u001b[0mcout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \"\"\"\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Exemple d'architecture basée sur LeNet\n",
    "\"\"\"\n",
    "import torch\n",
    "torch.manual_seed(0) # Pour résultats reproductibles\n",
    "\n",
    "# Fonction J d'entropie croisée\n",
    "import torch.nn.functional as F\n",
    "fonction_cout = F.cross_entropy\n",
    "\n",
    "def taux_bonnes_predictions(lot_Y_predictions, lot_Y):\n",
    "    predictions_categorie = torch.argmax(lot_Y_predictions, dim=1)\n",
    "    return (predictions_categorie == lot_Y).float().mean()\n",
    "\n",
    "from torch import nn\n",
    "# Définition de l'architecture du RNA\n",
    "\n",
    "modele = torch.nn.Sequential(\n",
    "    nn.Conv2d(1, 6, kernel_size=5, padding=2), nn.Sigmoid(), #(N, 1, 28, 28) -> (N, 6, 28, 28)\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2), #(N, 6, 28, 28) -> (N, 6, 14, 14)\n",
    "    nn.Conv2d(6, 16, kernel_size=5), nn.Sigmoid(), #(N, 6, 14, 14) -> (N, 16, 10, 10)\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2), #(N, 16, 10, 10) -> (N, 16, 5, 5)\n",
    "    nn.Flatten(), #(N, 16, 5, 5) -> (N, 400)\n",
    "    nn.Linear(16 * 5 * 5, 120), nn.Sigmoid(), #(N, 400) -> (N, 120)\n",
    "    nn.Linear(120, 84), nn.Sigmoid(), #(N, 120) -> (N, 84)\n",
    "    nn.Linear(84, 10)) #(N, 84) -> (N, 10)\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "modele.apply(init_weights)\n",
    "\n",
    "from torch import optim\n",
    "optimiseur = optim.SGD(modele.parameters(), lr=0.05)\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#Chargement des données\n",
    "ds = torchvision.datasets.MNIST(root = \"./data\", train = True, download = True, transform = transforms.ToTensor())\n",
    "ds_ent, ds_valid = torch.utils.data.random_split(ds, [50000, 10000])\n",
    "ds_test = torchvision.datasets.MNIST(root = \"./data\", train = False, download = True, transform = transforms.ToTensor())\n",
    "\n",
    "#Création du DataLoader avec le dataset\n",
    "dl_ent = torch.utils.data.DataLoader(ds_ent, batch_size=100, shuffle = True)\n",
    "dl_valid = torch.utils.data.DataLoader(ds_valid, batch_size=100)\n",
    "\n",
    "def entrainer(modele, dl_ent, dl_valid, optimiseur, nb_epochs=10):\n",
    "\n",
    "    # Listes pour les métriques par epoch\n",
    "    liste_cout_moyen_ent = []\n",
    "    liste_taux_moyen_ent = []\n",
    "    liste_cout_moyen_valid = []\n",
    "    liste_taux_moyen_valid = []\n",
    "    \n",
    "    # Boucle d'apprentissage\n",
    "    for epoch in range(nb_epochs):\n",
    "        cout_total_ent = 0 # pour cumuler les couts par mini-lot\n",
    "        taux_bonnes_predictions_ent = 0 # pour cumuler les taux par mini-lot\n",
    "        modele.train() # Pour certains types de couches (nn.BatchNorm2d, nn.Dropout, ...)\n",
    "        \n",
    "        # Boucle d'apprentissage par mini-lot pour une epoch\n",
    "        for lot_X, lot_Y in dl_ent:\n",
    "            optimiseur.zero_grad() # Remettre les dérivées à zéro\n",
    "            lot_Y_predictions = modele(lot_X) # Appel de la méthode forward\n",
    "            cout = fonction_cout(lot_Y_predictions, lot_Y)\n",
    "            cout.backward() # Calcul des gradiants par rétropropagation\n",
    "            with torch.no_grad():\n",
    "                cout_total_ent +=cout\n",
    "                taux_bonnes_predictions_ent += taux_bonnes_predictions(lot_Y_predictions, lot_Y)\n",
    "            optimiseur.step() # Mise à jour des paramètres\n",
    "        # Calculer les moyennes par mini-lot\n",
    "        with torch.no_grad():\n",
    "            cout_moyen_ent = cout_total_ent/len(dl_ent)\n",
    "            taux_moyen_ent = taux_bonnes_predictions_ent/len(dl_ent)\n",
    "       \n",
    "        modele.eval() # Pour certains types de couches (nn.BatchNorm2d, nn.Dropout, ...)\n",
    "        with torch.no_grad():\n",
    "            cout_valid = sum(fonction_cout(modele(lot_valid_X), lot_valid_Y) for lot_valid_X, lot_valid_Y in dl_valid)\n",
    "            taux_bons_valid = sum(taux_bonnes_predictions(modele(lot_valid_X), lot_valid_Y) for lot_valid_X, lot_valid_Y in dl_valid)\n",
    "        cout_moyen_valid = cout_valid/len(dl_valid)\n",
    "        taux_moyen_valid = taux_bons_valid/len(dl_valid)\n",
    "        print(f'-------- > epoch {epoch+1}:  coût moyen entraînement = {cout_moyen_ent}')\n",
    "        print(f'-------- > epoch {epoch+1}:  taux moyen entraînement = {taux_moyen_ent}')\n",
    "        print(f'-------- > epoch {epoch+1}:  coût moyen validation = {cout_moyen_valid}')\n",
    "        print(f'-------- > epoch {epoch+1}:  taux moyen validation = {taux_moyen_valid}')\n",
    "    \n",
    "        liste_cout_moyen_ent.append(cout_moyen_ent)\n",
    "        liste_taux_moyen_ent.append(taux_moyen_ent)\n",
    "        liste_cout_moyen_valid.append(cout_moyen_valid)\n",
    "        liste_taux_moyen_valid.append(taux_moyen_valid)\n",
    "    \n",
    "    # Affichage du graphique d'évolution des métriques par epoch\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(np.arange(0,nb_epochs),liste_cout_moyen_ent,label='Erreur entraînement')\n",
    "    plt.plot(np.arange(0,nb_epochs),liste_cout_moyen_valid,label='Erreur validation')\n",
    "    plt.title(\"Evolution du coût\")\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('moyenne par observation')\n",
    "    plt.legend(loc='upper center')\n",
    "    plt.show()\n",
    "        \n",
    "    plt.plot(np.arange(0,nb_epochs),liste_taux_moyen_ent,label='Taux bonnes réponses entraînement')\n",
    "    plt.plot(np.arange(0,nb_epochs),liste_taux_moyen_valid,label='Taux bonnes réponses validation')\n",
    "    plt.title(\"Evolution du taux\")\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('moyenne par observation')\n",
    "    plt.legend(loc='lower center')\n",
    "    plt.show()\n",
    "\n",
    "entrainer(modele, dl_ent, dl_valid, optimiseur, nb_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type de couche: Conv2d   Forme de sortie: torch.Size([1, 6, 28, 28])\n",
      "Type de couche: Sigmoid   Forme de sortie: torch.Size([1, 6, 28, 28])\n",
      "Type de couche: AvgPool2d   Forme de sortie: torch.Size([1, 6, 14, 14])\n",
      "Type de couche: Conv2d   Forme de sortie: torch.Size([1, 16, 10, 10])\n",
      "Type de couche: Sigmoid   Forme de sortie: torch.Size([1, 16, 10, 10])\n",
      "Type de couche: AvgPool2d   Forme de sortie: torch.Size([1, 16, 5, 5])\n",
      "Type de couche: Flatten   Forme de sortie: torch.Size([1, 400])\n",
      "Type de couche: Linear   Forme de sortie: torch.Size([1, 120])\n",
      "Type de couche: Sigmoid   Forme de sortie: torch.Size([1, 120])\n",
      "Type de couche: Linear   Forme de sortie: torch.Size([1, 84])\n",
      "Type de couche: Sigmoid   Forme de sortie: torch.Size([1, 84])\n",
      "Type de couche: Linear   Forme de sortie: torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(size=(1, 1, 28, 28), dtype=torch.float32)\n",
    "for une_couche in modele:\n",
    "    X = une_couche(X)\n",
    "    print('Type de couche:',une_couche.__class__.__name__,'  Forme de sortie:',X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
