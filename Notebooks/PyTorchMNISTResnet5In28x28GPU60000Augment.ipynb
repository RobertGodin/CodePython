{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrainement sur  cpu\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0ea0515edce3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m \u001b[0mentrainer_GPU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodele\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdl_ent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdl_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimiseur\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-0ea0515edce3>\u001b[0m in \u001b[0;36mentrainer_GPU\u001b[1;34m(modele, dl_ent, dl_valid, optimiseur, nb_epochs)\u001b[0m\n\u001b[0;32m    109\u001b[0m             \u001b[0mlot_Y_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodele\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlot_X\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Appel de la méthode forward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[0mcout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfonction_cout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlot_Y_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlot_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m             \u001b[0mcout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Calcul des gradiants par rétropropagation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m                 \u001b[0mcout_total_ent\u001b[0m \u001b[1;33m+=\u001b[0m\u001b[0mcout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \"\"\"\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Exemple de MNIST avec PyTorch\n",
    "Exemple avec ResNet5 (5 couches convolutives) pour 28x28\n",
    "Exploitation des 60000 données d'entrainement et des données de test\n",
    "Augmentation des données d'entrainement\n",
    "Version avec GPU\n",
    "\"\"\"\n",
    "import torch\n",
    "torch.manual_seed(0) # Pour résultats reproductibles\n",
    "\n",
    "# Fonction J d'entropie croisée\n",
    "import torch.nn.functional as F\n",
    "fonction_cout = F.cross_entropy\n",
    "\n",
    "def taux_bonnes_predictions(lot_Y_predictions, lot_Y):\n",
    "    predictions_categorie = torch.argmax(lot_Y_predictions, dim=1)\n",
    "    return (predictions_categorie == lot_Y).float().mean()\n",
    "\n",
    "from torch import nn\n",
    "# Définition de l'architecture du RNA\n",
    "\n",
    "class BlocResiduel2d(nn.Module):\n",
    "    \"\"\" Représente un bloc de base de l'architecture Resnet\n",
    "    nb_canaux_in : nombre de canaux de l'entrée X\n",
    "    nb_canaux_out : nombre de canaux de la sortie Y\n",
    "    pas : le pas de la première convolution conv1\n",
    "    \"\"\"\n",
    "    def __init__(self, nb_canaux_in, nb_canaux_out,pas=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(nb_canaux_in, nb_canaux_out,kernel_size=3, padding=1, stride=pas)\n",
    "        self.conv2 = nn.Conv2d(nb_canaux_out, nb_canaux_out,kernel_size=3, padding=1)\n",
    "        if nb_canaux_in != nb_canaux_out:\n",
    "            self.conv3 = nn.Conv2d(nb_canaux_in, nb_canaux_out,kernel_size=1, stride=pas)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        self.bn1 = nn.BatchNorm2d(nb_canaux_out)\n",
    "        self.bn2 = nn.BatchNorm2d(nb_canaux_out)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, lot_X):\n",
    "        lot_Y_predictions = F.relu(self.bn1(self.conv1(lot_X)))\n",
    "        lot_Y_predictions = self.bn2(self.conv2(lot_Y_predictions))\n",
    "        \n",
    "        # si le nombre de canaux de la sortie est différent de l'entrée\n",
    "        # la convolution 1x1 fait la conversion de l'entrée X\n",
    "        if self.conv3:\n",
    "            lot_X = self.conv3(lot_X)\n",
    "\n",
    "        lot_Y_predictions += lot_X\n",
    "        return F.relu(lot_Y_predictions)\n",
    "    \n",
    "# Resnet5 simplifié sans la première convolution pour résolution MNIST 28x28\n",
    "modele = nn.Sequential(BlocResiduel2d(1,32), BlocResiduel2d(32,64) ,# ->(N,64,28,28)\n",
    "                   nn.AdaptiveMaxPool2d((1,1)), nn.Flatten(), nn.Linear(64,10))\n",
    "\n",
    "from torch import optim\n",
    "optimiseur = optim.SGD(modele.parameters(), lr=0.01)\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "transformations_ent = transforms.Compose([\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Normalisation mais sans augmentation pour la validation\n",
    "transformations_valid = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "#Chargement des données\n",
    "ds_ent = torchvision.datasets.MNIST(root = \"./data\", train = True, download = True, transform = transformations_ent)\n",
    "ds_valid = torchvision.datasets.MNIST(root = \"./data\", train = False, download = True, transform = transformations_valid)\n",
    "\n",
    "#Création du DataLoader avec le dataset\n",
    "dl_ent = torch.utils.data.DataLoader(ds_ent, batch_size=100, shuffle = True)\n",
    "dl_valid = torch.utils.data.DataLoader(ds_valid, batch_size=100)\n",
    "\n",
    "# Déterminer si un GPU est disponible\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Entrainement sur ',device)\n",
    "\n",
    "# Placer le modèle en mode GPU si possible\n",
    "modele = modele.to(device)\n",
    "\n",
    "import time\n",
    "def entrainer_GPU(modele, dl_ent, dl_valid, optimiseur, nb_epochs=10):\n",
    "\n",
    "    debut = time.time()\n",
    "\n",
    "    # Listes pour les métriques par epoch\n",
    "    liste_cout_moyen_ent = []\n",
    "    liste_taux_moyen_ent = []\n",
    "    liste_cout_moyen_valid = []\n",
    "    liste_taux_moyen_valid = []\n",
    "    \n",
    "    # Boucle d'apprentissage\n",
    "    for epoch in range(nb_epochs):\n",
    "        cout_total_ent = 0 # pour cumuler les couts par mini-lot\n",
    "        taux_bonnes_predictions_ent = 0 # pour cumuler les taux par mini-lot\n",
    "        modele.train() # Pour certains types de couches (nn.BatchNorm2d, nn.Dropout, ...)\n",
    "        \n",
    "        # Boucle d'apprentissage par mini-lot pour une epoch\n",
    "        for lot_X, lot_Y in dl_ent:\n",
    "            \n",
    "            # Les données doivent être placés en GPU pour être compatibles avec le modèle\n",
    "            lot_X = lot_X.to(device)\n",
    "            lot_Y = lot_Y.to(device)\n",
    "\n",
    "            optimiseur.zero_grad() # Remettre les dérivées à zéro\n",
    "            lot_Y_predictions = modele(lot_X) # Appel de la méthode forward\n",
    "            cout = fonction_cout(lot_Y_predictions, lot_Y)\n",
    "            cout.backward() # Calcul des gradiants par rétropropagation\n",
    "            with torch.no_grad():\n",
    "                cout_total_ent +=cout\n",
    "                taux_bonnes_predictions_ent += taux_bonnes_predictions(lot_Y_predictions, lot_Y)\n",
    "            optimiseur.step() # Mise à jour des paramètres\n",
    "            # scheduler.step()\n",
    "        # Calculer les moyennes par mini-lot\n",
    "        with torch.no_grad():\n",
    "            cout_moyen_ent = cout_total_ent/len(dl_ent)\n",
    "            taux_moyen_ent = taux_bonnes_predictions_ent/len(dl_ent)\n",
    "       \n",
    "        modele.eval() # Pour certains types de couches (nn.BatchNorm2d, nn.Dropout, ...)\n",
    "        with torch.no_grad():\n",
    "            # Les données de validation doivent aussi être placés en GPU\n",
    "            cout_valid = sum(fonction_cout(modele(lot_valid_X.to(device)), lot_valid_Y.to(device)) for lot_valid_X, lot_valid_Y in dl_valid)\n",
    "            taux_bons_valid = sum(taux_bonnes_predictions(modele(lot_valid_X.to(device)), lot_valid_Y.to(device)) for lot_valid_X, lot_valid_Y in dl_valid)\n",
    "        cout_moyen_valid = cout_valid/len(dl_valid)\n",
    "        taux_moyen_valid = taux_bons_valid/len(dl_valid)\n",
    "        print(f'-------- > epoch {epoch+1}:  coût moyen entraînement = {cout_moyen_ent}')\n",
    "        print(f'-------- > epoch {epoch+1}:  taux moyen entraînement = {taux_moyen_ent}')\n",
    "        print(f'-------- > epoch {epoch+1}:  coût moyen validation = {cout_moyen_valid}')\n",
    "        print(f'-------- > epoch {epoch+1}:  taux moyen validation = {taux_moyen_valid}')\n",
    "    \n",
    "        liste_cout_moyen_ent.append(cout_moyen_ent)\n",
    "        liste_taux_moyen_ent.append(taux_moyen_ent)\n",
    "        liste_cout_moyen_valid.append(cout_moyen_valid)\n",
    "        liste_taux_moyen_valid.append(taux_moyen_valid)\n",
    "        \n",
    "        temps_ecoule = time.time() - debut\n",
    "        print('Temps écoulé : {:.0f}m {:.0f}s'.format(temps_ecoule // 60, temps_ecoule % 60))\n",
    "\n",
    "    \n",
    "    # Affichage du graphique d'évolution des métriques par epoch\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(np.arange(0,nb_epochs),liste_cout_moyen_ent,label='Erreur entraînement')\n",
    "    plt.plot(np.arange(0,nb_epochs),liste_cout_moyen_valid,label='Erreur validation')\n",
    "    plt.title(\"Evolution du coût\")\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('moyenne par observation')\n",
    "    plt.legend(loc='upper center')\n",
    "    plt.show()\n",
    "        \n",
    "    plt.plot(np.arange(0,nb_epochs),liste_taux_moyen_ent,label='Taux bonnes réponses entraînement')\n",
    "    plt.plot(np.arange(0,nb_epochs),liste_taux_moyen_valid,label='Taux bonnes réponses validation')\n",
    "    plt.title(\"Evolution du taux\")\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('moyenne par observation')\n",
    "    plt.legend(loc='center')\n",
    "    plt.show()\n",
    "\n",
    "entrainer_GPU(modele, dl_ent, dl_valid, optimiseur, nb_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
