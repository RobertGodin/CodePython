{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Réseau de neurones récurrent, modèle de langue par mot, pour paroles de chansons\n",
    "Version avec couche vectorisation de mots et RNN \n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(0) # Pour résultats reproductibles\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "class DatasetParoles(torch.utils.data.Dataset):\n",
    "    \"\"\" Créer un Dataset avec les paroles de la colonne Lyric du fichier \n",
    "    taille_sequence : taille d'une séquence de mots pour le modèle de langue\n",
    "    Le texte est découpé en séquences de la taille taille_sequence\n",
    "    \"\"\"\n",
    "    def __init__(self, nom_fichier, taille_sequence=4):\n",
    "        self.nom_fichier = nom_fichier\n",
    "        self.taille_sequence = taille_sequence\n",
    "        self.mots = self.charger_mots()\n",
    "        self.mots_uniques = self.chercher_mots_uniques()\n",
    "\n",
    "        self.index_a_mot = {index: mot for index, mot in enumerate(self.mots_uniques)}\n",
    "        self.mot_a_index = {mot: index for index, mot in enumerate(self.mots_uniques)}\n",
    "\n",
    "        self.mots_indexes = [self.mot_a_index[w] for w in self.mots]\n",
    "\n",
    "    def charger_mots(self):\n",
    "        dataframe_entrainement = pd.read_csv(self.nom_fichier)\n",
    "        texte_concatene = dataframe_entrainement.iloc[0:100]['Lyric'].str.cat(sep=' ')\n",
    "        return texte_concatene.split(' ')\n",
    "\n",
    "    def chercher_mots_uniques(self):\n",
    "        frequence_mot = Counter(self.mots)\n",
    "        return sorted(frequence_mot, key=frequence_mot.get, reverse=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mots_indexes) - self.taille_sequence\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            torch.tensor(self.mots_indexes[index:index+self.taille_sequence]),\n",
    "            torch.tensor(self.mots_indexes[index+1:index+self.taille_sequence+1]),\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([1588,    3,    1,    7,   26,  225]), tensor([   3,    1,    7,   26,  225, 1589]))\n"
     ]
    }
   ],
   "source": [
    "ds_paroles = DatasetParoles(\"lyrics-data.csv\",taille_sequence=6)\n",
    "print(ds_paroles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- > epoch 0 lot 0 :  coût = 7.6551690101623535\n",
      "-------- > epoch 0 lot 10 :  coût = 7.510778427124023\n",
      "-------- > epoch 0 lot 20 :  coût = 7.000609874725342\n",
      "-------- > epoch 0 lot 30 :  coût = 6.249145030975342\n",
      "-------- > epoch 0 lot 40 :  coût = 6.797878265380859\n",
      "-------- > epoch 0 lot 50 :  coût = 6.162596225738525\n",
      "-------- > epoch 0 lot 60 :  coût = 6.240902423858643\n",
      "-------- > epoch 0 lot 70 :  coût = 5.520714282989502\n",
      "-------- > epoch 0 lot 80 :  coût = 6.088428020477295\n",
      "-------- > epoch 0 lot 90 :  coût = 5.626760005950928\n",
      "-------- > epoch 0 lot 100 :  coût = 6.3954644203186035\n",
      "-------- > epoch 0 lot 110 :  coût = 6.560697078704834\n",
      "-------- > epoch 0 lot 120 :  coût = 5.489595413208008\n",
      "-------- > epoch 0 lot 130 :  coût = 5.921864986419678\n",
      "-------- > epoch 0 lot 140 :  coût = 5.709108352661133\n",
      "-------- > epoch 0 lot 150 :  coût = 8.206951141357422\n",
      "-------- > epoch 0 lot 160 :  coût = 7.392282962799072\n",
      "-------- > epoch 0 lot 170 :  coût = 6.257867336273193\n",
      "-------- > epoch 0 lot 180 :  coût = 5.82142972946167\n",
      "-------- > epoch 0 lot 190 :  coût = 5.816694736480713\n",
      "-------- > epoch 0 lot 200 :  coût = 6.041383743286133\n",
      "-------- > epoch 0 lot 210 :  coût = 6.263282775878906\n",
      "-------- > epoch 0 lot 220 :  coût = 5.658518314361572\n",
      "-------- > epoch 0 lot 230 :  coût = 5.736162185668945\n",
      "-------- > epoch 0 lot 240 :  coût = 5.243499279022217\n",
      "-------- > epoch 0 lot 250 :  coût = 5.848491191864014\n",
      "-------- > epoch 0 lot 260 :  coût = 6.014623641967773\n",
      "-------- > epoch 0 lot 270 :  coût = 5.6855549812316895\n",
      "-------- > epoch 0 lot 280 :  coût = 6.029968738555908\n",
      "-------- > epoch 0 lot 290 :  coût = 6.492640018463135\n",
      "-------- > epoch 0 lot 300 :  coût = 6.130289077758789\n",
      "-------- > epoch 0 lot 310 :  coût = 6.302769184112549\n",
      "-------- > epoch 0 lot 320 :  coût = 7.937774181365967\n",
      "-------- > epoch 0 lot 330 :  coût = 5.5663371086120605\n",
      "-------- > epoch 0 lot 340 :  coût = 5.135261058807373\n",
      "-------- > epoch 0 lot 350 :  coût = 6.135927200317383\n",
      "-------- > epoch 0 lot 360 :  coût = 6.367097854614258\n",
      "-------- > epoch 0 lot 370 :  coût = 7.014787197113037\n",
      "-------- > epoch 0 lot 380 :  coût = 5.931941986083984\n",
      "-------- > epoch 0 lot 390 :  coût = 6.873127460479736\n",
      "-------- > epoch 0 lot 400 :  coût = 6.153977870941162\n",
      "-------- > epoch 0 lot 410 :  coût = 6.005138397216797\n",
      "-------- > epoch 0 lot 420 :  coût = 5.143365859985352\n",
      "-------- > epoch 0 lot 430 :  coût = 5.411701202392578\n",
      "-------- > epoch 0 lot 440 :  coût = 6.747907638549805\n",
      "-------- > epoch 0 lot 450 :  coût = 6.030824661254883\n",
      "-------- > epoch 0 lot 460 :  coût = 5.423772811889648\n",
      "-------- > epoch 0 lot 470 :  coût = 6.884206771850586\n",
      "-------- > epoch 0 lot 480 :  coût = 5.162407398223877\n",
      "-------- > epoch 0 lot 490 :  coût = 5.7093377113342285\n",
      "-------- > epoch 0 lot 500 :  coût = 5.750776767730713\n",
      "-------- > epoch 0 lot 510 :  coût = 6.6674723625183105\n",
      "-------- > epoch 0 lot 520 :  coût = 5.3332743644714355\n",
      "-------- > epoch 0 lot 530 :  coût = 5.654853343963623\n",
      "-------- > epoch 0 lot 540 :  coût = 5.051885604858398\n",
      "-------- > epoch 0 lot 550 :  coût = 5.816583156585693\n",
      "-------- > epoch 0 lot 560 :  coût = 6.297609329223633\n",
      "-------- > epoch 0 lot 570 :  coût = 5.884438991546631\n",
      "-------- > epoch 0 lot 580 :  coût = 5.768962860107422\n",
      "-------- > epoch 0 lot 590 :  coût = 6.047149658203125\n",
      "-------- > epoch 0 lot 600 :  coût = 7.395477771759033\n",
      "-------- > epoch 0 lot 610 :  coût = 7.039313793182373\n",
      "-------- > epoch 1 lot 0 :  coût = 5.103887557983398\n",
      "-------- > epoch 1 lot 10 :  coût = 5.277317523956299\n",
      "-------- > epoch 1 lot 20 :  coût = 5.030331134796143\n",
      "-------- > epoch 1 lot 30 :  coût = 4.52350378036499\n",
      "-------- > epoch 1 lot 40 :  coût = 4.4565558433532715\n",
      "-------- > epoch 1 lot 50 :  coût = 5.119663715362549\n",
      "-------- > epoch 1 lot 60 :  coût = 5.14477014541626\n",
      "-------- > epoch 1 lot 70 :  coût = 4.1217875480651855\n",
      "-------- > epoch 1 lot 80 :  coût = 5.434957504272461\n",
      "-------- > epoch 1 lot 90 :  coût = 4.878156661987305\n",
      "-------- > epoch 1 lot 100 :  coût = 5.591013431549072\n",
      "-------- > epoch 1 lot 110 :  coût = 5.767139434814453\n",
      "-------- > epoch 1 lot 120 :  coût = 4.474579811096191\n",
      "-------- > epoch 1 lot 130 :  coût = 4.796775817871094\n",
      "-------- > epoch 1 lot 140 :  coût = 4.826185703277588\n",
      "-------- > epoch 1 lot 150 :  coût = 6.658344745635986\n",
      "-------- > epoch 1 lot 160 :  coût = 6.81577730178833\n",
      "-------- > epoch 1 lot 170 :  coût = 5.498552322387695\n",
      "-------- > epoch 1 lot 180 :  coût = 4.893684387207031\n",
      "-------- > epoch 1 lot 190 :  coût = 4.926853656768799\n",
      "-------- > epoch 1 lot 200 :  coût = 5.348372936248779\n",
      "-------- > epoch 1 lot 210 :  coût = 5.512603759765625\n",
      "-------- > epoch 1 lot 220 :  coût = 5.073718547821045\n",
      "-------- > epoch 1 lot 230 :  coût = 4.849979400634766\n",
      "-------- > epoch 1 lot 240 :  coût = 4.469557762145996\n",
      "-------- > epoch 1 lot 250 :  coût = 5.095720291137695\n",
      "-------- > epoch 1 lot 260 :  coût = 5.149210453033447\n",
      "-------- > epoch 1 lot 270 :  coût = 5.012382984161377\n",
      "-------- > epoch 1 lot 280 :  coût = 5.206859588623047\n",
      "-------- > epoch 1 lot 290 :  coût = 5.963659763336182\n",
      "-------- > epoch 1 lot 300 :  coût = 5.151419162750244\n",
      "-------- > epoch 1 lot 310 :  coût = 5.344882488250732\n",
      "-------- > epoch 1 lot 320 :  coût = 6.773133754730225\n",
      "-------- > epoch 1 lot 330 :  coût = 4.933550834655762\n",
      "-------- > epoch 1 lot 340 :  coût = 4.536369323730469\n",
      "-------- > epoch 1 lot 350 :  coût = 5.212654113769531\n",
      "-------- > epoch 1 lot 360 :  coût = 5.886458873748779\n",
      "-------- > epoch 1 lot 370 :  coût = 6.1331634521484375\n",
      "-------- > epoch 1 lot 380 :  coût = 5.528728485107422\n",
      "-------- > epoch 1 lot 390 :  coût = 5.771447658538818\n",
      "-------- > epoch 1 lot 400 :  coût = 5.513362884521484\n",
      "-------- > epoch 1 lot 410 :  coût = 5.540298938751221\n",
      "-------- > epoch 1 lot 420 :  coût = 4.422080993652344\n",
      "-------- > epoch 1 lot 430 :  coût = 4.858409404754639\n",
      "-------- > epoch 1 lot 440 :  coût = 6.18589448928833\n",
      "-------- > epoch 1 lot 450 :  coût = 5.236242771148682\n",
      "-------- > epoch 1 lot 460 :  coût = 4.964724540710449\n",
      "-------- > epoch 1 lot 470 :  coût = 5.741270065307617\n",
      "-------- > epoch 1 lot 480 :  coût = 3.977154016494751\n",
      "-------- > epoch 1 lot 490 :  coût = 4.718513488769531\n",
      "-------- > epoch 1 lot 500 :  coût = 5.422571182250977\n",
      "-------- > epoch 1 lot 510 :  coût = 6.305845737457275\n",
      "-------- > epoch 1 lot 520 :  coût = 4.69877815246582\n",
      "-------- > epoch 1 lot 530 :  coût = 4.664369583129883\n",
      "-------- > epoch 1 lot 540 :  coût = 4.306011199951172\n",
      "-------- > epoch 1 lot 550 :  coût = 4.975822925567627\n",
      "-------- > epoch 1 lot 560 :  coût = 5.898309707641602\n",
      "-------- > epoch 1 lot 570 :  coût = 5.376764297485352\n",
      "-------- > epoch 1 lot 580 :  coût = 4.884220123291016\n",
      "-------- > epoch 1 lot 590 :  coût = 5.597782135009766\n",
      "-------- > epoch 1 lot 600 :  coût = 6.706178188323975\n",
      "-------- > epoch 1 lot 610 :  coût = 6.426595211029053\n",
      "-------- > epoch 2 lot 0 :  coût = 4.833288192749023\n",
      "-------- > epoch 2 lot 10 :  coût = 4.927438259124756\n",
      "-------- > epoch 2 lot 20 :  coût = 4.776046276092529\n",
      "-------- > epoch 2 lot 30 :  coût = 3.980839967727661\n",
      "-------- > epoch 2 lot 40 :  coût = 3.675368309020996\n",
      "-------- > epoch 2 lot 50 :  coût = 4.907151699066162\n",
      "-------- > epoch 2 lot 60 :  coût = 4.587985515594482\n",
      "-------- > epoch 2 lot 70 :  coût = 3.6803998947143555\n",
      "-------- > epoch 2 lot 80 :  coût = 4.790024757385254\n",
      "-------- > epoch 2 lot 90 :  coût = 4.607280254364014\n",
      "-------- > epoch 2 lot 100 :  coût = 5.423065662384033\n",
      "-------- > epoch 2 lot 110 :  coût = 5.519199848175049\n",
      "-------- > epoch 2 lot 120 :  coût = 3.828815460205078\n",
      "-------- > epoch 2 lot 130 :  coût = 4.261775493621826\n",
      "-------- > epoch 2 lot 140 :  coût = 4.2298903465271\n",
      "-------- > epoch 2 lot 150 :  coût = 5.842193603515625\n",
      "-------- > epoch 2 lot 160 :  coût = 6.387544631958008\n",
      "-------- > epoch 2 lot 170 :  coût = 5.207176208496094\n",
      "-------- > epoch 2 lot 180 :  coût = 4.089035987854004\n",
      "-------- > epoch 2 lot 190 :  coût = 4.38010835647583\n",
      "-------- > epoch 2 lot 200 :  coût = 4.996857166290283\n",
      "-------- > epoch 2 lot 210 :  coût = 5.25756311416626\n",
      "-------- > epoch 2 lot 220 :  coût = 4.8129448890686035\n",
      "-------- > epoch 2 lot 230 :  coût = 4.179571151733398\n",
      "-------- > epoch 2 lot 240 :  coût = 3.9589860439300537\n",
      "-------- > epoch 2 lot 250 :  coût = 4.639489650726318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- > epoch 2 lot 260 :  coût = 4.519418239593506\n",
      "-------- > epoch 2 lot 270 :  coût = 4.713341236114502\n",
      "-------- > epoch 2 lot 280 :  coût = 4.937442302703857\n",
      "-------- > epoch 2 lot 290 :  coût = 5.499549865722656\n",
      "-------- > epoch 2 lot 300 :  coût = 4.506556034088135\n",
      "-------- > epoch 2 lot 310 :  coût = 4.757735729217529\n",
      "-------- > epoch 2 lot 320 :  coût = 5.512849807739258\n",
      "-------- > epoch 2 lot 330 :  coût = 4.396300792694092\n",
      "-------- > epoch 2 lot 340 :  coût = 4.324193000793457\n",
      "-------- > epoch 2 lot 350 :  coût = 4.632694721221924\n",
      "-------- > epoch 2 lot 360 :  coût = 5.568561553955078\n",
      "-------- > epoch 2 lot 370 :  coût = 5.697877883911133\n",
      "-------- > epoch 2 lot 380 :  coût = 5.20526647567749\n",
      "-------- > epoch 2 lot 390 :  coût = 4.980088233947754\n",
      "-------- > epoch 2 lot 400 :  coût = 5.121632099151611\n",
      "-------- > epoch 2 lot 410 :  coût = 5.251952648162842\n",
      "-------- > epoch 2 lot 420 :  coût = 3.957341194152832\n",
      "-------- > epoch 2 lot 430 :  coût = 4.451236248016357\n",
      "-------- > epoch 2 lot 440 :  coût = 5.656169414520264\n",
      "-------- > epoch 2 lot 450 :  coût = 4.904395580291748\n",
      "-------- > epoch 2 lot 460 :  coût = 4.663163661956787\n",
      "-------- > epoch 2 lot 470 :  coût = 5.1173787117004395\n",
      "-------- > epoch 2 lot 480 :  coût = 3.3519065380096436\n",
      "-------- > epoch 2 lot 490 :  coût = 4.212151050567627\n",
      "-------- > epoch 2 lot 500 :  coût = 5.118829250335693\n",
      "-------- > epoch 2 lot 510 :  coût = 6.047291278839111\n",
      "-------- > epoch 2 lot 520 :  coût = 4.351983547210693\n",
      "-------- > epoch 2 lot 530 :  coût = 4.047346591949463\n",
      "-------- > epoch 2 lot 540 :  coût = 3.7764434814453125\n",
      "-------- > epoch 2 lot 550 :  coût = 4.432645797729492\n",
      "-------- > epoch 2 lot 560 :  coût = 5.465022563934326\n",
      "-------- > epoch 2 lot 570 :  coût = 5.07130241394043\n",
      "-------- > epoch 2 lot 580 :  coût = 4.021251201629639\n",
      "-------- > epoch 2 lot 590 :  coût = 5.158183574676514\n",
      "-------- > epoch 2 lot 600 :  coût = 5.990697860717773\n",
      "-------- > epoch 2 lot 610 :  coût = 5.9652099609375\n",
      "-------- > epoch 3 lot 0 :  coût = 4.639379501342773\n",
      "-------- > epoch 3 lot 10 :  coût = 4.537144184112549\n",
      "-------- > epoch 3 lot 20 :  coût = 4.581953525543213\n",
      "-------- > epoch 3 lot 30 :  coût = 3.5146114826202393\n",
      "-------- > epoch 3 lot 40 :  coût = 3.040987968444824\n",
      "-------- > epoch 3 lot 50 :  coût = 4.779605388641357\n",
      "-------- > epoch 3 lot 60 :  coût = 4.075026988983154\n",
      "-------- > epoch 3 lot 70 :  coût = 3.227288246154785\n",
      "-------- > epoch 3 lot 80 :  coût = 4.070930004119873\n",
      "-------- > epoch 3 lot 90 :  coût = 4.31009578704834\n",
      "-------- > epoch 3 lot 100 :  coût = 5.132105350494385\n",
      "-------- > epoch 3 lot 110 :  coût = 5.220317363739014\n",
      "-------- > epoch 3 lot 120 :  coût = 3.4140920639038086\n",
      "-------- > epoch 3 lot 130 :  coût = 3.8986518383026123\n",
      "-------- > epoch 3 lot 140 :  coût = 3.7362444400787354\n",
      "-------- > epoch 3 lot 150 :  coût = 4.841461658477783\n",
      "-------- > epoch 3 lot 160 :  coût = 5.965173721313477\n",
      "-------- > epoch 3 lot 170 :  coût = 5.009675979614258\n",
      "-------- > epoch 3 lot 180 :  coût = 3.6481449604034424\n",
      "-------- > epoch 3 lot 190 :  coût = 3.8814687728881836\n",
      "-------- > epoch 3 lot 200 :  coût = 4.760499000549316\n",
      "-------- > epoch 3 lot 210 :  coût = 5.051662921905518\n",
      "-------- > epoch 3 lot 220 :  coût = 4.551393032073975\n",
      "-------- > epoch 3 lot 230 :  coût = 3.73276424407959\n",
      "-------- > epoch 3 lot 240 :  coût = 3.528160333633423\n",
      "-------- > epoch 3 lot 250 :  coût = 4.219223499298096\n",
      "-------- > epoch 3 lot 260 :  coût = 3.928133726119995\n",
      "-------- > epoch 3 lot 270 :  coût = 4.5130085945129395\n",
      "-------- > epoch 3 lot 280 :  coût = 4.6074934005737305\n",
      "-------- > epoch 3 lot 290 :  coût = 5.210582256317139\n",
      "-------- > epoch 3 lot 300 :  coût = 3.9566662311553955\n",
      "-------- > epoch 3 lot 310 :  coût = 4.219396114349365\n",
      "-------- > epoch 3 lot 320 :  coût = 4.458540439605713\n",
      "-------- > epoch 3 lot 330 :  coût = 3.9683141708374023\n",
      "-------- > epoch 3 lot 340 :  coût = 4.025355815887451\n",
      "-------- > epoch 3 lot 350 :  coût = 4.234453201293945\n",
      "-------- > epoch 3 lot 360 :  coût = 5.201213359832764\n",
      "-------- > epoch 3 lot 370 :  coût = 5.290788650512695\n",
      "-------- > epoch 3 lot 380 :  coût = 4.853987693786621\n",
      "-------- > epoch 3 lot 390 :  coût = 4.388638973236084\n",
      "-------- > epoch 3 lot 400 :  coût = 4.82416296005249\n",
      "-------- > epoch 3 lot 410 :  coût = 5.010840892791748\n",
      "-------- > epoch 3 lot 420 :  coût = 3.6330220699310303\n",
      "-------- > epoch 3 lot 430 :  coût = 4.111870288848877\n",
      "-------- > epoch 3 lot 440 :  coût = 5.153563022613525\n",
      "-------- > epoch 3 lot 450 :  coût = 4.611172199249268\n",
      "-------- > epoch 3 lot 460 :  coût = 4.401486396789551\n",
      "-------- > epoch 3 lot 470 :  coût = 4.548202037811279\n",
      "-------- > epoch 3 lot 480 :  coût = 2.968428611755371\n",
      "-------- > epoch 3 lot 490 :  coût = 3.8015387058258057\n",
      "-------- > epoch 3 lot 500 :  coût = 4.854248046875\n",
      "-------- > epoch 3 lot 510 :  coût = 5.704040050506592\n",
      "-------- > epoch 3 lot 520 :  coût = 4.1058526039123535\n",
      "-------- > epoch 3 lot 530 :  coût = 3.6324779987335205\n",
      "-------- > epoch 3 lot 540 :  coût = 3.3695290088653564\n",
      "-------- > epoch 3 lot 550 :  coût = 4.036207675933838\n",
      "-------- > epoch 3 lot 560 :  coût = 5.113880634307861\n",
      "-------- > epoch 3 lot 570 :  coût = 4.8124518394470215\n",
      "-------- > epoch 3 lot 580 :  coût = 3.3843834400177\n",
      "-------- > epoch 3 lot 590 :  coût = 4.8237223625183105\n",
      "-------- > epoch 3 lot 600 :  coût = 5.354620456695557\n",
      "-------- > epoch 3 lot 610 :  coût = 5.480234622955322\n",
      "-------- > epoch 4 lot 0 :  coût = 4.554583549499512\n",
      "-------- > epoch 4 lot 10 :  coût = 4.269903659820557\n",
      "-------- > epoch 4 lot 20 :  coût = 4.40791654586792\n",
      "-------- > epoch 4 lot 30 :  coût = 3.079730272293091\n",
      "-------- > epoch 4 lot 40 :  coût = 2.6571948528289795\n",
      "-------- > epoch 4 lot 50 :  coût = 4.659328937530518\n",
      "-------- > epoch 4 lot 60 :  coût = 3.651563882827759\n",
      "-------- > epoch 4 lot 70 :  coût = 2.9065210819244385\n",
      "-------- > epoch 4 lot 80 :  coût = 3.529179334640503\n",
      "-------- > epoch 4 lot 90 :  coût = 4.019554615020752\n",
      "-------- > epoch 4 lot 100 :  coût = 4.743988513946533\n",
      "-------- > epoch 4 lot 110 :  coût = 4.854959487915039\n",
      "-------- > epoch 4 lot 120 :  coût = 3.0778093338012695\n",
      "-------- > epoch 4 lot 130 :  coût = 3.5903263092041016\n",
      "-------- > epoch 4 lot 140 :  coût = 3.457805633544922\n",
      "-------- > epoch 4 lot 150 :  coût = 3.785517930984497\n",
      "-------- > epoch 4 lot 160 :  coût = 5.420377254486084\n",
      "-------- > epoch 4 lot 170 :  coût = 4.881856441497803\n",
      "-------- > epoch 4 lot 180 :  coût = 3.4197998046875\n",
      "-------- > epoch 4 lot 190 :  coût = 3.4998457431793213\n",
      "-------- > epoch 4 lot 200 :  coût = 4.4973978996276855\n",
      "-------- > epoch 4 lot 210 :  coût = 4.932553768157959\n",
      "-------- > epoch 4 lot 220 :  coût = 4.312190055847168\n",
      "-------- > epoch 4 lot 230 :  coût = 3.37943959236145\n",
      "-------- > epoch 4 lot 240 :  coût = 3.180760383605957\n",
      "-------- > epoch 4 lot 250 :  coût = 3.8765738010406494\n",
      "-------- > epoch 4 lot 260 :  coût = 3.36387038230896\n",
      "-------- > epoch 4 lot 270 :  coût = 4.351434230804443\n",
      "-------- > epoch 4 lot 280 :  coût = 4.231253147125244\n",
      "-------- > epoch 4 lot 290 :  coût = 4.903717517852783\n",
      "-------- > epoch 4 lot 300 :  coût = 3.5561182498931885\n",
      "-------- > epoch 4 lot 310 :  coût = 3.8262546062469482\n",
      "-------- > epoch 4 lot 320 :  coût = 3.515623092651367\n",
      "-------- > epoch 4 lot 330 :  coût = 3.545024871826172\n",
      "-------- > epoch 4 lot 340 :  coût = 3.7281172275543213\n",
      "-------- > epoch 4 lot 350 :  coût = 3.870069742202759\n",
      "-------- > epoch 4 lot 360 :  coût = 4.843434810638428\n",
      "-------- > epoch 4 lot 370 :  coût = 4.82566499710083\n",
      "-------- > epoch 4 lot 380 :  coût = 4.6294121742248535\n",
      "-------- > epoch 4 lot 390 :  coût = 3.9920623302459717\n",
      "-------- > epoch 4 lot 400 :  coût = 4.580277442932129\n",
      "-------- > epoch 4 lot 410 :  coût = 4.721783638000488\n",
      "-------- > epoch 4 lot 420 :  coût = 3.3945887088775635\n",
      "-------- > epoch 4 lot 430 :  coût = 3.9361989498138428\n",
      "-------- > epoch 4 lot 440 :  coût = 4.707772731781006\n",
      "-------- > epoch 4 lot 450 :  coût = 4.436054706573486\n",
      "-------- > epoch 4 lot 460 :  coût = 4.118112087249756\n",
      "-------- > epoch 4 lot 470 :  coût = 4.096441745758057\n",
      "-------- > epoch 4 lot 480 :  coût = 2.6982297897338867\n",
      "-------- > epoch 4 lot 490 :  coût = 3.389348268508911\n",
      "-------- > epoch 4 lot 500 :  coût = 4.519653797149658\n",
      "-------- > epoch 4 lot 510 :  coût = 5.43943977355957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- > epoch 4 lot 520 :  coût = 3.8704893589019775\n",
      "-------- > epoch 4 lot 530 :  coût = 3.3905506134033203\n",
      "-------- > epoch 4 lot 540 :  coût = 3.04787278175354\n",
      "-------- > epoch 4 lot 550 :  coût = 3.6801671981811523\n",
      "-------- > epoch 4 lot 560 :  coût = 4.641909599304199\n",
      "-------- > epoch 4 lot 570 :  coût = 4.579174995422363\n",
      "-------- > epoch 4 lot 580 :  coût = 2.9572792053222656\n",
      "-------- > epoch 4 lot 590 :  coût = 4.501807689666748\n",
      "-------- > epoch 4 lot 600 :  coût = 4.818921089172363\n",
      "-------- > epoch 4 lot 610 :  coût = 5.041574001312256\n",
      "['you', 'know', 'the', 'promise', 'of', 'stars', \"we've\", 'no', 'myself', 'meet', 'the', 'bubble', 'and', 'written', 'poison', 'frey', 'the', 'fireplace', 'what', 'if', 'mmm', 'god']\n"
     ]
    }
   ],
   "source": [
    "class Modele(nn.Module):\n",
    "    \"\"\"Modèle de RNR avec une couche vectorisation, suivie d'une couche RNN et d'une couche linéaire\"\"\"\n",
    "    def __init__(self, ds_paroles):\n",
    "        super(Modele, self).__init__()\n",
    "        self.taille_H_RNN = 128\n",
    "        self.taille_vectorisation_mots = 64\n",
    "        self.nombre_couches_RNR = 2\n",
    "\n",
    "        taille_vocabulaire = len(ds_paroles.mots_uniques)\n",
    "        self.vectorisation_mots = nn.Embedding(num_embeddings=taille_vocabulaire,\n",
    "            embedding_dim=self.taille_vectorisation_mots)\n",
    "        self.rnn = nn.RNN(input_size=self.taille_vectorisation_mots,hidden_size=self.taille_H_RNN,\n",
    "            num_layers=self.nombre_couches_RNR,dropout=0.2,batch_first=True)\n",
    "        self.fc = nn.Linear(self.taille_H_RNN, taille_vocabulaire)\n",
    "\n",
    "    def forward(self, lot_X, etat_0):\n",
    "        vectorisation = self.vectorisation_mots(lot_X)\n",
    "        lot_Ht, etat = self.rnn(vectorisation, etat_0)\n",
    "        lot_Yt = self.fc(lot_Ht)\n",
    "\n",
    "        return lot_Yt, etat\n",
    "\n",
    "    def initializer_etat(self, taille_sequence):\n",
    "        return (torch.zeros(self.nombre_couches_RNR, taille_sequence, self.taille_H_RNN))\n",
    "    \n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def entrainer_RNR(ds_paroles, modele, taille_lot=32, epochs=10, taille_sequence=6):\n",
    "    modele.train()\n",
    "    dl_paroles = DataLoader(ds_paroles,batch_size=taille_lot)\n",
    "\n",
    "    fonction_cout = nn.CrossEntropyLoss()\n",
    "    optimizeur = optim.Adam(modele.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        for lot, (lot_X, lot_Y) in enumerate(dl_paroles):\n",
    "\n",
    "            optimizeur.zero_grad()\n",
    "            etat = modele.initializer_etat(lot_X.shape[0])\n",
    "            lot_Y_predictions, etat = modele(lot_X, etat)\n",
    "            cout = fonction_cout(lot_Y_predictions.transpose(1, 2), lot_Y)\n",
    "            \n",
    "            cout.backward()\n",
    "            optimizeur.step()\n",
    "            if lot%10 == 0:\n",
    "                print(f'-------- > epoch {epoch} lot {lot} :  coût = {cout.item()}')\n",
    "\n",
    "def predire(ds, modele, debut_texte, nb_mots=20):\n",
    "    \"\"\" Prédire une suite de nb_mots à partir de debut_texte selon le modele\"\"\"\n",
    "    mots = debut_texte.split(' ')\n",
    "    modele.eval()\n",
    "    etat = modele.initializer_etat(1)\n",
    "\n",
    "    for i in range(0, nb_mots):\n",
    "        lot_X = torch.tensor([[ds.mot_a_index[m] for m in mots[i:]]])\n",
    "        lot_Y_predictions, etat = modele(lot_X, etat)\n",
    "        dernier_mot_Yt = lot_Y_predictions[0][-1]\n",
    "        probs_dernier_mot = torch.nn.functional.softmax(dernier_mot_Yt, dim=0).detach().numpy()\n",
    "        index_mot_choisi = np.random.choice(len(dernier_mot_Yt), p=probs_dernier_mot)\n",
    "        mots.append(ds.index_a_mot[index_mot_choisi])\n",
    "\n",
    "    return mots\n",
    "\n",
    "ds_paroles = DatasetParoles(\"ColdPlay.csv\", taille_sequence=6)\n",
    "modele = Modele(ds_paroles)\n",
    "\n",
    "entrainer_RNR(ds_paroles, modele, taille_lot=32, epochs=5, taille_sequence=6)\n",
    "print(predire(ds_paroles, modele, debut_texte='you know'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 344 entries, 0 to 343\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  344 non-null    object \n",
      " 1   Artist      339 non-null    object \n",
      " 2   Title       339 non-null    object \n",
      " 3   Album       262 non-null    object \n",
      " 4   Year        240 non-null    float64\n",
      " 5   Date        240 non-null    object \n",
      " 6   Lyric       328 non-null    object \n",
      "dtypes: float64(1), object(6)\n",
      "memory usage: 18.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataframe_entrainement = pd.read_csv('ColdPlay.csv')\n",
    "print(dataframe_entrainement.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "come up to meet you tell you i'm sorry you don't know how lovely you are i had to find you tell you i need you tell you i set you apart tell me your secrets and ask me your questions oh let's go back to the start running in circles coming up tails heads on a science apart   nobody said it was easy it's such a shame for us to part nobody said it was easy no one ever said it would be this hard oh take me back to the start   i was just guessing at numbers and figures pulling the puzzles apart questions of science science and progress do not speak as loud as my heart tell me you love me come back and haunt me oh and i rush to the start running in circles chasing our tails coming back as we are   nobody said it was easy oh it's such a shame for us to part nobody said it was easy no one ever said it would be so hard i'm going back to the start   ohooh oohoohoohooh ahooh oohoohoohooh ohooh oohoohoohooh ohooh oohoohoohooh chris martin i used to rule the world seas would rise when i gave the word now in the morning i sleep alone sweep the streets i used to own   chris martin i used to roll the dice feel the fear in my enemy's eyes listen as the crowd would sing now the old king is dead long live the king one minute i held the key next the walls were closed on me and i discovered that my castles stand upon pillars of salt and pillars of sand   chris martin i hear jerusalem bells are ringing roman cavalry choirs are singing be my mirror my sword and shield my missionaries in a foreign field for some reason i can't explain once you'd gone there was never never an honest word and that was when i ruled the world   chris martin it was the wicked and wild wind blew down the doors to let me in shattered windows and the sound of drums people couldn't believe what i'd become revolutionaries wait for my head on a silver plate just a puppet on a lonely string oh who would ever want to be king   chris martin i hear jerusalem bells are ringing roman cavalry choirs are singing be my mirror my sword and shield my missionaries in a foreign field for some reason i can't explain i know saint peter won't call my name never an honest word but that was when i ruled the world   will jonny guy brian ohohwoah ohoh oh ohohwoah ohoh oh ohohwoah ohoh oh ohohwoah ohoh oh  breakdown chris martin  will jonny guy  brian ohohwoah ohoh oh i hear jerusalem bells are ringing ohohwoah ohoh oh roman cavalry choirs are singing ohohwoah ohoh oh be my mirror my sword and shield ohohwoah ohoh oh my missionaries in a foreign field ohohwoah ohoh oh for some reason i can't explain ohohwoah ohoh oh i know saint peter won't call my name never an honest word but that was when i ruled the world   mmm mmm mmm mmm mmm mmm mmm mmm mmm mmm\n"
     ]
    }
   ],
   "source": [
    "texte_concatene = dataframe_entrainement.iloc[0:2]['Lyric'].str.cat(sep=' ')\n",
    "print(texte_concatene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    come up to meet you tell you i'm sorry you don...\n",
      "1    chris martin i used to rule the world seas wou...\n",
      "Name: Lyric, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dataframe_entrainement.iloc[0:2]['Lyric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['come', 'up', 'to', 'meet', 'you', 'tell', 'you', \"i'm\", 'sorry', 'you', \"don't\", 'know', 'how', 'lovely', 'you', 'are', 'i', 'had', 'to', 'find', 'you', 'tell', 'you', 'i', 'need', 'you', 'tell', 'you', 'i', 'set', 'you', 'apart', 'tell', 'me', 'your', 'secrets', 'and', 'ask', 'me', 'your', 'questions', 'oh', \"let's\", 'go', 'back', 'to', 'the', 'start', 'running', 'in', 'circles', 'coming', 'up', 'tails', 'heads', 'on', 'a', 'science', 'apart', '', '', 'nobody', 'said', 'it', 'was', 'easy', \"it's\", 'such', 'a', 'shame', 'for', 'us', 'to', 'part', 'nobody', 'said', 'it', 'was', 'easy', 'no', 'one', 'ever', 'said', 'it', 'would', 'be', 'this', 'hard', 'oh', 'take', 'me', 'back', 'to', 'the', 'start', '', '', 'i', 'was', 'just', 'guessing', 'at', 'numbers', 'and', 'figures', 'pulling', 'the', 'puzzles', 'apart', 'questions', 'of', 'science', 'science', 'and', 'progress', 'do', 'not', 'speak', 'as', 'loud', 'as', 'my', 'heart', 'tell', 'me', 'you', 'love', 'me', 'come', 'back', 'and', 'haunt', 'me', 'oh', 'and', 'i', 'rush', 'to', 'the', 'start', 'running', 'in', 'circles', 'chasing', 'our', 'tails', 'coming', 'back', 'as', 'we', 'are', '', '', 'nobody', 'said', 'it', 'was', 'easy', 'oh', \"it's\", 'such', 'a', 'shame', 'for', 'us', 'to', 'part', 'nobody', 'said', 'it', 'was', 'easy', 'no', 'one', 'ever', 'said', 'it', 'would', 'be', 'so', 'hard', \"i'm\", 'going', 'back', 'to', 'the', 'start', '', '', 'ohooh', 'oohoohoohooh', 'ahooh', 'oohoohoohooh', 'ohooh', 'oohoohoohooh', 'ohooh', 'oohoohoohooh', 'chris', 'martin', 'i', 'used', 'to', 'rule', 'the', 'world', 'seas', 'would', 'rise', 'when', 'i', 'gave', 'the', 'word', 'now', 'in', 'the', 'morning', 'i', 'sleep', 'alone', 'sweep', 'the', 'streets', 'i', 'used', 'to', 'own', '', '', 'chris', 'martin', 'i', 'used', 'to', 'roll', 'the', 'dice', 'feel', 'the', 'fear', 'in', 'my', \"enemy's\", 'eyes', 'listen', 'as', 'the', 'crowd', 'would', 'sing', 'now', 'the', 'old', 'king', 'is', 'dead', 'long', 'live', 'the', 'king', 'one', 'minute', 'i', 'held', 'the', 'key', 'next', 'the', 'walls', 'were', 'closed', 'on', 'me', 'and', 'i', 'discovered', 'that', 'my', 'castles', 'stand', 'upon', 'pillars', 'of', 'salt', 'and', 'pillars', 'of', 'sand', '', '', 'chris', 'martin', 'i', 'hear', 'jerusalem', 'bells', 'are', 'ringing', 'roman', 'cavalry', 'choirs', 'are', 'singing', 'be', 'my', 'mirror', 'my', 'sword', 'and', 'shield', 'my', 'missionaries', 'in', 'a', 'foreign', 'field', 'for', 'some', 'reason', 'i', \"can't\", 'explain', 'once', \"you'd\", 'gone', 'there', 'was', 'never', 'never', 'an', 'honest', 'word', 'and', 'that', 'was', 'when', 'i', 'ruled', 'the', 'world', '', '', 'chris', 'martin', 'it', 'was', 'the', 'wicked', 'and', 'wild', 'wind', 'blew', 'down', 'the', 'doors', 'to', 'let', 'me', 'in', 'shattered', 'windows', 'and', 'the', 'sound', 'of', 'drums', 'people', \"couldn't\", 'believe', 'what', \"i'd\", 'become', 'revolutionaries', 'wait', 'for', 'my', 'head', 'on', 'a', 'silver', 'plate', 'just', 'a', 'puppet', 'on', 'a', 'lonely', 'string', 'oh', 'who', 'would', 'ever', 'want', 'to', 'be', 'king', '', '', 'chris', 'martin', 'i', 'hear', 'jerusalem', 'bells', 'are', 'ringing', 'roman', 'cavalry', 'choirs', 'are', 'singing', 'be', 'my', 'mirror', 'my', 'sword', 'and', 'shield', 'my', 'missionaries', 'in', 'a', 'foreign', 'field', 'for', 'some', 'reason', 'i', \"can't\", 'explain', 'i', 'know', 'saint', 'peter', \"won't\", 'call', 'my', 'name', 'never', 'an', 'honest', 'word', 'but', 'that', 'was', 'when', 'i', 'ruled', 'the', 'world', '', '', 'will', 'jonny', 'guy', 'brian', 'ohohwoah', 'ohoh', 'oh', 'ohohwoah', 'ohoh', 'oh', 'ohohwoah', 'ohoh', 'oh', 'ohohwoah', 'ohoh', 'oh', '', 'breakdown', 'chris', 'martin', '', 'will', 'jonny', 'guy', '', 'brian', 'ohohwoah', 'ohoh', 'oh', 'i', 'hear', 'jerusalem', 'bells', 'are', 'ringing', 'ohohwoah', 'ohoh', 'oh', 'roman', 'cavalry', 'choirs', 'are', 'singing', 'ohohwoah', 'ohoh', 'oh', 'be', 'my', 'mirror', 'my', 'sword', 'and', 'shield', 'ohohwoah', 'ohoh', 'oh', 'my', 'missionaries', 'in', 'a', 'foreign', 'field', 'ohohwoah', 'ohoh', 'oh', 'for', 'some', 'reason', 'i', \"can't\", 'explain', 'ohohwoah', 'ohoh', 'oh', 'i', 'know', 'saint', 'peter', \"won't\", 'call', 'my', 'name', 'never', 'an', 'honest', 'word', 'but', 'that', 'was', 'when', 'i', 'ruled', 'the', 'world', '', '', 'mmm', 'mmm', 'mmm', 'mmm', 'mmm', 'mmm', 'mmm', 'mmm', 'mmm', 'mmm']\n"
     ]
    }
   ],
   "source": [
    "print(texte_concatene.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
