{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrainement sur  cpu\n",
      "-------- > epoch 0 lot 0 :  coût = 9.061922073364258\n",
      "Temps écoulé : 0m 0s\n",
      "-------- > epoch 0 lot 100 :  coût = 6.747535228729248\n",
      "Temps écoulé : 0m 5s\n",
      "-------- > epoch 0 lot 200 :  coût = 6.274324417114258\n",
      "Temps écoulé : 0m 10s\n",
      "-------- > epoch 0 lot 300 :  coût = 6.470521926879883\n",
      "Temps écoulé : 0m 15s\n",
      "-------- > epoch 0 lot 400 :  coût = 6.111426830291748\n",
      "Temps écoulé : 0m 19s\n",
      "-------- > epoch 0 lot 500 :  coût = 6.197742938995361\n",
      "Temps écoulé : 0m 25s\n",
      "-------- > epoch 0 lot 600 :  coût = 6.6435322761535645\n",
      "Temps écoulé : 0m 31s\n",
      "-------- > epoch 0 lot 700 :  coût = 5.55642557144165\n",
      "Temps écoulé : 0m 36s\n",
      "-------- > epoch 0 lot 800 :  coût = 5.485583305358887\n",
      "Temps écoulé : 0m 42s\n",
      "-------- > epoch 0 lot 900 :  coût = 5.166685581207275\n",
      "Temps écoulé : 0m 48s\n",
      "-------- > epoch 0 lot 1000 :  coût = 5.36018180847168\n",
      "Temps écoulé : 0m 53s\n",
      "-------- > epoch 0 lot 1100 :  coût = 5.8614654541015625\n",
      "Temps écoulé : 0m 60s\n",
      "-------- > epoch 0 lot 1200 :  coût = 6.3083367347717285\n",
      "Temps écoulé : 1m 6s\n",
      "-------- > epoch 0 lot 1300 :  coût = 7.156601428985596\n",
      "Temps écoulé : 1m 13s\n",
      "-------- > epoch 0 lot 1400 :  coût = 5.366923809051514\n",
      "Temps écoulé : 1m 20s\n",
      "-------- > epoch 0 lot 1500 :  coût = 6.027414321899414\n",
      "Temps écoulé : 1m 25s\n",
      "-------- > epoch 0 lot 1600 :  coût = 6.232086181640625\n",
      "Temps écoulé : 1m 31s\n",
      "-------- > epoch 0 lot 1700 :  coût = 6.529340744018555\n",
      "Temps écoulé : 1m 37s\n",
      "-------- > epoch 0 lot 1800 :  coût = 5.455472946166992\n",
      "Temps écoulé : 1m 43s\n",
      "-------- > epoch 0 lot 1900 :  coût = 5.581598281860352\n",
      "Temps écoulé : 1m 49s\n",
      "-------- > epoch 0 lot 2000 :  coût = 5.097315788269043\n",
      "Temps écoulé : 1m 56s\n",
      "-------- > epoch 0 lot 2100 :  coût = 5.900510787963867\n",
      "Temps écoulé : 2m 2s\n",
      "-------- > epoch 0 lot 2200 :  coût = 6.447957515716553\n",
      "Temps écoulé : 2m 8s\n",
      "-------- > epoch 0 lot 2300 :  coût = 6.078495979309082\n",
      "Temps écoulé : 2m 14s\n",
      "-------- > epoch 0 lot 2400 :  coût = 5.851760387420654\n",
      "Temps écoulé : 2m 19s\n",
      "-------- > epoch 0 lot 2500 :  coût = 5.781061172485352\n",
      "Temps écoulé : 2m 25s\n",
      "-------- > epoch 0 lot 2600 :  coût = 4.9612717628479\n",
      "Temps écoulé : 2m 30s\n",
      "-------- > epoch 0 lot 2700 :  coût = 5.38740873336792\n",
      "Temps écoulé : 2m 36s\n",
      "-------- > epoch 0 lot 2800 :  coût = 6.5232157707214355\n",
      "Temps écoulé : 2m 43s\n",
      "-------- > epoch 0 lot 2900 :  coût = 6.397550106048584\n",
      "Temps écoulé : 2m 49s\n",
      "-------- > epoch 0 lot 3000 :  coût = 5.247457027435303\n",
      "Temps écoulé : 2m 57s\n",
      "-------- > epoch 0 lot 3100 :  coût = 5.880369663238525\n",
      "Temps écoulé : 3m 3s\n",
      "-------- > epoch 0 lot 3200 :  coût = 5.480576038360596\n",
      "Temps écoulé : 3m 10s\n",
      "-------- > epoch 1 lot 0 :  coût = 6.378548622131348\n",
      "Temps écoulé : 3m 15s\n",
      "-------- > epoch 1 lot 100 :  coût = 5.002846717834473\n",
      "Temps écoulé : 3m 21s\n",
      "-------- > epoch 1 lot 200 :  coût = 5.132328033447266\n",
      "Temps écoulé : 3m 28s\n",
      "-------- > epoch 1 lot 300 :  coût = 5.413045406341553\n",
      "Temps écoulé : 3m 34s\n",
      "-------- > epoch 1 lot 400 :  coût = 4.685837268829346\n",
      "Temps écoulé : 3m 40s\n",
      "-------- > epoch 1 lot 500 :  coût = 5.0276713371276855\n",
      "Temps écoulé : 3m 46s\n",
      "-------- > epoch 1 lot 600 :  coût = 5.505253791809082\n",
      "Temps écoulé : 3m 52s\n",
      "-------- > epoch 1 lot 700 :  coût = 4.7060723304748535\n",
      "Temps écoulé : 3m 58s\n",
      "-------- > epoch 1 lot 800 :  coût = 4.606042385101318\n",
      "Temps écoulé : 4m 6s\n",
      "-------- > epoch 1 lot 900 :  coût = 4.261806488037109\n",
      "Temps écoulé : 4m 12s\n",
      "-------- > epoch 1 lot 1000 :  coût = 4.628521919250488\n",
      "Temps écoulé : 4m 18s\n",
      "-------- > epoch 1 lot 1100 :  coût = 5.1586079597473145\n",
      "Temps écoulé : 4m 24s\n",
      "-------- > epoch 1 lot 1200 :  coût = 5.509314060211182\n",
      "Temps écoulé : 4m 30s\n",
      "-------- > epoch 1 lot 1300 :  coût = 5.6907830238342285\n",
      "Temps écoulé : 4m 35s\n",
      "-------- > epoch 1 lot 1400 :  coût = 4.575373649597168\n",
      "Temps écoulé : 4m 41s\n",
      "-------- > epoch 1 lot 1500 :  coût = 5.363641738891602\n",
      "Temps écoulé : 4m 47s\n",
      "-------- > epoch 1 lot 1600 :  coût = 5.308947563171387\n",
      "Temps écoulé : 4m 52s\n",
      "-------- > epoch 1 lot 1700 :  coût = 5.805184841156006\n",
      "Temps écoulé : 4m 58s\n",
      "-------- > epoch 1 lot 1800 :  coût = 4.7324323654174805\n",
      "Temps écoulé : 5m 3s\n",
      "-------- > epoch 1 lot 1900 :  coût = 4.973713397979736\n",
      "Temps écoulé : 5m 10s\n",
      "-------- > epoch 1 lot 2000 :  coût = 4.532248020172119\n",
      "Temps écoulé : 5m 16s\n",
      "-------- > epoch 1 lot 2100 :  coût = 5.1932759284973145\n",
      "Temps écoulé : 5m 22s\n",
      "-------- > epoch 1 lot 2200 :  coût = 5.596592426300049\n",
      "Temps écoulé : 5m 28s\n",
      "-------- > epoch 1 lot 2300 :  coût = 5.391263961791992\n",
      "Temps écoulé : 5m 34s\n",
      "-------- > epoch 1 lot 2400 :  coût = 5.314584732055664\n",
      "Temps écoulé : 5m 40s\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Réseau de neurones récurrent, modèle de langue par mot, pour livres de Sherlock Holmes\n",
    "Version avec couche vectorisation de mots et RNN\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(0) # Pour résultats reproductibles\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "taille_sequence = 8\n",
    "nombre_textes = 5000\n",
    "\n",
    "# Déterminer si un GPU est disponible\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Entrainement sur ',device)\n",
    "\n",
    "class DatasetSherlockHolmes(torch.utils.data.Dataset):\n",
    "    \"\"\" Créer un Dataset avec les paroles de la colonne Lyric du fichier nom_fichier\n",
    "    taille_sequence : taille d'une séquence de mots pour le modèle de langue\n",
    "    Le texte est découpé en séquences de la taille taille_sequence\n",
    "    \"\"\"\n",
    "    def __init__(self, taille_sequence=4,):\n",
    "        self.taille_sequence = taille_sequence\n",
    "        self.mots = self.charger_mots()\n",
    "        self.mots_uniques = self.chercher_mots_uniques()\n",
    "\n",
    "        self.index_a_mot = {index: mot for index, mot in enumerate(self.mots_uniques)}\n",
    "        self.mot_a_index = {mot: index for index, mot in enumerate(self.mots_uniques)}\n",
    "\n",
    "        self.mots_indexes = [self.mot_a_index[w] for w in self.mots]\n",
    "\n",
    "    def charger_mots(self):\n",
    "        with open('SherlockHolmes.txt') as f: \n",
    "            texte = f.read()\n",
    "        return re.sub(r'[^\\w\\s]', '', texte).lower().split()\n",
    "\n",
    "    def chercher_mots_uniques(self):\n",
    "        frequence_mot = Counter(self.mots)\n",
    "        return sorted(frequence_mot, key=frequence_mot.get, reverse=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mots_indexes) - self.taille_sequence\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            torch.tensor(self.mots_indexes[index:index+self.taille_sequence]),\n",
    "            torch.tensor(self.mots_indexes[index+1:index+self.taille_sequence+1]),\n",
    "        )\n",
    "    \n",
    "class Modele(nn.Module):\n",
    "    \"\"\"Modèle de RNR avec une couche vectorisation, suivie d'une couche RNN et d'une couche linéaire\"\"\"\n",
    "    def __init__(self, ds_paroles):\n",
    "        super(Modele, self).__init__()\n",
    "        self.taille_H_RNN = 128\n",
    "        self.taille_vectorisation_mots = 64\n",
    "        self.nombre_couches_RNR = 1\n",
    "\n",
    "        taille_vocabulaire = len(ds_paroles.mots_uniques)\n",
    "        self.vectorisation_mots = nn.Embedding(num_embeddings=taille_vocabulaire,\n",
    "            embedding_dim=self.taille_vectorisation_mots)\n",
    "        self.rnn = nn.RNN(input_size=self.taille_vectorisation_mots,hidden_size=self.taille_H_RNN,\n",
    "            num_layers=self.nombre_couches_RNR,batch_first=True)\n",
    "        self.dense_linaire = nn.Linear(self.taille_H_RNN, taille_vocabulaire)\n",
    "\n",
    "    def forward(self, lot_X, etat_0):\n",
    "        vectorisation = self.vectorisation_mots(lot_X)\n",
    "        lot_Ht, etat = self.rnn(vectorisation, etat_0)\n",
    "        lot_Yt = self.dense_linaire(lot_Ht)\n",
    "        return lot_Yt, etat\n",
    "\n",
    "    def initializer_etat(self, taille_sequence):\n",
    "        return (torch.zeros(self.nombre_couches_RNR, taille_sequence, self.taille_H_RNN))\n",
    "\n",
    "ds_paroles = DatasetSherlockHolmes(taille_sequence=taille_sequence)\n",
    "modele = Modele(ds_paroles)\n",
    "# Placer le modèle en mode GPU si possible\n",
    "modele = modele.to(device)\n",
    "    \n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "def entrainer_RNR(ds_paroles, modele, taille_lot=32, epochs=5, taille_sequence=6):\n",
    "    debut = time.time()\n",
    "    modele.train()\n",
    "    dl_paroles = DataLoader(ds_paroles,batch_size=taille_lot)\n",
    "\n",
    "    fonction_cout = nn.CrossEntropyLoss()\n",
    "    optimizeur = optim.Adam(modele.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        for lot, (lot_X, lot_Y) in enumerate(dl_paroles):\n",
    "            lot_X = lot_X.to(device)\n",
    "            lot_Y = lot_Y.to(device)\n",
    "            etat = modele.initializer_etat(lot_X.shape[0])\n",
    "            etat = etat.to(device)\n",
    "            optimizeur.zero_grad()\n",
    "            \n",
    "            lot_Y_predictions, etat = modele(lot_X, etat)\n",
    "            cout = fonction_cout(lot_Y_predictions.transpose(1, 2), lot_Y)\n",
    "            \n",
    "            cout.backward()\n",
    "            optimizeur.step()\n",
    "            if lot%100 == 0:\n",
    "                print(f'-------- > epoch {epoch} lot {lot} :  coût = {cout.item()}')\n",
    "                temps_ecoule = time.time() - debut\n",
    "                print('Temps écoulé : {:.0f}m {:.0f}s'.format(temps_ecoule // 60, temps_ecoule % 60))\n",
    "\n",
    "\n",
    "def predire(ds, modele, debut_texte, nb_mots=20, mode =0):\n",
    "    \"\"\" Prédire une suite de nb_mots à partir de debut_texte selon le modele\"\"\"\n",
    "\n",
    "    mots = debut_texte.split(' ')\n",
    "    modele.eval()\n",
    "    etat = modele.initializer_etat(1)\n",
    "    etat = etat.to(device)\n",
    "    for i in range(0, nb_mots):\n",
    "        lot_X = torch.tensor([[ds.mot_a_index[m] for m in mots[i:]]])\n",
    "        lot_X = lot_X.to(device)\n",
    "        lot_Y_predictions, etat = modele(lot_X, etat)\n",
    "        dernier_mot_Yt = lot_Y_predictions[0][-1]\n",
    "        probs_dernier_mot = torch.nn.functional.softmax(dernier_mot_Yt, dim=0).data\n",
    "        if mode == 0 :\n",
    "            index_mot_choisi = torch.max(probs_dernier_mot, dim=0)[1].item()\n",
    "        else :\n",
    "            index_mot_choisi = torch.multinomial(probs_dernier_mot, 1)[0].item()\n",
    "        mots.append(ds.index_a_mot[index_mot_choisi])\n",
    "    return mots\n",
    "\n",
    "entrainer_RNR(ds_paroles, modele, taille_lot=32, epochs=5, taille_sequence=taille_sequence)\n",
    "print(\"Texte stochastique 1 :\",predire(ds_paroles, modele, debut_texte='elementary ', mode = 1))\n",
    "print(\"Texte stochastique 2 :\",predire(ds_paroles, modele, debut_texte='elementary', mode = 1))\n",
    "print(\"Texte stochastique 3 :\",predire(ds_paroles, modele, debut_texte='elementary', mode = 1))\n",
    "print(\"Texte max :\",predire(ds_paroles, modele, debut_texte='elementary', mode = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "610921"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('SherlockHolmes.txt') as f: \n",
    "    texte = f.read()\n",
    "len(texte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'adventures',\n",
       " 'of',\n",
       " 'sherlock',\n",
       " 'holmes',\n",
       " 'arthur',\n",
       " 'conan',\n",
       " 'doyle',\n",
       " 'table',\n",
       " 'of',\n",
       " 'contents',\n",
       " 'a',\n",
       " 'scandal',\n",
       " 'in',\n",
       " 'bohemia',\n",
       " 'the',\n",
       " 'redheaded',\n",
       " 'league',\n",
       " 'a',\n",
       " 'case',\n",
       " 'of',\n",
       " 'identity',\n",
       " 'the',\n",
       " 'boscombe',\n",
       " 'valley',\n",
       " 'mystery',\n",
       " 'the',\n",
       " 'five',\n",
       " 'orange',\n",
       " 'pips',\n",
       " 'the',\n",
       " 'man',\n",
       " 'with',\n",
       " 'the',\n",
       " 'twisted',\n",
       " 'lip',\n",
       " 'the',\n",
       " 'adventure',\n",
       " 'of',\n",
       " 'the',\n",
       " 'blue',\n",
       " 'carbuncle',\n",
       " 'the',\n",
       " 'adventure',\n",
       " 'of',\n",
       " 'the',\n",
       " 'speckled',\n",
       " 'band',\n",
       " 'the',\n",
       " 'adventure',\n",
       " 'of',\n",
       " 'the',\n",
       " 'engineers',\n",
       " 'thumb',\n",
       " 'the',\n",
       " 'adventure',\n",
       " 'of',\n",
       " 'the',\n",
       " 'noble',\n",
       " 'bachelor',\n",
       " 'the',\n",
       " 'adventure',\n",
       " 'of',\n",
       " 'the',\n",
       " 'beryl',\n",
       " 'coronet',\n",
       " 'the',\n",
       " 'adventure',\n",
       " 'of',\n",
       " 'the',\n",
       " 'copper',\n",
       " 'beeches',\n",
       " 'a',\n",
       " 'scandal',\n",
       " 'in',\n",
       " 'bohemia',\n",
       " 'table',\n",
       " 'of',\n",
       " 'contents',\n",
       " 'chapter',\n",
       " '1',\n",
       " 'chapter',\n",
       " '2',\n",
       " 'chapter',\n",
       " '3',\n",
       " 'chapter',\n",
       " 'i',\n",
       " 'to',\n",
       " 'sherlock',\n",
       " 'holmes',\n",
       " 'she',\n",
       " 'is',\n",
       " 'always',\n",
       " 'the',\n",
       " 'woman',\n",
       " 'i',\n",
       " 'have',\n",
       " 'seldom',\n",
       " 'heard',\n",
       " 'him',\n",
       " 'mention',\n",
       " 'her',\n",
       " 'under',\n",
       " 'any',\n",
       " 'other',\n",
       " 'name',\n",
       " 'in',\n",
       " 'his',\n",
       " 'eyes',\n",
       " 'she',\n",
       " 'eclipses',\n",
       " 'and',\n",
       " 'predominates',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'of',\n",
       " 'her',\n",
       " 'sex',\n",
       " 'it',\n",
       " 'was',\n",
       " 'not',\n",
       " 'that',\n",
       " 'he',\n",
       " 'felt',\n",
       " 'any',\n",
       " 'emotion',\n",
       " 'akin',\n",
       " 'to',\n",
       " 'love',\n",
       " 'for',\n",
       " 'irene',\n",
       " 'adler',\n",
       " 'all',\n",
       " 'emotions',\n",
       " 'and',\n",
       " 'that',\n",
       " 'one',\n",
       " 'particularly',\n",
       " 'were',\n",
       " 'abhorrent',\n",
       " 'to',\n",
       " 'his',\n",
       " 'cold',\n",
       " 'precise',\n",
       " 'but',\n",
       " 'admirably',\n",
       " 'balanced',\n",
       " 'mind',\n",
       " 'he',\n",
       " 'was',\n",
       " 'i',\n",
       " 'take',\n",
       " 'it',\n",
       " 'the',\n",
       " 'most',\n",
       " 'perfect',\n",
       " 'reasoning',\n",
       " 'and',\n",
       " 'observing',\n",
       " 'machine',\n",
       " 'that',\n",
       " 'the',\n",
       " 'world',\n",
       " 'has',\n",
       " 'seen',\n",
       " 'but',\n",
       " 'as',\n",
       " 'a',\n",
       " 'lover',\n",
       " 'he',\n",
       " 'would',\n",
       " 'have',\n",
       " 'placed',\n",
       " 'himself',\n",
       " 'in',\n",
       " 'a',\n",
       " 'false',\n",
       " 'position',\n",
       " 'he',\n",
       " 'never',\n",
       " 'spoke',\n",
       " 'of',\n",
       " 'the',\n",
       " 'softer',\n",
       " 'passions',\n",
       " 'save',\n",
       " 'with',\n",
       " 'a',\n",
       " 'gibe',\n",
       " 'and',\n",
       " 'a',\n",
       " 'sneer',\n",
       " 'they',\n",
       " 'were',\n",
       " 'admirable',\n",
       " 'things',\n",
       " 'for',\n",
       " 'the',\n",
       " 'observerexcellent',\n",
       " 'for',\n",
       " 'drawing',\n",
       " 'the',\n",
       " 'veil',\n",
       " 'from',\n",
       " 'mens',\n",
       " 'motives',\n",
       " 'and',\n",
       " 'actions',\n",
       " 'but',\n",
       " 'for',\n",
       " 'the',\n",
       " 'trained',\n",
       " 'reasoner',\n",
       " 'to',\n",
       " 'admit',\n",
       " 'such',\n",
       " 'intrusions',\n",
       " 'into',\n",
       " 'his',\n",
       " 'own',\n",
       " 'delicate',\n",
       " 'and',\n",
       " 'finely',\n",
       " 'adjusted',\n",
       " 'temperament',\n",
       " 'was',\n",
       " 'to',\n",
       " 'introduce',\n",
       " 'a',\n",
       " 'distracting',\n",
       " 'factor',\n",
       " 'which',\n",
       " 'might',\n",
       " 'throw',\n",
       " 'a',\n",
       " 'doubt',\n",
       " 'upon',\n",
       " 'all',\n",
       " 'his',\n",
       " 'mental',\n",
       " 'results',\n",
       " 'grit',\n",
       " 'in',\n",
       " 'a',\n",
       " 'sensitive',\n",
       " 'instrument',\n",
       " 'or',\n",
       " 'a',\n",
       " 'crack',\n",
       " 'in',\n",
       " 'one',\n",
       " 'of',\n",
       " 'his',\n",
       " 'own',\n",
       " 'highpower',\n",
       " 'lenses',\n",
       " 'would',\n",
       " 'not',\n",
       " 'be',\n",
       " 'more',\n",
       " 'disturbing',\n",
       " 'than',\n",
       " 'a',\n",
       " 'strong',\n",
       " 'emotion',\n",
       " 'in',\n",
       " 'a',\n",
       " 'nature',\n",
       " 'such',\n",
       " 'as',\n",
       " 'his',\n",
       " 'and',\n",
       " 'yet',\n",
       " 'there',\n",
       " 'was',\n",
       " 'but',\n",
       " 'one',\n",
       " 'woman',\n",
       " 'to',\n",
       " 'him',\n",
       " 'and',\n",
       " 'that',\n",
       " 'woman',\n",
       " 'was',\n",
       " 'the',\n",
       " 'late',\n",
       " 'irene',\n",
       " 'adler',\n",
       " 'of',\n",
       " 'dubious',\n",
       " 'and',\n",
       " 'questionable',\n",
       " 'memory',\n",
       " 'i',\n",
       " 'had',\n",
       " 'seen',\n",
       " 'little',\n",
       " 'of',\n",
       " 'holmes',\n",
       " 'lately',\n",
       " 'my',\n",
       " 'marriage',\n",
       " 'had',\n",
       " 'drifted',\n",
       " 'us',\n",
       " 'away',\n",
       " 'from',\n",
       " 'each',\n",
       " 'other',\n",
       " 'my',\n",
       " 'own',\n",
       " 'complete',\n",
       " 'happiness',\n",
       " 'and',\n",
       " 'the',\n",
       " 'homecentred',\n",
       " 'interests',\n",
       " 'which',\n",
       " 'rise',\n",
       " 'up',\n",
       " 'around',\n",
       " 'the',\n",
       " 'man',\n",
       " 'who',\n",
       " 'first',\n",
       " 'finds',\n",
       " 'himself',\n",
       " 'master',\n",
       " 'of',\n",
       " 'his',\n",
       " 'own',\n",
       " 'establishment',\n",
       " 'were',\n",
       " 'sufficient',\n",
       " 'to',\n",
       " 'absorb',\n",
       " 'all',\n",
       " 'my',\n",
       " 'attention',\n",
       " 'while',\n",
       " 'holmes',\n",
       " 'who',\n",
       " 'loathed',\n",
       " 'every',\n",
       " 'form',\n",
       " 'of',\n",
       " 'society',\n",
       " 'with',\n",
       " 'his',\n",
       " 'whole',\n",
       " 'bohemian',\n",
       " 'soul',\n",
       " 'remained',\n",
       " 'in',\n",
       " 'our',\n",
       " 'lodgings',\n",
       " 'in',\n",
       " 'baker',\n",
       " 'street',\n",
       " 'buried',\n",
       " 'among',\n",
       " 'his',\n",
       " 'old',\n",
       " 'books',\n",
       " 'and',\n",
       " 'alternating',\n",
       " 'from',\n",
       " 'week',\n",
       " 'to',\n",
       " 'week',\n",
       " 'between',\n",
       " 'cocaine',\n",
       " 'and',\n",
       " 'ambition',\n",
       " 'the',\n",
       " 'drowsiness',\n",
       " 'of',\n",
       " 'the',\n",
       " 'drug',\n",
       " 'and',\n",
       " 'the',\n",
       " 'fierce',\n",
       " 'energy',\n",
       " 'of',\n",
       " 'his',\n",
       " 'own',\n",
       " 'keen',\n",
       " 'nature',\n",
       " 'he',\n",
       " 'was',\n",
       " 'still',\n",
       " 'as',\n",
       " 'ever',\n",
       " 'deeply',\n",
       " 'attracted',\n",
       " 'by',\n",
       " 'the',\n",
       " 'study',\n",
       " 'of',\n",
       " 'crime',\n",
       " 'and',\n",
       " 'occupied',\n",
       " 'his',\n",
       " 'immense',\n",
       " 'faculties',\n",
       " 'and',\n",
       " 'extraordinary',\n",
       " 'powers',\n",
       " 'of',\n",
       " 'observation',\n",
       " 'in',\n",
       " 'following',\n",
       " 'out',\n",
       " 'those',\n",
       " 'clues',\n",
       " 'and',\n",
       " 'clearing',\n",
       " 'up',\n",
       " 'those',\n",
       " 'mysteries',\n",
       " 'which',\n",
       " 'had',\n",
       " 'been',\n",
       " 'abandoned',\n",
       " 'as',\n",
       " 'hopeless',\n",
       " 'by',\n",
       " 'the',\n",
       " 'official',\n",
       " 'police',\n",
       " 'from',\n",
       " 'time',\n",
       " 'to',\n",
       " 'time',\n",
       " 'i',\n",
       " 'heard',\n",
       " 'some',\n",
       " 'vague',\n",
       " 'account',\n",
       " 'of',\n",
       " 'his',\n",
       " 'doings',\n",
       " 'of',\n",
       " 'his',\n",
       " 'summons',\n",
       " 'to',\n",
       " 'odessa',\n",
       " 'in',\n",
       " 'the',\n",
       " 'case',\n",
       " 'of',\n",
       " 'the',\n",
       " 'trepoff',\n",
       " 'murder',\n",
       " 'of',\n",
       " 'his',\n",
       " 'clearing',\n",
       " 'up',\n",
       " 'of',\n",
       " 'the',\n",
       " 'singular',\n",
       " 'tragedy',\n",
       " 'of',\n",
       " 'the',\n",
       " 'atkinson',\n",
       " 'brothers',\n",
       " 'at',\n",
       " 'trincomalee',\n",
       " 'and',\n",
       " 'finally',\n",
       " 'of',\n",
       " 'the',\n",
       " 'mission',\n",
       " 'which',\n",
       " 'he',\n",
       " 'had',\n",
       " 'accomplished',\n",
       " 'so',\n",
       " 'delicately',\n",
       " 'and',\n",
       " 'successfully',\n",
       " 'for',\n",
       " 'the',\n",
       " 'reigning',\n",
       " 'family',\n",
       " 'of',\n",
       " 'holland',\n",
       " 'beyond',\n",
       " 'these',\n",
       " 'signs',\n",
       " 'of',\n",
       " 'his',\n",
       " 'activity',\n",
       " 'however',\n",
       " 'which',\n",
       " 'i',\n",
       " 'merely',\n",
       " 'shared',\n",
       " 'with',\n",
       " 'all',\n",
       " 'the',\n",
       " 'readers',\n",
       " 'of',\n",
       " 'the',\n",
       " 'daily',\n",
       " 'press',\n",
       " 'i',\n",
       " 'knew',\n",
       " 'little',\n",
       " 'of',\n",
       " 'my',\n",
       " 'former',\n",
       " 'friend',\n",
       " 'and',\n",
       " 'companion',\n",
       " 'one',\n",
       " 'nightit',\n",
       " 'was',\n",
       " 'on',\n",
       " 'the',\n",
       " 'twentieth',\n",
       " 'of',\n",
       " 'march',\n",
       " '1888i',\n",
       " 'was',\n",
       " 'returning',\n",
       " 'from',\n",
       " 'a',\n",
       " 'journey',\n",
       " 'to',\n",
       " 'a',\n",
       " 'patient',\n",
       " 'for',\n",
       " 'i',\n",
       " 'had',\n",
       " 'now',\n",
       " 'returned',\n",
       " 'to',\n",
       " 'civil',\n",
       " 'practice',\n",
       " 'when',\n",
       " 'my',\n",
       " 'way',\n",
       " 'led',\n",
       " 'me',\n",
       " 'through',\n",
       " 'baker',\n",
       " 'street',\n",
       " 'as',\n",
       " 'i',\n",
       " 'passed',\n",
       " 'the',\n",
       " 'wellremembered',\n",
       " 'door',\n",
       " 'which',\n",
       " 'must',\n",
       " 'always',\n",
       " 'be',\n",
       " 'associated',\n",
       " 'in',\n",
       " 'my',\n",
       " 'mind',\n",
       " 'with',\n",
       " 'my',\n",
       " 'wooing',\n",
       " 'and',\n",
       " 'with',\n",
       " 'the',\n",
       " 'dark',\n",
       " 'incidents',\n",
       " 'of',\n",
       " 'the',\n",
       " 'study',\n",
       " 'in',\n",
       " 'scarlet',\n",
       " 'i',\n",
       " 'was',\n",
       " 'seized',\n",
       " 'with',\n",
       " 'a',\n",
       " 'keen',\n",
       " 'desire',\n",
       " 'to',\n",
       " 'see',\n",
       " 'holmes',\n",
       " 'again',\n",
       " 'and',\n",
       " 'to',\n",
       " 'know',\n",
       " 'how',\n",
       " 'he',\n",
       " 'was',\n",
       " 'employing',\n",
       " 'his',\n",
       " 'extraordinary',\n",
       " 'powers',\n",
       " 'his',\n",
       " 'rooms',\n",
       " 'were',\n",
       " 'brilliantly',\n",
       " 'lit',\n",
       " 'and',\n",
       " 'even',\n",
       " 'as',\n",
       " 'i',\n",
       " 'looked',\n",
       " 'up',\n",
       " 'i',\n",
       " 'saw',\n",
       " 'his',\n",
       " 'tall',\n",
       " 'spare',\n",
       " 'figure',\n",
       " 'pass',\n",
       " 'twice',\n",
       " 'in',\n",
       " 'a',\n",
       " 'dark',\n",
       " 'silhouette',\n",
       " 'against',\n",
       " 'the',\n",
       " 'blind',\n",
       " 'he',\n",
       " 'was',\n",
       " 'pacing',\n",
       " 'the',\n",
       " 'room',\n",
       " 'swiftly',\n",
       " 'eagerly',\n",
       " 'with',\n",
       " 'his',\n",
       " 'head',\n",
       " 'sunk',\n",
       " 'upon',\n",
       " 'his',\n",
       " 'chest',\n",
       " 'and',\n",
       " 'his',\n",
       " 'hands',\n",
       " 'clasped',\n",
       " 'behind',\n",
       " 'him',\n",
       " 'to',\n",
       " 'me',\n",
       " 'who',\n",
       " 'knew',\n",
       " 'his',\n",
       " 'every',\n",
       " 'mood',\n",
       " 'and',\n",
       " 'habit',\n",
       " 'his',\n",
       " 'attitude',\n",
       " 'and',\n",
       " 'manner',\n",
       " 'told',\n",
       " 'their',\n",
       " 'own',\n",
       " 'story',\n",
       " 'he',\n",
       " 'was',\n",
       " 'at',\n",
       " 'work',\n",
       " 'again',\n",
       " 'he',\n",
       " 'had',\n",
       " 'risen',\n",
       " 'out',\n",
       " 'of',\n",
       " 'his',\n",
       " 'drugcreated',\n",
       " 'dreams',\n",
       " 'and',\n",
       " 'was',\n",
       " 'hot',\n",
       " 'upon',\n",
       " 'the',\n",
       " 'scent',\n",
       " 'of',\n",
       " 'some',\n",
       " 'new',\n",
       " 'problem',\n",
       " 'i',\n",
       " 'rang',\n",
       " 'the',\n",
       " 'bell',\n",
       " 'and',\n",
       " 'was',\n",
       " 'shown',\n",
       " 'up',\n",
       " 'to',\n",
       " 'the',\n",
       " 'chamber',\n",
       " 'which',\n",
       " 'had',\n",
       " 'formerly',\n",
       " 'been',\n",
       " 'in',\n",
       " 'part',\n",
       " 'my',\n",
       " 'own',\n",
       " 'his',\n",
       " 'manner',\n",
       " 'was',\n",
       " 'not',\n",
       " 'effusive',\n",
       " 'it',\n",
       " 'seldom',\n",
       " 'was',\n",
       " 'but',\n",
       " 'he',\n",
       " 'was',\n",
       " 'glad',\n",
       " 'i',\n",
       " 'think',\n",
       " 'to',\n",
       " 'see',\n",
       " 'me',\n",
       " 'with',\n",
       " 'hardly',\n",
       " 'a',\n",
       " 'word',\n",
       " 'spoken',\n",
       " 'but',\n",
       " 'with',\n",
       " 'a',\n",
       " 'kindly',\n",
       " 'eye',\n",
       " 'he',\n",
       " 'waved',\n",
       " 'me',\n",
       " 'to',\n",
       " 'an',\n",
       " 'armchair',\n",
       " 'threw',\n",
       " 'across',\n",
       " 'his',\n",
       " 'case',\n",
       " 'of',\n",
       " 'cigars',\n",
       " 'and',\n",
       " 'indicated',\n",
       " 'a',\n",
       " 'spirit',\n",
       " 'case',\n",
       " 'and',\n",
       " 'a',\n",
       " 'gasogene',\n",
       " 'in',\n",
       " 'the',\n",
       " 'corner',\n",
       " 'then',\n",
       " 'he',\n",
       " 'stood',\n",
       " 'before',\n",
       " 'the',\n",
       " 'fire',\n",
       " 'and',\n",
       " 'looked',\n",
       " 'me',\n",
       " 'over',\n",
       " 'in',\n",
       " 'his',\n",
       " 'singular',\n",
       " 'introspective',\n",
       " 'fashion',\n",
       " 'wedlock',\n",
       " 'suits',\n",
       " 'you',\n",
       " 'he',\n",
       " 'remarked',\n",
       " 'i',\n",
       " 'think',\n",
       " 'watson',\n",
       " 'that',\n",
       " 'you',\n",
       " 'have',\n",
       " 'put',\n",
       " 'on',\n",
       " 'seven',\n",
       " 'and',\n",
       " 'a',\n",
       " 'half',\n",
       " 'pounds',\n",
       " 'since',\n",
       " 'i',\n",
       " 'saw',\n",
       " 'you',\n",
       " 'seven',\n",
       " 'i',\n",
       " 'answered',\n",
       " 'indeed',\n",
       " 'i',\n",
       " 'should',\n",
       " 'have',\n",
       " 'thought',\n",
       " 'a',\n",
       " 'little',\n",
       " 'more',\n",
       " 'just',\n",
       " 'a',\n",
       " 'trifle',\n",
       " 'more',\n",
       " 'i',\n",
       " 'fancy',\n",
       " 'watson',\n",
       " 'and',\n",
       " 'in',\n",
       " 'practice',\n",
       " 'again',\n",
       " 'i',\n",
       " 'observe',\n",
       " 'you',\n",
       " 'did',\n",
       " 'not',\n",
       " 'tell',\n",
       " 'me',\n",
       " 'that',\n",
       " 'you',\n",
       " 'intended',\n",
       " 'to',\n",
       " 'go',\n",
       " 'into',\n",
       " 'harness',\n",
       " 'then',\n",
       " 'how',\n",
       " 'do',\n",
       " 'you',\n",
       " 'know',\n",
       " 'i',\n",
       " 'see',\n",
       " 'it',\n",
       " 'i',\n",
       " 'deduce',\n",
       " 'it',\n",
       " 'how',\n",
       " 'do',\n",
       " 'i',\n",
       " 'know',\n",
       " 'that',\n",
       " 'you',\n",
       " 'have',\n",
       " 'been',\n",
       " 'getting',\n",
       " 'yourself',\n",
       " 'very',\n",
       " 'wet',\n",
       " 'lately',\n",
       " 'and',\n",
       " 'that',\n",
       " 'you',\n",
       " 'have',\n",
       " 'a',\n",
       " 'most',\n",
       " 'clumsy',\n",
       " 'and',\n",
       " 'careless',\n",
       " 'servant',\n",
       " 'girl',\n",
       " 'my',\n",
       " 'dear',\n",
       " 'holmes',\n",
       " 'said',\n",
       " 'i',\n",
       " 'this',\n",
       " 'is',\n",
       " 'too',\n",
       " 'much',\n",
       " 'you',\n",
       " 'would',\n",
       " 'certainly',\n",
       " 'have',\n",
       " 'been',\n",
       " 'burned',\n",
       " 'had',\n",
       " 'you',\n",
       " 'lived',\n",
       " 'a',\n",
       " 'few',\n",
       " 'centuries',\n",
       " 'ago',\n",
       " 'it',\n",
       " 'is',\n",
       " 'true',\n",
       " 'that',\n",
       " 'i',\n",
       " 'had',\n",
       " 'a',\n",
       " 'country',\n",
       " 'walk',\n",
       " 'on',\n",
       " 'thursday',\n",
       " 'and',\n",
       " 'came',\n",
       " 'home',\n",
       " 'in',\n",
       " 'a',\n",
       " 'dreadful',\n",
       " 'mess',\n",
       " 'but',\n",
       " 'as',\n",
       " 'i',\n",
       " 'have',\n",
       " 'changed',\n",
       " 'my',\n",
       " 'clothes',\n",
       " 'i',\n",
       " 'cant',\n",
       " 'imagine',\n",
       " 'how',\n",
       " 'you',\n",
       " 'deduce',\n",
       " 'it',\n",
       " 'as',\n",
       " 'to',\n",
       " 'mary',\n",
       " 'jane',\n",
       " 'she',\n",
       " 'is',\n",
       " 'incorrigible',\n",
       " 'and',\n",
       " 'my',\n",
       " 'wife',\n",
       " 'has',\n",
       " 'given',\n",
       " 'her',\n",
       " 'notice',\n",
       " 'but',\n",
       " 'there',\n",
       " 'again',\n",
       " 'i',\n",
       " 'fail',\n",
       " 'to',\n",
       " 'see',\n",
       " 'how',\n",
       " 'you',\n",
       " 'work',\n",
       " 'it',\n",
       " 'out',\n",
       " 'he',\n",
       " 'chuckled',\n",
       " 'to',\n",
       " 'himself',\n",
       " 'and',\n",
       " 'rubbed',\n",
       " 'his',\n",
       " 'long',\n",
       " 'nervous',\n",
       " 'hands',\n",
       " 'together',\n",
       " 'it',\n",
       " 'is',\n",
       " 'simplicity',\n",
       " 'itself',\n",
       " 'said',\n",
       " 'he',\n",
       " 'my',\n",
       " 'eyes',\n",
       " 'tell',\n",
       " 'me',\n",
       " 'that',\n",
       " 'on',\n",
       " 'the',\n",
       " 'inside',\n",
       " 'of',\n",
       " 'your',\n",
       " 'left',\n",
       " 'shoe',\n",
       " 'just',\n",
       " 'where',\n",
       " 'the',\n",
       " 'firelight',\n",
       " 'strikes',\n",
       " 'it',\n",
       " 'the',\n",
       " 'leather',\n",
       " 'is',\n",
       " 'scored',\n",
       " 'by',\n",
       " 'six',\n",
       " 'almost',\n",
       " 'parallel',\n",
       " 'cuts',\n",
       " 'obviously',\n",
       " 'they',\n",
       " 'have',\n",
       " 'been',\n",
       " 'caused',\n",
       " 'by',\n",
       " 'someone',\n",
       " 'who',\n",
       " 'has',\n",
       " 'very',\n",
       " 'carelessly',\n",
       " 'scraped',\n",
       " 'round',\n",
       " 'the',\n",
       " 'edges',\n",
       " 'of',\n",
       " 'the',\n",
       " ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.sub(r'[^\\w\\s]', '', texte).lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'texte_concatene' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-dfd65d839338>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexte_concatene\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'texte_concatene' is not defined"
     ]
    }
   ],
   "source": [
    "print(texte_concatene.lower().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texte_concatene = dataframe_entrainement[(dataframe_entrainement['language'] == 'en')].iloc[0:2]['Lyric'].str.cat(sep=' ')\n",
    "re.sub(r'[^\\w\\s]', '', texte_concatene).lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_paroles = DatasetSherlockHolmes(taille_sequence=taille_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_paroles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
