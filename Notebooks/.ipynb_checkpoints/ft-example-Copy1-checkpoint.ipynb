{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be94e6d6-4096-4d1a-aa58-5afd89f33bff",
   "metadata": {},
   "source": [
    "# Exemple de réglage fin avec la stratégie LoRA sur données IMDB\n",
    "Adapté de https://github.com/ShawhinT/YouTube-Blog/blob/main/LLMs/fine-tuning/ft-example.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0fba828-f681-4fa1-9956-5b1a016001a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vango\\anaconda3b\\envs\\pytorch_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoConfig, \n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer)\n",
    "import peft\n",
    "from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\n",
    "import evaluate\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6a4484-07d8-49dd-81ef-672105f53ebe",
   "metadata": {},
   "source": [
    "### Création du dataset avec 1000 exemples de IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa9722d3-0609-4aea-9585-9aa2cfc1fc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 7.81k/7.81k [00:00<?, ?B/s]\n",
      "Downloading data: 100%|██████████| 21.0M/21.0M [00:00<00:00, 40.7MB/s]\n",
      "Downloading data: 100%|██████████| 20.5M/20.5M [00:00<00:00, 46.1MB/s]\n",
      "Downloading data: 100%|██████████| 42.0M/42.0M [00:00<00:00, 53.7MB/s]\n",
      "Generating train split: 100%|██████████| 25000/25000 [00:00<00:00, 173026.35 examples/s]\n",
      "Generating test split: 100%|██████████| 25000/25000 [00:00<00:00, 242630.45 examples/s]\n",
      "Generating unsupervised split: 100%|██████████| 50000/50000 [00:00<00:00, 261843.86 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Charger les données d'évaluation de films de imdb\n",
    "dataset_imdb = load_dataset(\"imdb\")\n",
    "N = 1000 # taille de la sous-collection\n",
    "np.random.seed(22)\n",
    "indices_aleatoires = np.random.randint(24999, size=N)\n",
    "\n",
    "# Extraire 1000 exemples\n",
    "x_ent = dataset_imdb['train'][indices_aleatoires]['text']\n",
    "y_ent = dataset_imdb['train'][indices_aleatoires]['label']\n",
    "\n",
    "x_test = dataset_imdb['test'][indices_aleatoires]['text']\n",
    "y_test = dataset_imdb['test'][indices_aleatoires]['label']\n",
    "\n",
    "# Dataset pour la sous-collection\n",
    "dataset = DatasetDict({'train':Dataset.from_dict({'label':y_ent,'text':x_ent}),\n",
    "                      'test':Dataset.from_dict({'label':y_test,'text':x_test})})# load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5625faa-5fea-4334-bd38-b77de983d8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.506"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pourcentage d'évaluations positives\n",
    "np.array(dataset['train']['label']).sum()/len(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a93eb88c-2a5a-4c7f-8d80-54f1f289bdc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': [0, 1, 1, 1, 1],\n",
       " 'text': [\"I purchased this video quite cheaply ex-rental, thinking that the cover looked quite nice. And it was nice, but the movie is trash. I can handle B-grade, I sometimes even enjoy a good B romp (ie. 'Surf Nazis Must Die' is a classic example of how entertaining the genre can be), but this was just bland bland bland. Incredibly dull scenes were broken up too sparsely by good wholesome cheap porn and entertaining dream horror sequences. This movie has very little to offer.\",\n",
       "  'What is contained on this disk is a first rate show by a first rate band. This disc is NOT for the faint of heart...the music is incredibly intense, and VERY cool. What you will learn when you watch this movie is just why the Who was so huge for so long. It is true that their records were great, but their shows were the top of the heap. In 1969 when this concert was shot, the screaming teenie boppers that threw jelly beans at the Beatles were gone and bands (and audiences) had settled down to long and often amazing displays of musical virtuosity--something that few audiences have the intellectual curiosity to pursue in the age of canned music by Britney and Christina. What you especially learn here are the amazing things that can happen when gifted musicians are encouraged to improvise. Try the concert out, it really is amazing.',\n",
       "  'Although I was in this movie playing the part of Sheriff Hodges, it still managed to make me jump in several places and believe me I\\'m NOT that easy. You might say that I\\'m biased about the film, and, OK, I am, but I didn\\'t see the finished product until 12/27/2006 and was extremely pleased. I\\'m not a Horror film fan as such but love the old \"B\" movies and black and white Sci Fi films. This movie will make you \"think\" you know when something is going to happen, then it doesn\\'t, then it does. It will keep you completely off balance. I would suggest watching the movie first then the director\\'s notes and special features. It is so well written, directed and filmed and I can tell you personally that it was a real joy to work with this cast and crew. I sincerely hope to be part of Brian and Laurence\\'s future projects.',\n",
       "  'Deliverance is the fascinating, haunting and sometimes even disturbing tale by James Dickey, turned into a brilliant movie by John Boorman. It\\'s about four businessmen, driven by manhood and macho-behavior, who\\'re spending a canoeing weekend high up in the mountains. Up there, they\\'re faced with every darkest side of man and every worst form of human misery...poverty, buggery and even physical harassment! These four men intended to travel down the river for adventure and excitement but their trip soon changes into an odyssey through a violent and lurking mountain-land, completely estranged from all forms of civilisation. All these elements actually make Deliverance one of the most nightmarish films I\\'ve ever seen. Just about everything that happens to these men, you pray that you\\'ll never find yourself to be in a similar situation. Pure talking cinema, Deliverance is a very important movie as well. John Boorman\\'s best (closely followed by Zardoz and Excalibur) was - and still is - a very influential film and it contains several memorable scenes that already featured in numberless other movies. Just think about the terrific \"Duelling banjos\" musical score and, of course, the unforgettable homosexual \"squeal like a pig\" rape scene. All the actors deliver (haha) perfect acting performances. Especially Jon Voight. A must see motion picture!!',\n",
       "  \"I enjoyed Longstreet, which followed in the steps of Raymond Burr's successful Ironside TV series and was intended to give it competition. But this show was canceled after one season because it was decided--I believe wrongly--that Longstreet was not able to compete with Mr. Burr's Ironside.<br /><br />I may add that the pilot for this show was especially well done and very memorable. I hope that a box set of Longstreet will appear.<br /><br />Writers should note that this story idea was only briefly explored here and that much more could and should be done to show the play and interplay of disabilities on TV.\"]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3644c68d-9adf-48a4-90a2-8fd89555a302",
   "metadata": {},
   "source": [
    "### Création du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a60dd1fe-8144-4678-b018-20891e49237a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "nom_modele = 'distilbert-base-uncased'\n",
    "# model_checkpoint = 'roberta-base' # you can alternatively use roberta-base but this model is bigger thus training will take longer\n",
    "\n",
    "# Traduction des étiquettes de classe\n",
    "id2label = {0: \"Negative\", 1: \"Positive\"}\n",
    "label2id = {\"Negative\":0, \"Positive\":1}\n",
    "modele = AutoModelForSequenceClassification.from_pretrained(\n",
    "    nom_modele, num_labels=2, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd7efe2-9e12-4357-b894-ef15e09458d5",
   "metadata": {},
   "source": [
    "### Vectorisation des textes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fe08707-657f-4e66-aa72-84899c54bf8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 2447.91 examples/s]\n",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 2271.01 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(nom_modele)\n",
    "def tokenize(donnees_texte):\n",
    "    jetons = tokenizer(donnees_texte['text'], truncation=True)\n",
    "    return jetons\n",
    "\n",
    "ds_jetons = dataset.map(tokenize, batched=True)\n",
    "ds_jetons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f8e85f9-1804-4f49-a783-4da59580ea1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd9a120-580d-470c-a981-7c7e22604865",
   "metadata": {},
   "source": [
    "## Métrique d'évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c07b9be2-a3f6-4b38-b9e8-6a2bc8aa945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": accuracy.compute(predictions=predictions, references=labels)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47500035-a555-46e0-83dc-440586d96b7e",
   "metadata": {},
   "source": [
    "### Test avant entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f3761c1-a297-45c8-882e-d74856259810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédictions avant entrainement:\n",
      "It was good. - Positive\n",
      "Not a fan, don't recommed. - Positive\n",
      "Better than the first one. - Positive\n",
      "This is not worth watching even once. - Positive\n",
      "This one is a pass. - Positive\n"
     ]
    }
   ],
   "source": [
    "liste_exemples = [\"It was good.\", \"Not a fan, don't recommed.\", \"Better than the first one.\", \"This is not worth watching even once.\", \"This one is a pass.\"]\n",
    "print(\"Prédictions avant entrainement:\")\n",
    "for texte in liste_exemples:\n",
    "    inputs = tokenizer.encode(texte, return_tensors=\"pt\")\n",
    "    # compute logits\n",
    "    logits = modele(inputs).logits\n",
    "    # convert logits to label\n",
    "    predictions = torch.argmax(logits)\n",
    "    print(texte + \" - \" + id2label[predictions.tolist()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff356f78-c9fd-4f2b-8f5b-097cf29c1c08",
   "metadata": {},
   "source": [
    "### Entrainement avec LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4dde538-cd7f-4ab5-a96d-c30f3003822e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type='SEQ_CLS', inference_mode=False, r=4, target_modules={'q_lin'}, lora_alpha=32, lora_dropout=0.01, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_config = LoraConfig(task_type=\"SEQ_CLS\",r=4,lora_alpha=32,\n",
    "              lora_dropout=0.01,target_modules = ['q_lin'])\n",
    "peft_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e0d9408-9fc4-4bd3-8d35-4d8217fe01e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 628,994 || all params: 67,584,004 || trainable%: 0.9307\n"
     ]
    }
   ],
   "source": [
    "modele = get_peft_model(modele, peft_config)\n",
    "modele.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5db78059-e5ae-4807-89db-b58ef6abedd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir= nom_modele + \"-lora-classification\",\n",
    "    learning_rate=1e-3,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=modele,\n",
    "    args=training_args,\n",
    "    train_dataset=ds_jetons[\"train\"],\n",
    "    eval_dataset=ds_jetons[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc8bc705-5dd7-4305-a797-399b2b0fa2c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2500/2500 3:33:46, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.707886</td>\n",
       "      <td>{'accuracy': 0.494}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.736600</td>\n",
       "      <td>0.695795</td>\n",
       "      <td>{'accuracy': 0.494}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.736600</td>\n",
       "      <td>0.697977</td>\n",
       "      <td>{'accuracy': 0.494}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.727300</td>\n",
       "      <td>0.699477</td>\n",
       "      <td>{'accuracy': 0.494}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.727300</td>\n",
       "      <td>0.700064</td>\n",
       "      <td>{'accuracy': 0.494}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.700800</td>\n",
       "      <td>0.693188</td>\n",
       "      <td>{'accuracy': 0.494}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.700800</td>\n",
       "      <td>0.693820</td>\n",
       "      <td>{'accuracy': 0.494}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.695300</td>\n",
       "      <td>0.693261</td>\n",
       "      <td>{'accuracy': 0.506}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.695300</td>\n",
       "      <td>0.693252</td>\n",
       "      <td>{'accuracy': 0.506}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.694300</td>\n",
       "      <td>0.693115</td>\n",
       "      <td>{'accuracy': 0.506}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2500, training_loss=0.7108740356445312, metrics={'train_runtime': 12830.4685, 'train_samples_per_second': 0.779, 'train_steps_per_second': 0.195, 'total_flos': 1111722294204960.0, 'train_loss': 0.7108740356445312, 'epoch': 10.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5664d1-9bd2-4ce1-bc24-cab5adf80f49",
   "metadata": {},
   "source": [
    "### Prédictions après entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5dc029e-1c16-491d-a3f1-715f9e0adf52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédictions après entrainement:\n",
      "It was good. - Positive\n",
      "Not a fan, don't recommed. - Positive\n",
      "Better than the first one. - Positive\n",
      "This is not worth watching even once. - Positive\n",
      "This one is a pass. - Positive\n"
     ]
    }
   ],
   "source": [
    "print(\"Prédictions après entrainement:\")\n",
    "for texte in liste_exemples:\n",
    "    inputs = tokenizer.encode(texte, return_tensors=\"pt\")\n",
    "    logits = modele(inputs).logits\n",
    "    predictions = torch.argmax(logits)\n",
    "    print(texte + \" - \" + id2label[predictions.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c86e08-707e-4a68-8c39-2b1cc45a65bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to('cpu') # moving to mps for Mac (can alternatively do 'cpu')\n",
    "\n",
    "print(\"Trained model predictions:\")\n",
    "print(\"--------------------------\")\n",
    "for text in text_list:\n",
    "    inputs = tokenizer.encode(text, return_tensors=\"pt\").to(\"cpu\") # moving to mps for Mac (can alternatively do 'cpu')\n",
    "\n",
    "    logits = model(inputs).logits\n",
    "    predictions = torch.max(logits,1).indices\n",
    "\n",
    "    print(text + \" - \" + id2label[predictions.tolist()[0]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c084bd9e-f7b1-4979-b753-73335ee0cede",
   "metadata": {},
   "source": [
    "### Optional: push model to hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159eb49a-dd0d-4c9e-b9ab-27e06585fd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# option 1: notebook login\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login() # ensure token gives write access\n",
    "\n",
    "# # option 2: key login\n",
    "# from huggingface_hub import login\n",
    "# write_key = 'hf_' # paste token here\n",
    "# login(write_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09496307-e253-47e3-a46f-3f28a84c89a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_name = 'shawhin' # your hf username or org name\n",
    "model_id = hf_name + \"/\" + model_checkpoint + \"-lora-text-classification\" # you can name the model whatever you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56ea581-0ea3-45f3-af21-362e9093ee37",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.push_to_hub(model_id) # save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f487331a-8552-4fb2-867f-985b8fe1d1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub(model_id) # save trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e7feaa-b70e-4b1d-a118-23c616d14639",
   "metadata": {},
   "source": [
    "### Optional: load peft model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cffa01-25a4-4c86-a7fa-a84353b8caae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to load peft model from hub for inference\n",
    "config = PeftConfig.from_pretrained(model_id)\n",
    "inference_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    config.base_model_name_or_path, num_labels=2, id2label=id2label, label2id=label2id\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "model = PeftModel.from_pretrained(inference_model, model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c6ed42-8ec3-4343-9e42-405feac052ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
