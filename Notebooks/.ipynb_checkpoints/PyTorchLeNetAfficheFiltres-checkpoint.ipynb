{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Parametres à entraîner:\n",
      "\t fc.weight\n",
      "\t fc.bias\n",
      "Entrainement sur  cpu\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\"\"\"\n",
    "Exemple de Cifar10 avec PyTorch\n",
    "Exemple d'apprentissage pas transfert avec ResNet18\n",
    "Version avec GPU\n",
    "\"\"\"\n",
    "import torch\n",
    "torch.manual_seed(0) # Pour résultats reproductibles\n",
    "\n",
    "# Fonction J d'entropie croisée\n",
    "import torch.nn.functional as F\n",
    "fonction_cout = F.cross_entropy\n",
    "\n",
    "def taux_bonnes_predictions(lot_Y_predictions, lot_Y):\n",
    "    predictions_categorie = torch.argmax(lot_Y_predictions, dim=1)\n",
    "    return (predictions_categorie == lot_Y).float().mean()\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "modele = models.resnet18(pretrained=True)\n",
    "\n",
    "# Désactiver l'apprentissage des paramètres pour réutiliser les valeurs déjà entraînées\n",
    "for parametre in modele.parameters():\n",
    "    parametre.requires_grad = False        \n",
    "\n",
    "# Modifier la dernière couche pour nouvelles données\n",
    "nombre_canaux_input = modele.fc.in_features\n",
    "nombre_classes = 10\n",
    "\n",
    "from torch import nn\n",
    "modele.fc = nn.Linear(nombre_canaux_input, nombre_classes)\n",
    "\n",
    "pretraitement = transforms.Compose([\n",
    "transforms.Resize(224),\n",
    "transforms.ToTensor(),\n",
    "transforms.Normalize(\n",
    "mean=[0.485, 0.456, 0.406],\n",
    "std=[0.229, 0.224, 0.225]\n",
    ")])\n",
    "\n",
    "#Chargement des données\n",
    "ds = torchvision.datasets.CIFAR10(root = \"./data\", train = True, download = True, transform = pretraitement)\n",
    "ds_ent, ds_valid = torch.utils.data.random_split(ds, [40000, 10000])\n",
    "\n",
    "#Création du DataLoader avec le dataset\n",
    "dl_ent = torch.utils.data.DataLoader(ds_ent, batch_size=100, shuffle = True)\n",
    "dl_valid = torch.utils.data.DataLoader(ds_valid, batch_size=100)\n",
    "\n",
    "print(\"Parametres à entraîner:\")\n",
    "parametres_a_entrainer = []\n",
    "for nom,parametre in modele.named_parameters():\n",
    "    if parametre.requires_grad == True:\n",
    "        parametres_a_entrainer.append(parametre)\n",
    "        print(\"\\t\",nom)\n",
    "\n",
    "from torch import optim\n",
    "optimiseur = optim.SGD(parametres_a_entrainer, lr=0.001,momentum=0.9)\n",
    "\n",
    "# Déterminer si un GPU est disponible\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Placer le modèle en mode GPU si possible\n",
    "modele = modele.to(device)\n",
    "print('Entrainement sur ',device)\n",
    "\n",
    "import time\n",
    "def entrainer_GPU(modele, dl_ent, dl_valid, optimiseur, nb_epochs=10):\n",
    "\n",
    "    debut = time.time()\n",
    "\n",
    "    # Listes pour les métriques par epoch\n",
    "    liste_cout_moyen_ent = []\n",
    "    liste_taux_moyen_ent = []\n",
    "    liste_cout_moyen_valid = []\n",
    "    liste_taux_moyen_valid = []\n",
    "    \n",
    "    # Boucle d'apprentissage\n",
    "    for epoch in range(nb_epochs):\n",
    "        cout_total_ent = 0 # pour cumuler les couts par mini-lot\n",
    "        taux_bonnes_predictions_ent = 0 # pour cumuler les taux par mini-lot\n",
    "        modele.train() # Pour certains types de couches (nn.BatchNorm2d, nn.Dropout, ...)\n",
    "        \n",
    "        # Boucle d'apprentissage par mini-lot pour une epoch\n",
    "        for lot_X, lot_Y in dl_ent:\n",
    "            \n",
    "            # Les données doivent être placés en GPU pour être compatibles avec le modèle\n",
    "            lot_X = lot_X.to(device)\n",
    "            lot_Y = lot_Y.to(device)\n",
    "\n",
    "            optimiseur.zero_grad() # Remettre les dérivées à zéro\n",
    "            lot_Y_predictions = modele(lot_X) # Appel de la méthode forward\n",
    "            cout = fonction_cout(lot_Y_predictions, lot_Y)\n",
    "            cout.backward() # Calcul des gradiants par rétropropagation\n",
    "            with torch.no_grad():\n",
    "                cout_total_ent +=cout\n",
    "                taux_bonnes_predictions_ent += taux_bonnes_predictions(lot_Y_predictions, lot_Y)\n",
    "            optimiseur.step() # Mise à jour des paramètres\n",
    "            # scheduler.step()\n",
    "        # Calculer les moyennes par mini-lot\n",
    "        with torch.no_grad():\n",
    "            cout_moyen_ent = cout_total_ent/len(dl_ent)\n",
    "            taux_moyen_ent = taux_bonnes_predictions_ent/len(dl_ent)\n",
    "       \n",
    "        modele.eval() # Pour certains types de couches (nn.BatchNorm2d, nn.Dropout, ...)\n",
    "        with torch.no_grad():\n",
    "            # Les données de validation doivent aussi être placés en GPU\n",
    "            cout_valid = sum(fonction_cout(modele(lot_valid_X.to(device)), lot_valid_Y.to(device)) for lot_valid_X, lot_valid_Y in dl_valid)\n",
    "            taux_bons_valid = sum(taux_bonnes_predictions(modele(lot_valid_X.to(device)), lot_valid_Y.to(device)) for lot_valid_X, lot_valid_Y in dl_valid)\n",
    "        cout_moyen_valid = cout_valid/len(dl_valid)\n",
    "        taux_moyen_valid = taux_bons_valid/len(dl_valid)\n",
    "        print(f'-------- > epoch {epoch+1}:  coût moyen entraînement = {cout_moyen_ent}')\n",
    "        print(f'-------- > epoch {epoch+1}:  taux moyen entraînement = {taux_moyen_ent}')\n",
    "        print(f'-------- > epoch {epoch+1}:  coût moyen validation = {cout_moyen_valid}')\n",
    "        print(f'-------- > epoch {epoch+1}:  taux moyen validation = {taux_moyen_valid}')\n",
    "    \n",
    "        liste_cout_moyen_ent.append(cout_moyen_ent)\n",
    "        liste_taux_moyen_ent.append(taux_moyen_ent)\n",
    "        liste_cout_moyen_valid.append(cout_moyen_valid)\n",
    "        liste_taux_moyen_valid.append(taux_moyen_valid)\n",
    "        \n",
    "        temps_ecoule = time.time() - debut\n",
    "        print('Temps écoulé : {:.0f}m {:.0f}s'.format(temps_ecoule // 60, temps_ecoule % 60))\n",
    "\n",
    "    \n",
    "    # Affichage du graphique d'évolution des métriques par epoch\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(np.arange(0,nb_epochs),liste_cout_moyen_ent,label='Erreur entraînement')\n",
    "    plt.plot(np.arange(0,nb_epochs),liste_cout_moyen_valid,label='Erreur validation')\n",
    "    plt.title(\"Evolution du coût\")\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('moyenne par observation')\n",
    "    plt.legend(loc='upper center')\n",
    "    plt.show()\n",
    "        \n",
    "    plt.plot(np.arange(0,nb_epochs),liste_taux_moyen_ent,label='Taux bonnes réponses entraînement')\n",
    "    plt.plot(np.arange(0,nb_epochs),liste_taux_moyen_valid,label='Taux bonnes réponses validation')\n",
    "    plt.title(\"Evolution du taux\")\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('moyenne par observation')\n",
    "    plt.legend(loc='center')\n",
    "    plt.show()\n",
    "\n",
    "entrainer_GPU(modele, dl_ent, dl_valid, optimiseur, nb_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_layers=0\n",
    "conv_layers=[]\n",
    "\n",
    "model_children=list(modelVGG.children())\n",
    "\n",
    "for child in model_children:\n",
    "  if type(child)==nn.Conv2d:\n",
    "    no_of_layers+=1\n",
    "    conv_layers.append(child)\n",
    "  elif type(child)==nn.Sequential:\n",
    "    for layer in child.children():\n",
    "      if type(layer)==nn.Conv2d:\n",
    "        no_of_layers+=1\n",
    "        conv_layers.append(layer)\n",
    "print(no_of_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [conv_layers[0](img)]\n",
    "for i in range(1, len(conv_layers)):\n",
    "    results.append(conv_layers[i](results[-1]))\n",
    "outputs = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_layer in range(len(outputs)):\n",
    "    plt.figure(figsize=(50, 10))\n",
    "    layer_viz = outputs[num_layer][0, :, :, :]\n",
    "    layer_viz = layer_viz.data\n",
    "    print(\"Layer \",num_layer+1)\n",
    "    for i, filter in enumerate(layer_viz):\n",
    "        if i == 16: \n",
    "            break\n",
    "        plt.subplot(2, 8, i + 1)\n",
    "        plt.imshow(filter, cmap='gray')\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
