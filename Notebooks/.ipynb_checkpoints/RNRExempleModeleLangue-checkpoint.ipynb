{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correspondances des caractères en entiers: {'f': 0, 'i': 1, 'k': 2, 's': 3, 'w': 4}\n",
      "Taille maximale de chaine : 4\n",
      "Mini-lot des séquences de caractères X\n",
      "['wif', 'wik', 'sif', 'kiw']\n",
      "Mini-lot des séquences de caractères Y\n",
      "['ifi', 'iki', 'ifi', 'iwi']\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Exemple de Réseau de Neurone Récurrent avec Pytorch RNN\n",
    "\n",
    "\"\"\"\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "torch.manual_seed(0) # Pour résultats reproductibles\n",
    "\n",
    "# Préparer les données d'entrainement\n",
    "liste_chaines = ['wifi','wiki','sifi','kiwi']\n",
    "ensemble_caracteres = sorted(list(set(''.join(liste_chaines))))\n",
    "dict_int_car = dict(enumerate(ensemble_caracteres))\n",
    "dict_car_int = {char: ind for ind, char in dict_int_car.items()}\n",
    "print(\"Correspondances des caractères en entiers:\",dict_car_int)\n",
    "taille_max_chaine = len(max(liste_chaines, key=len))\n",
    "print(\"Taille maximale de chaine :\",taille_max_chaine)\n",
    "\n",
    "# Niveler les tailles des chaines pour simplifier le traitement\n",
    "for i in range(len(liste_chaines)):\n",
    "    while len(liste_chaines[i])<taille_max_chaine:\n",
    "        liste_chaines[i] += ' '\n",
    "        \n",
    "mini_lot_sequence_X = [] # Mini_lot de séquences X pour l'entraînement\n",
    "mini_lot_sequence_Y = [] # Mini_lot de séquences cibles X pour l'entraînement\n",
    "\n",
    "for i in range(len(liste_chaines)):\n",
    "    mini_lot_sequence_X.append(liste_chaines[i][:-1]) # Supprimer dernier caractère de la sequence X\n",
    "    mini_lot_sequence_Y.append(liste_chaines[i][1:])  # Supprimer premier caractère de la sequence Y\n",
    "print(\"Mini-lot des séquences de caractères X\")\n",
    "print(mini_lot_sequence_X)\n",
    "print(\"Mini-lot des séquences de caractères Y\")\n",
    "print(mini_lot_sequence_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mini-lot des séquences X sous forme d'entiers\n",
      "[[4, 1, 0], [4, 1, 2], [3, 1, 0], [2, 1, 4]]\n",
      "Mini-lot des séquences Y sous forme d'entiers\n",
      "[[1, 0, 1], [1, 2, 1], [1, 0, 1], [1, 4, 1]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(liste_chaines)): # Conversion des caractères en entiers\n",
    "    mini_lot_sequence_X[i] = [dict_car_int[character] for character in mini_lot_sequence_X[i]]\n",
    "    mini_lot_sequence_Y[i] = [dict_car_int[character] for character in mini_lot_sequence_Y[i]]\n",
    "print(\"Mini-lot des séquences X sous forme d'entiers\")\n",
    "print(mini_lot_sequence_X)\n",
    "print(\"Mini-lot des séquences Y sous forme d'entiers\")\n",
    "print(mini_lot_sequence_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mini-lot des séquences X sous forme de bitmaps (encodage one-hot)\n",
      "Forme de X: (4, 3, 5) --> (taille mini lot, taille sequence, taille bitmap)\n",
      "[[[0. 0. 0. 0. 1.]\n",
      "  [0. 1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 1.]\n",
      "  [0. 1. 0. 0. 0.]\n",
      "  [0. 0. 1. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1. 0.]\n",
      "  [0. 1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 1.]]]\n"
     ]
    }
   ],
   "source": [
    "#Coder les entiers de Y en bitmap pour l'entrainement\n",
    "taille_dictionnaire = len(dict_car_int)    \n",
    "taille_sequence = taille_max_chaine - 1\n",
    "taille_mini_lot = len(liste_chaines)\n",
    "mini_lot_sequence_X_bitmap = np.zeros((taille_mini_lot, taille_sequence, taille_dictionnaire), dtype=np.float32)\n",
    "for indice_lot in range(taille_mini_lot):\n",
    "    for indice_sequence in range(taille_sequence):\n",
    "        mini_lot_sequence_X_bitmap[indice_lot, indice_sequence, mini_lot_sequence_X[indice_lot][indice_sequence]] = 1\n",
    "print(\"Mini-lot des séquences X sous forme de bitmaps (encodage one-hot)\")\n",
    "print(\"Forme de X: {} --> (taille mini lot, taille sequence, taille bitmap)\".format(mini_lot_sequence_X_bitmap.shape))\n",
    "print(mini_lot_sequence_X_bitmap)\n",
    "\n",
    "mini_lot_sequence_X_bitmap = torch.from_numpy(mini_lot_sequence_X_bitmap)\n",
    "mini_lot_sequence_Y = torch.Tensor(mini_lot_sequence_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrainement sur  cpu\n",
      "-------- > epoch 10:  coût = 1.2965151071548462\n",
      "-------- > epoch 20:  coût = 0.9457571506500244\n",
      "-------- > epoch 30:  coût = 0.6524205803871155\n",
      "-------- > epoch 40:  coût = 0.48680105805397034\n",
      "-------- > epoch 50:  coût = 0.4072342813014984\n",
      "-------- > epoch 60:  coût = 0.3534245193004608\n",
      "-------- > epoch 70:  coût = 0.31173354387283325\n",
      "-------- > epoch 80:  coût = 0.27940812706947327\n",
      "-------- > epoch 90:  coût = 0.25379493832588196\n",
      "-------- > epoch 100:  coût = 0.23382718861103058\n"
     ]
    }
   ],
   "source": [
    "# Déterminer si un GPU est disponible\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Entrainement sur ',device)\n",
    "    \n",
    "class Modele(nn.Module):\n",
    "    def __init__(self, taille_X, taille_Y, taille_H, nb_couches_RNR):\n",
    "        super(Modele, self).__init__()\n",
    "        self.taille_H = taille_H\n",
    "        self.nb_couches_RNR = nb_couches_RNR\n",
    "        self.rnn = nn.RNN(taille_X, taille_H, nb_couches_RNR, batch_first=True)\n",
    "        self.fc = nn.Linear(taille_H, taille_Y)\n",
    "    \n",
    "    def forward(self, lot_X):\n",
    "        \"\"\" lot_X : (taille_mini_lot, taille_sequence, taille_bitmap)\"\"\"\n",
    "        taille_mini_lot = lot_X.size(0)\n",
    "        H = torch.zeros(self.nb_couches_RNR, taille_mini_lot, self.taille_H).to(device)\n",
    "        lot_Ht, H = self.rnn(lot_X, H) # lot_Ht : (taille_mini_lot,taille_sequence,taille_H)\n",
    "        # Applatir (taille_mini_lot,taille_sequence) pour la couche dense qui suit\n",
    "        lot_Ht = lot_Ht.contiguous().view(-1, self.taille_H)  # lot_Ht : (taille_mini_lot*taille_sequence,taille_H)\n",
    "        lot_Yt = self.fc(lot_Ht) # lot_Yt : (taille_mini_lot*taille_sequence,taille_Y)\n",
    "        \n",
    "        return lot_Yt, H\n",
    "    \n",
    "    def init_H(self, taille_mini_lot):\n",
    "        H = torch.zeros(self.nb_couches_RNR, taille_mini_lot, self.taille_H).to(device)\n",
    "        return H\n",
    "\n",
    "modele = Modele(taille_X=taille_dictionnaire, taille_Y=taille_dictionnaire, taille_H=6, nb_couches_RNR=1)\n",
    "modele = modele.to(device)\n",
    "\n",
    "n_epochs = 100\n",
    "taux=0.01\n",
    "fonction_cout = nn.CrossEntropyLoss()\n",
    "optimizeur = torch.optim.Adam(modele.parameters(), lr=taux)\n",
    "\n",
    "# Entraînement du RNR\n",
    "mini_lot_sequence_X_bitmap = mini_lot_sequence_X_bitmap.to(device)\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    optimizeur.zero_grad()\n",
    "    lot_Yt, H = modele(mini_lot_sequence_X_bitmap)\n",
    "    lot_Yt = lot_Yt.to(device)\n",
    "    mini_lot_sequence_Y = mini_lot_sequence_Y.to(device)\n",
    "    cout = fonction_cout(lot_Yt, mini_lot_sequence_Y.view(-1).long())\n",
    "    cout.backward()\n",
    "    optimizeur.step()\n",
    "    if epoch%10 == 0:\n",
    "        print(f'-------- > epoch {epoch}:  coût = {cout}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédiction itération:  0\n",
      "Un seul lot X<1>, X<2>, ..., X<t>: tensor([[[0., 0., 0., 0., 1.]]])\n",
      "Prédiction Y<1>,Y<2>, ... ,Y<t>: tensor([[-3.5656,  2.8108, -2.5337, -1.9746, -2.0921]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Softmax du dernier Yt: tensor([0.0017, 0.9782, 0.0047, 0.0082, 0.0073])\n",
      "Caractère prédit:  i\n",
      "Prédiction itération:  1\n",
      "Un seul lot X<1>, X<2>, ..., X<t>: tensor([[[0., 0., 0., 0., 1.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "Prédiction Y<1>,Y<2>, ... ,Y<t>: tensor([[-3.5656,  2.8108, -2.5337, -1.9746, -2.0921],\n",
      "        [ 2.8301, -0.9715,  1.9997, -0.3128,  1.2256]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Softmax du dernier Yt: tensor([0.5874, 0.0131, 0.2560, 0.0254, 0.1181])\n",
      "Caractère prédit:  f\n",
      "Prédiction itération:  2\n",
      "Un seul lot X<1>, X<2>, ..., X<t>: tensor([[[0., 0., 0., 0., 1.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "Prédiction Y<1>,Y<2>, ... ,Y<t>: tensor([[-3.5656,  2.8108, -2.5337, -1.9746, -2.0921],\n",
      "        [ 2.8301, -0.9715,  1.9997, -0.3128,  1.2256],\n",
      "        [-4.2278,  3.1471, -2.9407, -2.0051, -2.3861]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Softmax du dernier Yt: tensor([6.1895e-04, 9.8752e-01, 2.2421e-03, 5.7144e-03, 3.9041e-03])\n",
      "Caractère prédit:  i\n",
      "wifi\n"
     ]
    }
   ],
   "source": [
    "def prediction(modele, ensemble_caracteres):\n",
    "    \"\"\" Retourner le prochain caratère de la séquence ensemble_caracteres selon le modèle\"\"\"\n",
    "    # Transformer l'ensemble en un mini-lot de taille 1 avec le format approprié (1,taille_seq,bitmap)\n",
    "    ensemble_caracteres = np.array([[dict_car_int[c] for c in ensemble_caracteres]])\n",
    "    taille_sequence = ensemble_caracteres.shape[1]\n",
    "    mini_lot_sequence_X_bitmap = np.zeros((1, taille_sequence, taille_dictionnaire), dtype=np.float32)\n",
    "    for indice_sequence in range(taille_sequence):\n",
    "        mini_lot_sequence_X_bitmap[0, indice_sequence, ensemble_caracteres[0][indice_sequence]] = 1\n",
    "    mini_lot_sequence_X_bitmap = torch.from_numpy(mini_lot_sequence_X_bitmap)\n",
    "    mini_lot_sequence_X_bitmap = mini_lot_sequence_X_bitmap.to(device)\n",
    "    Yt, H = modele(mini_lot_sequence_X_bitmap)\n",
    "    print(\"Un seul lot X<1>, X<2>, ..., X<t>:\",mini_lot_sequence_X_bitmap)\n",
    "    print(\"Prédiction Y<1>,Y<2>, ... ,Y<t>:\",Yt)\n",
    "    softmax_dernier_Yt = nn.functional.softmax(Yt[-1], dim=0).data\n",
    "    print(\"Softmax du dernier Yt:\",softmax_dernier_Yt)\n",
    "    indice_probabilite_maximale = torch.max(softmax_dernier_Yt, dim=0)[1].item()\n",
    "    return dict_int_car[indice_probabilite_maximale]\n",
    "\n",
    "def echantillon(modele, taille_resultat, prefixe='w'):\n",
    "    \"\"\" Compléter le préfixe par échantillonnage du modèle un caractère à la fois\"\"\"\n",
    "    modele.eval()\n",
    "    ensemble_caracteres = [caractere for caractere in prefixe]\n",
    "    taille_restante = taille_resultat - len(ensemble_caracteres)\n",
    "    for i in range(taille_restante):\n",
    "        print(\"Prédiction itération: \", i)\n",
    "        caractere_prediction = prediction(modele, ensemble_caracteres)\n",
    "        print(\"Caractère prédit: \", caractere_prediction)\n",
    "        ensemble_caracteres.append(caractere_prediction)\n",
    "    return ''.join(ensemble_caracteres)\n",
    "\n",
    "print(echantillon(modele,4,'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lot4_H = [[[0., 0., 0., 0., 0., 0.],\n",
    "         [0., 0., 0., 0., 0., 0.],\n",
    "         [0., 0., 0., 0., 0., 0.],\n",
    "         [0., 0., 0., 0., 0., 0.]]]\n",
    "lot_X = [[[0., 0., 0., 0., 1.],\n",
    "         [0., 1., 0., 0., 0.],\n",
    "         [1., 0., 0., 0., 0.]],\n",
    "\n",
    "        [[0., 0., 0., 0., 1.],\n",
    "         [0., 1., 0., 0., 0.],\n",
    "         [0., 0., 1., 0., 0.]],\n",
    "\n",
    "        [[0., 0., 0., 1., 0.],\n",
    "         [0., 1., 0., 0., 0.],\n",
    "         [1., 0., 0., 0., 0.]],\n",
    "\n",
    "        [[0., 0., 1., 0., 0.],\n",
    "         [0., 1., 0., 0., 0.],\n",
    "         [0., 0., 0., 0., 1.]]]\n",
    "Wih = [[-0.0031,  0.2190, -0.3360, -0.3004, -0.1572],\n",
    "        [ 0.1095, -0.0081,  0.3237, -0.0362,  0.1080],\n",
    "        [-0.1234, -0.0802, -0.3900, -0.2704, -0.1683],\n",
    "        [ 0.0151,  0.1614,  0.2450, -0.2768, -0.1778],\n",
    "        [ 0.1483,  0.3390, -0.0840,  0.3055, -0.0658],\n",
    "        [ 0.0432,  0.3697, -0.3787, -0.2570, -0.1034]]\n",
    "Whh = [[-0.1591,  0.3527, -0.2646, -0.1879, -0.2852, -0.3823],\n",
    "        [-0.2383,  0.3509,  0.1822,  0.1979,  0.0215, -0.2093],\n",
    "        [ 0.0691, -0.3812, -0.2950, -0.2105,  0.2576,  0.2394],\n",
    "        [-0.1811, -0.0147,  0.2611,  0.4059,  0.1620,  0.0552],\n",
    "        [ 0.2737, -0.2404,  0.0761, -0.3165, -0.2830, -0.2109],\n",
    "        [ 0.1847,  0.1642, -0.2418,  0.1233,  0.2241, -0.0515]]\n",
    "Bih = [ 0.0156,  0.0946,  0.2533,  0.3920, -0.3146, -0.1496]\n",
    "Bhh = [ 0.1604,  0.3383,  0.3553,  0.3602,  0.0812, -0.3550]\n",
    "lot4_Ht = [[[ 0.0188,  0.4936,  0.4138,  0.5186, -0.2905, -0.5427],\n",
    "         [ 0.5714,  0.7059, -0.0943,  0.8159,  0.0561, -0.1231],\n",
    "         [ 0.2295,  0.6778,  0.0963,  0.7453, -0.3396, -0.0973]],\n",
    "\n",
    "        [[ 0.0188,  0.4936,  0.4138,  0.5186, -0.2905, -0.5427],\n",
    "         [ 0.5714,  0.7059, -0.0943,  0.8159,  0.0561, -0.1231],\n",
    "         [-0.0989,  0.7776, -0.1684,  0.8312, -0.5270, -0.4774]],\n",
    "\n",
    "        [[-0.1238,  0.3771,  0.3258,  0.4426,  0.0720, -0.6420],\n",
    "         [ 0.5394,  0.7011,  0.0516,  0.8247, -0.0191, -0.0708],\n",
    "         [ 0.1958,  0.6894,  0.0445,  0.7618, -0.3299, -0.1568]],\n",
    "\n",
    "        [[-0.1586,  0.6390,  0.2151,  0.7604, -0.3071, -0.7081],\n",
    "         [ 0.6664,  0.7691, -0.1958,  0.8363, -0.0793, -0.0499],\n",
    "         [ 0.1198,  0.6587,  0.0425,  0.6139, -0.4992, -0.2197]]]\n",
    "lot4_H_suivant = [[[ 0.2295,  0.6778,  0.0963,  0.7453, -0.3396, -0.0973],\n",
    "         [-0.0989,  0.7776, -0.1684,  0.8312, -0.5270, -0.4774],\n",
    "         [ 0.1958,  0.6894,  0.0445,  0.7618, -0.3299, -0.1568],\n",
    "         [ 0.1198,  0.6587,  0.0425,  0.6139, -0.4992, -0.2197]]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
