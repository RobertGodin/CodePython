{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrainement sur  cpu\n",
      "-------- > epoch 0 lot 0 :  coût = 8.288488388061523\n",
      "Temps écoulé : 0m 0s\n",
      "-------- > epoch 0 lot 100 :  coût = 6.37285852432251\n",
      "Temps écoulé : 0m 3s\n",
      "-------- > epoch 0 lot 200 :  coût = 6.4168195724487305\n",
      "Temps écoulé : 0m 5s\n",
      "-------- > epoch 0 lot 300 :  coût = 6.325267314910889\n",
      "Temps écoulé : 0m 8s\n",
      "-------- > epoch 0 lot 400 :  coût = 6.300807476043701\n",
      "Temps écoulé : 0m 11s\n",
      "-------- > epoch 0 lot 500 :  coût = 5.721706390380859\n",
      "Temps écoulé : 0m 13s\n",
      "-------- > epoch 0 lot 600 :  coût = 7.842543125152588\n",
      "Temps écoulé : 0m 16s\n",
      "-------- > epoch 0 lot 700 :  coût = 7.548484802246094\n",
      "Temps écoulé : 0m 18s\n",
      "-------- > epoch 0 lot 800 :  coût = 5.539044380187988\n",
      "Temps écoulé : 0m 21s\n",
      "-------- > epoch 0 lot 900 :  coût = 5.960934162139893\n",
      "Temps écoulé : 0m 24s\n",
      "-------- > epoch 0 lot 1000 :  coût = 4.524051189422607\n",
      "Temps écoulé : 0m 27s\n",
      "-------- > epoch 0 lot 1100 :  coût = 7.4533491134643555\n",
      "Temps écoulé : 0m 29s\n",
      "-------- > epoch 0 lot 1200 :  coût = 2.2234573364257812\n",
      "Temps écoulé : 0m 32s\n",
      "-------- > epoch 0 lot 1300 :  coût = 5.4529805183410645\n",
      "Temps écoulé : 0m 35s\n",
      "-------- > epoch 0 lot 1400 :  coût = 6.221846580505371\n",
      "Temps écoulé : 0m 38s\n",
      "-------- > epoch 0 lot 1500 :  coût = 5.4514994621276855\n",
      "Temps écoulé : 0m 41s\n",
      "-------- > epoch 0 lot 1600 :  coût = 5.254108905792236\n",
      "Temps écoulé : 0m 43s\n",
      "-------- > epoch 0 lot 1700 :  coût = 4.61732816696167\n",
      "Temps écoulé : 0m 46s\n",
      "-------- > epoch 0 lot 1800 :  coût = 4.910546779632568\n",
      "Temps écoulé : 0m 49s\n",
      "-------- > epoch 0 lot 1900 :  coût = 5.030243396759033\n",
      "Temps écoulé : 0m 52s\n",
      "-------- > epoch 0 lot 2000 :  coût = 5.632030963897705\n",
      "Temps écoulé : 0m 55s\n",
      "-------- > epoch 1 lot 0 :  coût = 3.774651288986206\n",
      "Temps écoulé : 0m 56s\n",
      "-------- > epoch 1 lot 100 :  coût = 5.303441524505615\n",
      "Temps écoulé : 0m 59s\n",
      "-------- > epoch 1 lot 200 :  coût = 3.8409183025360107\n",
      "Temps écoulé : 1m 1s\n",
      "-------- > epoch 1 lot 300 :  coût = 5.160902976989746\n",
      "Temps écoulé : 1m 4s\n",
      "-------- > epoch 1 lot 400 :  coût = 4.704206943511963\n",
      "Temps écoulé : 1m 7s\n",
      "-------- > epoch 1 lot 500 :  coût = 4.933005332946777\n",
      "Temps écoulé : 1m 10s\n",
      "-------- > epoch 1 lot 600 :  coût = 6.267233371734619\n",
      "Temps écoulé : 1m 13s\n",
      "-------- > epoch 1 lot 700 :  coût = 6.398311614990234\n",
      "Temps écoulé : 1m 16s\n",
      "-------- > epoch 1 lot 800 :  coût = 4.372693061828613\n",
      "Temps écoulé : 1m 19s\n",
      "-------- > epoch 1 lot 900 :  coût = 4.809317588806152\n",
      "Temps écoulé : 1m 22s\n",
      "-------- > epoch 1 lot 1000 :  coût = 3.7362051010131836\n",
      "Temps écoulé : 1m 24s\n",
      "-------- > epoch 1 lot 1100 :  coût = 6.315938472747803\n",
      "Temps écoulé : 1m 27s\n",
      "-------- > epoch 1 lot 1200 :  coût = 0.719201385974884\n",
      "Temps écoulé : 1m 30s\n",
      "-------- > epoch 1 lot 1300 :  coût = 4.183592796325684\n",
      "Temps écoulé : 1m 33s\n",
      "-------- > epoch 1 lot 1400 :  coût = 5.636836528778076\n",
      "Temps écoulé : 1m 36s\n",
      "-------- > epoch 1 lot 1500 :  coût = 4.405368328094482\n",
      "Temps écoulé : 1m 39s\n",
      "-------- > epoch 1 lot 1600 :  coût = 3.125997304916382\n",
      "Temps écoulé : 1m 41s\n",
      "-------- > epoch 1 lot 1700 :  coût = 3.507263422012329\n",
      "Temps écoulé : 1m 44s\n",
      "-------- > epoch 1 lot 1800 :  coût = 3.6595711708068848\n",
      "Temps écoulé : 1m 47s\n",
      "-------- > epoch 1 lot 1900 :  coût = 4.049155235290527\n",
      "Temps écoulé : 1m 50s\n",
      "-------- > epoch 1 lot 2000 :  coût = 4.489012718200684\n",
      "Temps écoulé : 1m 53s\n",
      "-------- > epoch 2 lot 0 :  coût = 3.302553415298462\n",
      "Temps écoulé : 1m 53s\n",
      "-------- > epoch 2 lot 100 :  coût = 5.1691179275512695\n",
      "Temps écoulé : 1m 56s\n",
      "-------- > epoch 2 lot 200 :  coût = 2.9556989669799805\n",
      "Temps écoulé : 1m 59s\n",
      "-------- > epoch 2 lot 300 :  coût = 4.545626640319824\n",
      "Temps écoulé : 2m 2s\n",
      "-------- > epoch 2 lot 400 :  coût = 4.0055928230285645\n",
      "Temps écoulé : 2m 5s\n",
      "-------- > epoch 2 lot 500 :  coût = 4.436849594116211\n",
      "Temps écoulé : 2m 8s\n",
      "-------- > epoch 2 lot 600 :  coût = 5.044704914093018\n",
      "Temps écoulé : 2m 11s\n",
      "-------- > epoch 2 lot 700 :  coût = 5.433008670806885\n",
      "Temps écoulé : 2m 14s\n",
      "-------- > epoch 2 lot 800 :  coût = 3.7455124855041504\n",
      "Temps écoulé : 2m 17s\n",
      "-------- > epoch 2 lot 900 :  coût = 4.0677876472473145\n",
      "Temps écoulé : 2m 19s\n",
      "-------- > epoch 2 lot 1000 :  coût = 3.321958065032959\n",
      "Temps écoulé : 2m 22s\n",
      "-------- > epoch 2 lot 1100 :  coût = 5.407035827636719\n",
      "Temps écoulé : 2m 25s\n",
      "-------- > epoch 2 lot 1200 :  coût = 0.5413365364074707\n",
      "Temps écoulé : 2m 27s\n",
      "-------- > epoch 2 lot 1300 :  coût = 3.3264353275299072\n",
      "Temps écoulé : 2m 30s\n",
      "-------- > epoch 2 lot 1400 :  coût = 5.252309799194336\n",
      "Temps écoulé : 2m 33s\n",
      "-------- > epoch 2 lot 1500 :  coût = 3.684196710586548\n",
      "Temps écoulé : 2m 35s\n",
      "-------- > epoch 2 lot 1600 :  coût = 2.0816280841827393\n",
      "Temps écoulé : 2m 38s\n",
      "-------- > epoch 2 lot 1700 :  coût = 3.0107743740081787\n",
      "Temps écoulé : 2m 41s\n",
      "-------- > epoch 2 lot 1800 :  coût = 3.124518394470215\n",
      "Temps écoulé : 2m 44s\n",
      "-------- > epoch 2 lot 1900 :  coût = 3.2959563732147217\n",
      "Temps écoulé : 2m 47s\n",
      "-------- > epoch 2 lot 2000 :  coût = 3.7060024738311768\n",
      "Temps écoulé : 2m 50s\n",
      "-------- > epoch 3 lot 0 :  coût = 2.914449691772461\n",
      "Temps écoulé : 2m 51s\n",
      "-------- > epoch 3 lot 100 :  coût = 5.036782264709473\n",
      "Temps écoulé : 2m 54s\n",
      "-------- > epoch 3 lot 200 :  coût = 2.4213101863861084\n",
      "Temps écoulé : 2m 56s\n",
      "-------- > epoch 3 lot 300 :  coût = 3.9626376628875732\n",
      "Temps écoulé : 2m 59s\n",
      "-------- > epoch 3 lot 400 :  coût = 3.522273063659668\n",
      "Temps écoulé : 3m 2s\n",
      "-------- > epoch 3 lot 500 :  coût = 3.9922127723693848\n",
      "Temps écoulé : 3m 5s\n",
      "-------- > epoch 3 lot 600 :  coût = 4.18898868560791\n",
      "Temps écoulé : 3m 8s\n",
      "-------- > epoch 3 lot 700 :  coût = 4.4653849601745605\n",
      "Temps écoulé : 3m 11s\n",
      "-------- > epoch 3 lot 800 :  coût = 3.338712692260742\n",
      "Temps écoulé : 3m 13s\n",
      "-------- > epoch 3 lot 900 :  coût = 3.479856014251709\n",
      "Temps écoulé : 3m 16s\n",
      "-------- > epoch 3 lot 1000 :  coût = 3.003537893295288\n",
      "Temps écoulé : 3m 19s\n",
      "-------- > epoch 3 lot 1100 :  coût = 4.5104193687438965\n",
      "Temps écoulé : 3m 22s\n",
      "-------- > epoch 3 lot 1200 :  coût = 0.49057623744010925\n",
      "Temps écoulé : 3m 24s\n",
      "-------- > epoch 3 lot 1300 :  coût = 2.859245538711548\n",
      "Temps écoulé : 3m 27s\n",
      "-------- > epoch 3 lot 1400 :  coût = 5.042575359344482\n",
      "Temps écoulé : 3m 30s\n",
      "-------- > epoch 3 lot 1500 :  coût = 3.1459381580352783\n",
      "Temps écoulé : 3m 33s\n",
      "-------- > epoch 3 lot 1600 :  coût = 1.7714000940322876\n",
      "Temps écoulé : 3m 35s\n",
      "-------- > epoch 3 lot 1700 :  coût = 2.707648754119873\n",
      "Temps écoulé : 3m 38s\n",
      "-------- > epoch 3 lot 1800 :  coût = 2.8000268936157227\n",
      "Temps écoulé : 3m 41s\n",
      "-------- > epoch 3 lot 1900 :  coût = 2.762718439102173\n",
      "Temps écoulé : 3m 44s\n",
      "-------- > epoch 3 lot 2000 :  coût = 3.0914669036865234\n",
      "Temps écoulé : 3m 47s\n",
      "-------- > epoch 4 lot 0 :  coût = 2.6744987964630127\n",
      "Temps écoulé : 3m 48s\n",
      "-------- > epoch 4 lot 100 :  coût = 4.8652873039245605\n",
      "Temps écoulé : 3m 51s\n",
      "-------- > epoch 4 lot 200 :  coût = 2.049811840057373\n",
      "Temps écoulé : 3m 54s\n",
      "-------- > epoch 4 lot 300 :  coût = 3.485546588897705\n",
      "Temps écoulé : 3m 57s\n",
      "-------- > epoch 4 lot 400 :  coût = 3.148665428161621\n",
      "Temps écoulé : 3m 60s\n",
      "-------- > epoch 4 lot 500 :  coût = 3.7014966011047363\n",
      "Temps écoulé : 4m 3s\n",
      "-------- > epoch 4 lot 600 :  coût = 3.673776149749756\n",
      "Temps écoulé : 4m 6s\n",
      "-------- > epoch 4 lot 700 :  coût = 3.66099214553833\n",
      "Temps écoulé : 4m 9s\n",
      "-------- > epoch 4 lot 800 :  coût = 3.0431408882141113\n",
      "Temps écoulé : 4m 12s\n",
      "-------- > epoch 4 lot 900 :  coût = 3.017897129058838\n",
      "Temps écoulé : 4m 15s\n",
      "-------- > epoch 4 lot 1000 :  coût = 2.70389723777771\n",
      "Temps écoulé : 4m 18s\n",
      "-------- > epoch 4 lot 1100 :  coût = 3.7494945526123047\n",
      "Temps écoulé : 4m 20s\n",
      "-------- > epoch 4 lot 1200 :  coût = 0.44889959692955017\n",
      "Temps écoulé : 4m 23s\n",
      "-------- > epoch 4 lot 1300 :  coût = 2.5844767093658447\n",
      "Temps écoulé : 4m 26s\n",
      "-------- > epoch 4 lot 1400 :  coût = 4.902103424072266\n",
      "Temps écoulé : 4m 29s\n",
      "-------- > epoch 4 lot 1500 :  coût = 2.780022621154785\n",
      "Temps écoulé : 4m 31s\n",
      "-------- > epoch 4 lot 1600 :  coût = 1.5606839656829834\n",
      "Temps écoulé : 4m 34s\n",
      "-------- > epoch 4 lot 1700 :  coût = 2.5033023357391357\n",
      "Temps écoulé : 4m 37s\n",
      "-------- > epoch 4 lot 1800 :  coût = 2.539816379547119\n",
      "Temps écoulé : 4m 39s\n",
      "-------- > epoch 4 lot 1900 :  coût = 2.35965633392334\n",
      "Temps écoulé : 4m 42s\n",
      "-------- > epoch 4 lot 2000 :  coût = 2.564692735671997\n",
      "Temps écoulé : 4m 45s\n",
      "-------- > epoch 5 lot 0 :  coût = 2.5028932094573975\n",
      "Temps écoulé : 4m 46s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- > epoch 5 lot 100 :  coût = 4.693257808685303\n",
      "Temps écoulé : 4m 49s\n",
      "-------- > epoch 5 lot 200 :  coût = 1.730719804763794\n",
      "Temps écoulé : 4m 52s\n",
      "-------- > epoch 5 lot 300 :  coût = 3.1421780586242676\n",
      "Temps écoulé : 4m 55s\n",
      "-------- > epoch 5 lot 400 :  coût = 2.8268113136291504\n",
      "Temps écoulé : 4m 58s\n",
      "-------- > epoch 5 lot 500 :  coût = 3.4914944171905518\n",
      "Temps écoulé : 5m 0s\n",
      "-------- > epoch 5 lot 600 :  coût = 3.316831588745117\n",
      "Temps écoulé : 5m 3s\n",
      "-------- > epoch 5 lot 700 :  coût = 3.1100542545318604\n",
      "Temps écoulé : 5m 6s\n",
      "-------- > epoch 5 lot 800 :  coût = 2.8205149173736572\n",
      "Temps écoulé : 5m 9s\n",
      "-------- > epoch 5 lot 900 :  coût = 2.6998326778411865\n",
      "Temps écoulé : 5m 12s\n",
      "-------- > epoch 5 lot 1000 :  coût = 2.4686360359191895\n",
      "Temps écoulé : 5m 14s\n",
      "-------- > epoch 5 lot 1100 :  coût = 3.1767237186431885\n",
      "Temps écoulé : 5m 17s\n",
      "-------- > epoch 5 lot 1200 :  coût = 0.40035131573677063\n",
      "Temps écoulé : 5m 20s\n",
      "-------- > epoch 5 lot 1300 :  coût = 2.4153308868408203\n",
      "Temps écoulé : 5m 23s\n",
      "-------- > epoch 5 lot 1400 :  coût = 4.772415637969971\n",
      "Temps écoulé : 5m 25s\n",
      "-------- > epoch 5 lot 1500 :  coût = 2.519134759902954\n",
      "Temps écoulé : 5m 28s\n",
      "-------- > epoch 5 lot 1600 :  coût = 1.4154928922653198\n",
      "Temps écoulé : 5m 31s\n",
      "-------- > epoch 5 lot 1700 :  coût = 2.3398282527923584\n",
      "Temps écoulé : 5m 34s\n",
      "-------- > epoch 5 lot 1800 :  coût = 2.3418960571289062\n",
      "Temps écoulé : 5m 37s\n",
      "-------- > epoch 5 lot 1900 :  coût = 2.046809434890747\n",
      "Temps écoulé : 5m 39s\n",
      "-------- > epoch 5 lot 2000 :  coût = 2.1474995613098145\n",
      "Temps écoulé : 5m 42s\n",
      "-------- > epoch 6 lot 0 :  coût = 2.3485517501831055\n",
      "Temps écoulé : 5m 43s\n",
      "-------- > epoch 6 lot 100 :  coût = 4.546101093292236\n",
      "Temps écoulé : 5m 46s\n",
      "-------- > epoch 6 lot 200 :  coût = 1.490503191947937\n",
      "Temps écoulé : 5m 49s\n",
      "-------- > epoch 6 lot 300 :  coût = 2.8821699619293213\n",
      "Temps écoulé : 5m 52s\n",
      "-------- > epoch 6 lot 400 :  coût = 2.565218925476074\n",
      "Temps écoulé : 5m 55s\n",
      "-------- > epoch 6 lot 500 :  coût = 3.3142685890197754\n",
      "Temps écoulé : 5m 58s\n",
      "-------- > epoch 6 lot 600 :  coût = 3.005854845046997\n",
      "Temps écoulé : 6m 1s\n",
      "-------- > epoch 6 lot 700 :  coût = 2.7143256664276123\n",
      "Temps écoulé : 6m 4s\n",
      "-------- > epoch 6 lot 800 :  coût = 2.645236015319824\n",
      "Temps écoulé : 6m 6s\n",
      "-------- > epoch 6 lot 900 :  coût = 2.4880619049072266\n",
      "Temps écoulé : 6m 9s\n",
      "-------- > epoch 6 lot 1000 :  coût = 2.2948825359344482\n",
      "Temps écoulé : 6m 12s\n",
      "-------- > epoch 6 lot 1100 :  coût = 2.760556936264038\n",
      "Temps écoulé : 6m 15s\n",
      "-------- > epoch 6 lot 1200 :  coût = 0.3682614862918854\n",
      "Temps écoulé : 6m 18s\n",
      "-------- > epoch 6 lot 1300 :  coût = 2.3004660606384277\n",
      "Temps écoulé : 6m 20s\n",
      "-------- > epoch 6 lot 1400 :  coût = 4.645717144012451\n",
      "Temps écoulé : 6m 23s\n",
      "-------- > epoch 6 lot 1500 :  coût = 2.3348770141601562\n",
      "Temps écoulé : 6m 26s\n",
      "-------- > epoch 6 lot 1600 :  coût = 1.3116579055786133\n",
      "Temps écoulé : 6m 29s\n",
      "-------- > epoch 6 lot 1700 :  coût = 2.1958961486816406\n",
      "Temps écoulé : 6m 32s\n",
      "-------- > epoch 6 lot 1800 :  coût = 2.1968955993652344\n",
      "Temps écoulé : 6m 34s\n",
      "-------- > epoch 6 lot 1900 :  coût = 1.8151800632476807\n",
      "Temps écoulé : 6m 37s\n",
      "-------- > epoch 6 lot 2000 :  coût = 1.86767578125\n",
      "Temps écoulé : 6m 40s\n",
      "-------- > epoch 7 lot 0 :  coût = 2.223686456680298\n",
      "Temps écoulé : 6m 41s\n",
      "-------- > epoch 7 lot 100 :  coût = 4.4409871101379395\n",
      "Temps écoulé : 6m 44s\n",
      "-------- > epoch 7 lot 200 :  coût = 1.3186451196670532\n",
      "Temps écoulé : 6m 47s\n",
      "-------- > epoch 7 lot 300 :  coût = 2.659668207168579\n",
      "Temps écoulé : 6m 50s\n",
      "-------- > epoch 7 lot 400 :  coût = 2.3738389015197754\n",
      "Temps écoulé : 6m 53s\n",
      "-------- > epoch 7 lot 500 :  coût = 3.139801025390625\n",
      "Temps écoulé : 6m 56s\n",
      "-------- > epoch 7 lot 600 :  coût = 2.735098123550415\n",
      "Temps écoulé : 6m 59s\n",
      "-------- > epoch 7 lot 700 :  coût = 2.4208219051361084\n",
      "Temps écoulé : 7m 1s\n",
      "-------- > epoch 7 lot 800 :  coût = 2.5033514499664307\n",
      "Temps écoulé : 7m 4s\n",
      "-------- > epoch 7 lot 900 :  coût = 2.315795421600342\n",
      "Temps écoulé : 7m 7s\n",
      "-------- > epoch 7 lot 1000 :  coût = 2.1422040462493896\n",
      "Temps écoulé : 7m 10s\n",
      "-------- > epoch 7 lot 1100 :  coût = 2.45719313621521\n",
      "Temps écoulé : 7m 12s\n",
      "-------- > epoch 7 lot 1200 :  coût = 0.33913248777389526\n",
      "Temps écoulé : 7m 15s\n",
      "-------- > epoch 7 lot 1300 :  coût = 2.191669464111328\n",
      "Temps écoulé : 7m 18s\n",
      "-------- > epoch 7 lot 1400 :  coût = 4.525084495544434\n",
      "Temps écoulé : 7m 21s\n",
      "-------- > epoch 7 lot 1500 :  coût = 2.164177417755127\n",
      "Temps écoulé : 7m 24s\n",
      "-------- > epoch 7 lot 1600 :  coût = 1.2374323606491089\n",
      "Temps écoulé : 7m 26s\n",
      "-------- > epoch 7 lot 1700 :  coût = 2.0661773681640625\n",
      "Temps écoulé : 7m 29s\n",
      "-------- > epoch 7 lot 1800 :  coût = 2.0969314575195312\n",
      "Temps écoulé : 7m 32s\n",
      "-------- > epoch 7 lot 1900 :  coût = 1.6351723670959473\n",
      "Temps écoulé : 7m 35s\n",
      "-------- > epoch 7 lot 2000 :  coût = 1.6669330596923828\n",
      "Temps écoulé : 7m 37s\n",
      "-------- > epoch 8 lot 0 :  coût = 2.1434388160705566\n",
      "Temps écoulé : 7m 38s\n",
      "-------- > epoch 8 lot 100 :  coût = 4.366177558898926\n",
      "Temps écoulé : 7m 41s\n",
      "-------- > epoch 8 lot 200 :  coût = 1.19590163230896\n",
      "Temps écoulé : 7m 44s\n",
      "-------- > epoch 8 lot 300 :  coût = 2.4803178310394287\n",
      "Temps écoulé : 7m 47s\n",
      "-------- > epoch 8 lot 400 :  coût = 2.220625400543213\n",
      "Temps écoulé : 7m 50s\n",
      "-------- > epoch 8 lot 500 :  coût = 2.982332944869995\n",
      "Temps écoulé : 7m 53s\n",
      "-------- > epoch 8 lot 600 :  coût = 2.5081071853637695\n",
      "Temps écoulé : 7m 55s\n",
      "-------- > epoch 8 lot 700 :  coût = 2.176970958709717\n",
      "Temps écoulé : 7m 58s\n",
      "-------- > epoch 8 lot 800 :  coût = 2.3840301036834717\n",
      "Temps écoulé : 8m 1s\n",
      "-------- > epoch 8 lot 900 :  coût = 2.1846697330474854\n",
      "Temps écoulé : 8m 4s\n",
      "-------- > epoch 8 lot 1000 :  coût = 2.0074870586395264\n",
      "Temps écoulé : 8m 7s\n",
      "-------- > epoch 8 lot 1100 :  coût = 2.218722105026245\n",
      "Temps écoulé : 8m 10s\n",
      "-------- > epoch 8 lot 1200 :  coût = 0.3359138071537018\n",
      "Temps écoulé : 8m 13s\n",
      "-------- > epoch 8 lot 1300 :  coût = 2.082303762435913\n",
      "Temps écoulé : 8m 16s\n",
      "-------- > epoch 8 lot 1400 :  coût = 4.417637825012207\n",
      "Temps écoulé : 8m 18s\n",
      "-------- > epoch 8 lot 1500 :  coût = 2.0370032787323\n",
      "Temps écoulé : 8m 21s\n",
      "-------- > epoch 8 lot 1600 :  coût = 1.1827555894851685\n",
      "Temps écoulé : 8m 24s\n",
      "-------- > epoch 8 lot 1700 :  coût = 1.9561055898666382\n",
      "Temps écoulé : 8m 26s\n",
      "-------- > epoch 8 lot 1800 :  coût = 2.024606704711914\n",
      "Temps écoulé : 8m 29s\n",
      "-------- > epoch 8 lot 1900 :  coût = 1.486583948135376\n",
      "Temps écoulé : 8m 32s\n",
      "-------- > epoch 8 lot 2000 :  coût = 1.5087532997131348\n",
      "Temps écoulé : 8m 35s\n",
      "-------- > epoch 9 lot 0 :  coût = 2.0823564529418945\n",
      "Temps écoulé : 8m 36s\n",
      "-------- > epoch 9 lot 100 :  coût = 4.298294544219971\n",
      "Temps écoulé : 8m 39s\n",
      "-------- > epoch 9 lot 200 :  coût = 1.1074254512786865\n",
      "Temps écoulé : 8m 42s\n",
      "-------- > epoch 9 lot 300 :  coût = 2.333685874938965\n",
      "Temps écoulé : 8m 45s\n",
      "-------- > epoch 9 lot 400 :  coût = 2.088209390640259\n",
      "Temps écoulé : 8m 48s\n",
      "-------- > epoch 9 lot 500 :  coût = 2.8560237884521484\n",
      "Temps écoulé : 8m 51s\n",
      "-------- > epoch 9 lot 600 :  coût = 2.3121962547302246\n",
      "Temps écoulé : 8m 53s\n",
      "-------- > epoch 9 lot 700 :  coût = 1.9657917022705078\n",
      "Temps écoulé : 8m 56s\n",
      "-------- > epoch 9 lot 800 :  coût = 2.281680107116699\n",
      "Temps écoulé : 8m 59s\n",
      "-------- > epoch 9 lot 900 :  coût = 2.0680813789367676\n",
      "Temps écoulé : 9m 2s\n",
      "-------- > epoch 9 lot 1000 :  coût = 1.885590672492981\n",
      "Temps écoulé : 9m 5s\n",
      "-------- > epoch 9 lot 1100 :  coût = 2.0161006450653076\n",
      "Temps écoulé : 9m 7s\n",
      "-------- > epoch 9 lot 1200 :  coût = 0.3089718222618103\n",
      "Temps écoulé : 9m 10s\n",
      "-------- > epoch 9 lot 1300 :  coût = 1.9856398105621338\n",
      "Temps écoulé : 9m 13s\n",
      "-------- > epoch 9 lot 1400 :  coût = 4.326120376586914\n",
      "Temps écoulé : 9m 16s\n",
      "-------- > epoch 9 lot 1500 :  coût = 1.8747947216033936\n",
      "Temps écoulé : 9m 19s\n",
      "-------- > epoch 9 lot 1600 :  coût = 1.147606372833252\n",
      "Temps écoulé : 9m 22s\n",
      "-------- > epoch 9 lot 1700 :  coût = 1.8753290176391602\n",
      "Temps écoulé : 9m 24s\n",
      "-------- > epoch 9 lot 1800 :  coût = 1.972097396850586\n",
      "Temps écoulé : 9m 27s\n",
      "-------- > epoch 9 lot 1900 :  coût = 1.3649578094482422\n",
      "Temps écoulé : 9m 30s\n",
      "-------- > epoch 9 lot 2000 :  coût = 1.3817400932312012\n",
      "Temps écoulé : 9m 33s\n",
      "['you', 'know', 'that', \"you'll\", 'always', 'follow', 'and', 'but', 'sometimes', 'in', 'the', 'future', 'where', 'to', 'war', 'and', 'i', 'know', 'all', 'spies', 'at', 'each']\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Réseau de neurones récurrent, modèle de langue par mot, pour paroles de chansons\n",
    "Fichier ColdPlay.csv de https://www.kaggle.com/datasets/deepshah16/song-lyrics-dataset\n",
    "Version avec couche vectorisation de mots et RNN\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(0) # Pour résultats reproductibles\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "taille_sequence = 8\n",
    "\n",
    "# Déterminer si un GPU est disponible\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Entrainement sur ',device)\n",
    "\n",
    "class DatasetParoles(torch.utils.data.Dataset):\n",
    "    \"\"\" Créer un Dataset avec les paroles de la colonne Lyric du fichier nom_fichier\n",
    "    taille_sequence : taille d'une séquence de mots pour le modèle de langue\n",
    "    Le texte est découpé en séquences de la taille taille_sequence\n",
    "    \"\"\"\n",
    "    def __init__(self, nom_fichier, taille_sequence=4):\n",
    "        self.nom_fichier = nom_fichier\n",
    "        self.taille_sequence = taille_sequence\n",
    "        self.mots = self.charger_mots()\n",
    "        self.mots_uniques = self.chercher_mots_uniques()\n",
    "\n",
    "        self.index_a_mot = {index: mot for index, mot in enumerate(self.mots_uniques)}\n",
    "        self.mot_a_index = {mot: index for index, mot in enumerate(self.mots_uniques)}\n",
    "\n",
    "        self.mots_indexes = [self.mot_a_index[w] for w in self.mots]\n",
    "\n",
    "    def charger_mots(self):\n",
    "        dataframe_entrainement = pd.read_csv(self.nom_fichier)\n",
    "        texte_concatene = dataframe_entrainement['Lyric'].str.cat(sep=' ')\n",
    "        return texte_concatene.split(' ')\n",
    "\n",
    "    def chercher_mots_uniques(self):\n",
    "        frequence_mot = Counter(self.mots)\n",
    "        return sorted(frequence_mot, key=frequence_mot.get, reverse=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mots_indexes) - self.taille_sequence\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            torch.tensor(self.mots_indexes[index:index+self.taille_sequence]),\n",
    "            torch.tensor(self.mots_indexes[index+1:index+self.taille_sequence+1]),\n",
    "        )\n",
    "    \n",
    "class Modele(nn.Module):\n",
    "    \"\"\"Modèle de RNR avec une couche vectorisation, suivie d'une couche RNN et d'une couche linéaire\"\"\"\n",
    "    def __init__(self, ds_paroles):\n",
    "        super(Modele, self).__init__()\n",
    "        self.taille_H_RNN = 128\n",
    "        self.taille_vectorisation_mots = 64\n",
    "        self.nombre_couches_RNR = 1\n",
    "\n",
    "        taille_vocabulaire = len(ds_paroles.mots_uniques)\n",
    "        self.vectorisation_mots = nn.Embedding(num_embeddings=taille_vocabulaire,\n",
    "            embedding_dim=self.taille_vectorisation_mots)\n",
    "        self.rnn = nn.RNN(input_size=self.taille_vectorisation_mots,hidden_size=self.taille_H_RNN,\n",
    "            num_layers=self.nombre_couches_RNR,batch_first=True)\n",
    "        self.dense_linaire = nn.Linear(self.taille_H_RNN, taille_vocabulaire)\n",
    "\n",
    "    def forward(self, lot_X, etat_0):\n",
    "        vectorisation = self.vectorisation_mots(lot_X)\n",
    "        lot_Ht, etat = self.rnn(vectorisation, etat_0)\n",
    "        lot_Yt = self.dense_linaire(lot_Ht)\n",
    "        return lot_Yt, etat\n",
    "\n",
    "    def initializer_etat(self, taille_sequence):\n",
    "        return (torch.zeros(self.nombre_couches_RNR, taille_sequence, self.taille_H_RNN))\n",
    "\n",
    "ds_paroles = DatasetParoles(\"ColdPlay.csv\",taille_sequence=taille_sequence)\n",
    "modele = Modele(ds_paroles)\n",
    "# Placer le modèle en mode GPU si possible\n",
    "modele = modele.to(device)\n",
    "    \n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "def entrainer_RNR(ds_paroles, modele, taille_lot=32, epochs=10, taille_sequence=6):\n",
    "    debut = time.time()\n",
    "    modele.train()\n",
    "    dl_paroles = DataLoader(ds_paroles,batch_size=taille_lot)\n",
    "\n",
    "    fonction_cout = nn.CrossEntropyLoss()\n",
    "    optimizeur = optim.Adam(modele.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        for lot, (lot_X, lot_Y) in enumerate(dl_paroles):\n",
    "            lot_X = lot_X.to(device)\n",
    "            lot_Y = lot_Y.to(device)\n",
    "            etat = modele.initializer_etat(lot_X.shape[0])\n",
    "            etat = etat.to(device)\n",
    "            optimizeur.zero_grad()\n",
    "            \n",
    "            lot_Y_predictions, etat = modele(lot_X, etat)\n",
    "            cout = fonction_cout(lot_Y_predictions.transpose(1, 2), lot_Y)\n",
    "            \n",
    "            cout.backward()\n",
    "            optimizeur.step()\n",
    "            if lot%100 == 0:\n",
    "                print(f'-------- > epoch {epoch} lot {lot} :  coût = {cout.item()}')\n",
    "                temps_ecoule = time.time() - debut\n",
    "                print('Temps écoulé : {:.0f}m {:.0f}s'.format(temps_ecoule // 60, temps_ecoule % 60))\n",
    "\n",
    "\n",
    "def predire_stochastique(ds, modele, debut_texte, nb_mots=20):\n",
    "    \"\"\" Prédire une suite de nb_mots à partir de debut_texte selon le modele\"\"\"\n",
    "    mots = debut_texte.split(' ')\n",
    "    modele.eval()\n",
    "    etat = modele.initializer_etat(1)\n",
    "    etat = etat.to(device)\n",
    "    for i in range(0, nb_mots):\n",
    "        lot_X = torch.tensor([[ds.mot_a_index[m] for m in mots[i:]]])\n",
    "        lot_X = lot_X.to(device)\n",
    "        lot_Y_predictions, etat = modele(lot_X, etat)\n",
    "        dernier_mot_Yt = lot_Y_predictions[0][-1]\n",
    "        probs_dernier_mot = torch.nn.functional.softmax(dernier_mot_Yt, dim=0).data\n",
    "        #index_mot_choisi = torch.max(probs_dernier_mot, dim=0)[1].item()\n",
    "        index_mot_choisi = torch.multinomial(probs_dernier_mot, 1)[0].item()\n",
    "        mots.append(ds.index_a_mot[index_mot_choisi])\n",
    "    return mots\n",
    "\n",
    "def predire_max(ds, modele, debut_texte, nb_mots=20):\n",
    "    \"\"\" Prédire une suite de nb_mots à partir de debut_texte selon le modele\"\"\"\n",
    "    mots = debut_texte.split(' ')\n",
    "    modele.eval()\n",
    "    etat = modele.initializer_etat(1)\n",
    "    etat = etat.to(device)\n",
    "    for i in range(0, nb_mots):\n",
    "        lot_X = torch.tensor([[ds.mot_a_index[m] for m in mots[i:]]])\n",
    "        lot_X = lot_X.to(device)\n",
    "        lot_Y_predictions, etat = modele(lot_X, etat)\n",
    "        dernier_mot_Yt = lot_Y_predictions[0][-1]\n",
    "        probs_dernier_mot = torch.nn.functional.softmax(dernier_mot_Yt, dim=0).data\n",
    "        index_mot_choisi = torch.max(probs_dernier_mot, dim=0)[1].item()\n",
    "        mots.append(ds.index_a_mot[index_mot_choisi])\n",
    "    return mots\n",
    "\n",
    "entrainer_RNR(ds_paroles, modele, taille_lot=32, epochs=10, taille_sequence=taille_sequence)\n",
    "print(\"Texte stochastique 1 :\",predire_stochastique(ds_paroles, modele, debut_texte='it was'))\n",
    "print(\"Texte stochastique 2 :\",predire_stochastique(ds_paroles, modele, debut_texte='it was'))\n",
    "print(\"Texte stochastique 3 :\",predire_stochastique(ds_paroles, modele, debut_texte='it was'))\n",
    "print(\"Texte max :\",predire_max(ds_paroles, modele, debut_texte='it was'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
