{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cc4f597",
   "metadata": {},
   "source": [
    "Exemples d'utilisation Transformer avec l'interface Hugging Face.\n",
    "IL faut au préalable installer la bibliothèque Transformer (voir https://huggingface.co/docs/transformers/installation)\n",
    "Voyons d'abord un exemple minimaliste d'utilisation de pipeline pour l'analyse de sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e947065c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb3ce42",
   "metadata": {},
   "source": [
    "La fonction pipeline() charge un modèle déjà entraîné pour une tâche particulière ainsi qu'un Tokenizer approprié"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1f6355d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9996259212493896}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9978412985801697}]\n"
     ]
    }
   ],
   "source": [
    "classifieur = pipeline(\"sentiment-analysis\")\n",
    "texte1 = \"I like going to the movies!\"\n",
    "classifieur(texte1)\n",
    "resultat = classifieur(texte1)\n",
    "print(resultat)\n",
    "texte2 = \"I hate waiting when I call a customer service number.\"\n",
    "resultat = classifieur(texte2)\n",
    "print(resultat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db90e8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9996259212493896},\n",
       " {'label': 'NEGATIVE', 'score': 0.9978412985801697}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste_input = [texte1,texte2]\n",
    "classifieur(liste_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34ce12b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'NEGATIVE', 'score': 0.0003740561078302562},\n",
       "  {'label': 'POSITIVE', 'score': 0.9996259212493896}],\n",
       " [{'label': 'NEGATIVE', 'score': 0.9978412985801697},\n",
       "  {'label': 'POSITIVE', 'score': 0.0021586893126368523}]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifieur_tout_score = pipeline(\"sentiment-analysis\",return_all_scores=True)\n",
    "classifieur_tout_score(liste_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1468943f",
   "metadata": {},
   "source": [
    "Les tâches et leur modèle de défault :\n",
    "https://github.com/huggingface/transformers/blob/71688a8889c4df7dd6d90a65d895ccf4e33a1a56/src/transformers/pipelines.py#L2716-L2804"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24621b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9996259212493896},\n",
       " {'label': 'NEGATIVE', 'score': 0.9978412985801697}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nom_modele = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "classifieur = pipeline(\"sentiment-analysis\", model=nom_modele)\n",
    "classifieur(liste_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19759c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "modele = AutoModelForSequenceClassification.from_pretrained(nom_modele)\n",
    "modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6db1a136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='distilbert-base-uncased-finetuned-sst-2-english', vocab_size=30522, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(nom_modele)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa0ab8a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9996259212493896},\n",
       " {'label': 'NEGATIVE', 'score': 0.9978412985801697}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifieur = pipeline(\"sentiment-analysis\", model=modele, tokenizer=tokenizer)\n",
    "classifieur(liste_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "288b5212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'like', 'going', 'to', 'the', 'movies', '!']\n"
     ]
    }
   ],
   "source": [
    "jetons = tokenizer.tokenize(texte1)\n",
    "print(jetons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e64afa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1045, 2066, 2183, 2000, 1996, 5691, 999]\n"
     ]
    }
   ],
   "source": [
    "jetons_ids = tokenizer.convert_tokens_to_ids(jetons)\n",
    "print(jetons_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dada967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'hate', 'waiting', 'when', 'i', 'call', 'a', 'customer', 'service', 'number', '.']\n"
     ]
    }
   ],
   "source": [
    "jetons = tokenizer.tokenize(texte2)\n",
    "print(jetons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a07948a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1045, 5223, 3403, 2043, 1045, 2655, 1037, 8013, 2326, 2193, 1012]\n"
     ]
    }
   ],
   "source": [
    "jetons_ids = tokenizer.convert_tokens_to_ids(jetons)\n",
    "print(jetons_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d9ffe89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1045, 2066, 2183, 2000, 1996, 5691, 999, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(texte1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bca4719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 101, 1045, 2066, 2183, 2000, 1996, 5691,  999,  102,    0,    0,    0,\n",
      "            0],\n",
      "        [ 101, 1045, 5223, 3403, 2043, 1045, 2655, 1037, 8013, 2326, 2193, 1012,\n",
      "          102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "lot_entree = tokenizer(liste_input,padding=True,truncation=True,max_length=512, return_tensors=\"pt\")\n",
    "print(lot_entree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ceb41256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[-3.8102,  4.0805],\n",
      "        [ 3.3661, -2.7700]]), hidden_states=None, attentions=None)\n",
      "tensor([[3.7406e-04, 9.9963e-01],\n",
      "        [9.9784e-01, 2.1587e-03]])\n",
      "tensor([1, 0])\n",
      "['POSITIVE', 'NEGATIVE']\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    lot_output= modele(**lot_entree) # ** pour passer argument sous forme de dict\n",
    "    print(lot_output)\n",
    "    predictions = F.softmax(lot_output.logits, dim=1)\n",
    "    print(predictions)\n",
    "    resultats = torch.argmax(predictions, dim=1)\n",
    "    print(resultats)\n",
    "    etiquettes = [modele.config.id2label[label_id] for label_id in resultats.tolist()]\n",
    "    print(etiquettes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9667e8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=tensor(0.0013), logits=tensor([[-3.8102,  4.0805],\n",
      "        [ 3.3661, -2.7700]]), hidden_states=None, attentions=None)\n",
      "tensor([[3.7406e-04, 9.9963e-01],\n",
      "        [9.9784e-01, 2.1587e-03]])\n",
      "tensor([1, 0])\n",
      "['POSITIVE', 'NEGATIVE']\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    lot_output= modele(**lot_entree, labels = torch.tensor([1,0])) # etiquettes des classes pour calcul du coût\n",
    "    print(lot_output)\n",
    "    predictions = F.softmax(lot_output.logits, dim=1)\n",
    "    print(predictions)\n",
    "    resultats = torch.argmax(predictions, dim=1)\n",
    "    print(resultats)\n",
    "    etiquettes = [modele.config.id2label[label_id] for label_id in resultats.tolist()]\n",
    "    print(etiquettes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c344e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'positive', 'score': 0.9706764817237854},\n",
       " {'label': 'negative', 'score': 0.9286103248596191}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nom_modele = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "classifieur = pipeline(\"sentiment-analysis\", model=nom_modele)\n",
    "classifieur(liste_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec6bcd92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'positive', 'score': 0.8709720969200134},\n",
       "  {'label': 'neutral', 'score': 0.09320797771215439},\n",
       "  {'label': 'negative', 'score': 0.0358198881149292}],\n",
       " [{'label': 'positive', 'score': 0.09347988665103912},\n",
       "  {'label': 'neutral', 'score': 0.11243458092212677},\n",
       "  {'label': 'negative', 'score': 0.7940855026245117}]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifieur_multilingue = pipeline(\"sentiment-analysis\",\n",
    "    model=\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\", \n",
    "    return_all_scores=True\n",
    ")\n",
    "\n",
    "# français\n",
    "classifieur_multilingue([\"J'aime aller au cinéma\",\"Je déteste le froid hivernal\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa67a286",
   "metadata": {},
   "source": [
    "Les tâches et leur modèle de défault : https://github.com/huggingface/transformers/blob/71688a8889c4df7dd6d90a65d895ccf4e33a1a56/src/transformers/pipelines.py#L2716-L2804"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae39f5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Large language models will be updated in the near future to enhance the accessibility that people have for the new data and data analytics methods.\\n\\nIn the near future, users will see the same data being sent to and from Google+, such as traffic numbers'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generateur_texte = pipeline(\"text-generation\")\n",
    "generateur_texte(\"Large language models will\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52baef73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "modele = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd01776a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
