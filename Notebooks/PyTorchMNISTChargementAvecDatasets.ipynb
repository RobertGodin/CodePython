{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- > epoch 1:  coût moyen entraînement = 0.7042660117149353\n",
      "-------- > epoch 2:  coût moyen entraînement = 0.33543774485588074\n",
      "-------- > epoch 3:  coût moyen entraînement = 0.29535067081451416\n",
      "-------- > epoch 4:  coût moyen entraînement = 0.27018973231315613\n",
      "-------- > epoch 5:  coût moyen entraînement = 0.2502851188182831\n",
      "-------- > epoch 6:  coût moyen entraînement = 0.23262566328048706\n",
      "-------- > epoch 7:  coût moyen entraînement = 0.21765385568141937\n",
      "-------- > epoch 8:  coût moyen entraînement = 0.20479132235050201\n",
      "-------- > epoch 9:  coût moyen entraînement = 0.1935090869665146\n",
      "-------- > epoch 10:  coût moyen entraînement = 0.1830931156873703\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Exemple simple de MNIST avec PyTorch\n",
    "Exemple de nn.Module avec deux couches denses linéaires\n",
    "Boucle d'apprentissage simple\n",
    "Chargement avec torchvision.datasets.MNIST\n",
    "\"\"\"\n",
    "import torch\n",
    "torch.manual_seed(0) # Pour résultats reproductibles\n",
    "\n",
    "# Fonction J d'entropie croisée\n",
    "import torch.nn.functional as F\n",
    "fonction_cout = F.cross_entropy\n",
    "\n",
    "from torch import nn\n",
    "# Définition de l'architecture du RNA\n",
    "class RNASimple(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.couche_lineaire1 = nn.Linear(784, 30)\n",
    "        self.couche_lineaire2 = nn.Linear(30, 10)\n",
    "    def forward(self, lot_X):\n",
    "            lot_X = lot_X.view(lot_X.size()[0], -1)\n",
    "            lot_X = F.relu(self.couche_lineaire1(lot_X))\n",
    "            return self.couche_lineaire2(lot_X)\n",
    "modele = RNASimple()\n",
    "    \n",
    "from torch import optim\n",
    "optimiseur = optim.SGD(modele.parameters(), lr=0.05)\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#Chargement des données\n",
    "ds_ent = torchvision.datasets.MNIST(root = \"./data\", train = True, download = True, transform = transforms.ToTensor())\n",
    "ds_test = torchvision.datasets.MNIST(root = \"./data\", train = False, download = True, transform = transforms.ToTensor())\n",
    "\n",
    "#Création du DataLoader avec le dataset\n",
    "dl_ent = torch.utils.data.DataLoader(ds_ent, batch_size=100, shuffle = True)\n",
    "\n",
    "nb_epochs = 10\n",
    "# Boucle d'apprentissage\n",
    "for epoch in range(nb_epochs):\n",
    "    cout_total_ent = 0 \n",
    "    \n",
    "    # Boucle d'apprentissage par mini-lot pour une epoch\n",
    "    for lot_X, lot_Y in dl_ent:\n",
    "        optimiseur.zero_grad() # Remettre les dérivées à zéro\n",
    "        lot_Y_predictions = modele(lot_X) # Appel de la méthode forward\n",
    "        cout = fonction_cout(lot_Y_predictions, lot_Y)\n",
    "        cout_total_ent +=cout\n",
    "        cout.backward() # Calcul des gradiants par rétropropagation\n",
    "        optimiseur.step() # Mise à jour des paramètres\n",
    "        \n",
    "    cout_moyen_ent = cout_total_ent/len(dl_ent)\n",
    "    print(f'-------- > epoch {epoch+1}:  coût moyen entraînement = {cout_moyen_ent}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
