{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrainement sur  cpu\n",
      "Nombre de chansons anglaises traitées: ALink       270\n",
      "SName       270\n",
      "SLink       270\n",
      "Lyric       270\n",
      "language    270\n",
      "dtype: int64\n",
      "-------- > epoch 0 lot 0 :  coût = 8.619123458862305\n",
      "Temps écoulé : 0m 0s\n",
      "-------- > epoch 0 lot 100 :  coût = 5.610347270965576\n",
      "Temps écoulé : 0m 3s\n",
      "-------- > epoch 0 lot 200 :  coût = 6.325799942016602\n",
      "Temps écoulé : 0m 5s\n",
      "-------- > epoch 0 lot 300 :  coût = 6.413882255554199\n",
      "Temps écoulé : 0m 8s\n",
      "-------- > epoch 0 lot 400 :  coût = 5.1948933601379395\n",
      "Temps écoulé : 0m 11s\n",
      "-------- > epoch 0 lot 500 :  coût = 3.67103910446167\n",
      "Temps écoulé : 0m 14s\n",
      "-------- > epoch 0 lot 600 :  coût = 6.250830173492432\n",
      "Temps écoulé : 0m 16s\n",
      "-------- > epoch 0 lot 700 :  coût = 5.363526344299316\n",
      "Temps écoulé : 0m 19s\n",
      "-------- > epoch 0 lot 800 :  coût = 5.702860355377197\n",
      "Temps écoulé : 0m 22s\n",
      "-------- > epoch 0 lot 900 :  coût = 6.945082187652588\n",
      "Temps écoulé : 0m 25s\n",
      "-------- > epoch 0 lot 1000 :  coût = 5.905039310455322\n",
      "Temps écoulé : 0m 28s\n",
      "-------- > epoch 0 lot 1100 :  coût = 5.536479949951172\n",
      "Temps écoulé : 0m 31s\n",
      "-------- > epoch 0 lot 1200 :  coût = 4.011509895324707\n",
      "Temps écoulé : 0m 34s\n",
      "-------- > epoch 0 lot 1300 :  coût = 6.066995620727539\n",
      "Temps écoulé : 0m 37s\n",
      "-------- > epoch 0 lot 1400 :  coût = 3.721329689025879\n",
      "Temps écoulé : 0m 40s\n",
      "-------- > epoch 0 lot 1500 :  coût = 3.4832942485809326\n",
      "Temps écoulé : 0m 44s\n",
      "-------- > epoch 0 lot 1600 :  coût = 6.630996227264404\n",
      "Temps écoulé : 0m 47s\n",
      "-------- > epoch 0 lot 1700 :  coût = 5.305752754211426\n",
      "Temps écoulé : 0m 50s\n",
      "-------- > epoch 0 lot 1800 :  coût = 6.495715141296387\n",
      "Temps écoulé : 0m 52s\n",
      "-------- > epoch 0 lot 1900 :  coût = 6.088294506072998\n",
      "Temps écoulé : 0m 55s\n",
      "-------- > epoch 0 lot 2000 :  coût = 5.661151885986328\n",
      "Temps écoulé : 0m 58s\n",
      "-------- > epoch 0 lot 2100 :  coût = 5.672917366027832\n",
      "Temps écoulé : 1m 1s\n",
      "-------- > epoch 0 lot 2200 :  coût = 4.203850746154785\n",
      "Temps écoulé : 1m 4s\n",
      "-------- > epoch 0 lot 2300 :  coût = 5.98624324798584\n",
      "Temps écoulé : 1m 7s\n",
      "-------- > epoch 0 lot 2400 :  coût = 5.136961460113525\n",
      "Temps écoulé : 1m 10s\n",
      "-------- > epoch 0 lot 2500 :  coût = 6.154595375061035\n",
      "Temps écoulé : 1m 13s\n",
      "-------- > epoch 0 lot 2600 :  coût = 4.561284065246582\n",
      "Temps écoulé : 1m 16s\n",
      "-------- > epoch 0 lot 2700 :  coût = 5.157598495483398\n",
      "Temps écoulé : 1m 19s\n",
      "-------- > epoch 0 lot 2800 :  coût = 4.778306007385254\n",
      "Temps écoulé : 1m 22s\n",
      "-------- > epoch 0 lot 2900 :  coût = 4.586513996124268\n",
      "Temps écoulé : 1m 25s\n",
      "-------- > epoch 0 lot 3000 :  coût = 5.121696949005127\n",
      "Temps écoulé : 1m 28s\n",
      "-------- > epoch 0 lot 3100 :  coût = 4.555520534515381\n",
      "Temps écoulé : 1m 32s\n",
      "-------- > epoch 0 lot 3200 :  coût = 5.944394588470459\n",
      "Temps écoulé : 1m 35s\n",
      "-------- > epoch 1 lot 0 :  coût = 5.984650611877441\n",
      "Temps écoulé : 1m 35s\n",
      "-------- > epoch 1 lot 100 :  coût = 3.21917724609375\n",
      "Temps écoulé : 1m 38s\n",
      "-------- > epoch 1 lot 200 :  coût = 5.101343154907227\n",
      "Temps écoulé : 1m 41s\n",
      "-------- > epoch 1 lot 300 :  coût = 5.271962642669678\n",
      "Temps écoulé : 1m 44s\n",
      "-------- > epoch 1 lot 400 :  coût = 2.2452468872070312\n",
      "Temps écoulé : 1m 47s\n",
      "-------- > epoch 1 lot 500 :  coût = 1.8765228986740112\n",
      "Temps écoulé : 1m 50s\n",
      "-------- > epoch 1 lot 600 :  coût = 5.443116664886475\n",
      "Temps écoulé : 1m 53s\n",
      "-------- > epoch 1 lot 700 :  coût = 4.40972900390625\n",
      "Temps écoulé : 1m 56s\n",
      "-------- > epoch 1 lot 800 :  coût = 4.878747940063477\n",
      "Temps écoulé : 1m 59s\n",
      "-------- > epoch 1 lot 900 :  coût = 5.824906349182129\n",
      "Temps écoulé : 2m 2s\n",
      "-------- > epoch 1 lot 1000 :  coût = 4.7947797775268555\n",
      "Temps écoulé : 2m 5s\n",
      "-------- > epoch 1 lot 1100 :  coût = 4.816357612609863\n",
      "Temps écoulé : 2m 9s\n",
      "-------- > epoch 1 lot 1200 :  coût = 2.580876588821411\n",
      "Temps écoulé : 2m 12s\n",
      "-------- > epoch 1 lot 1300 :  coût = 4.9616498947143555\n",
      "Temps écoulé : 2m 15s\n",
      "-------- > epoch 1 lot 1400 :  coût = 2.318547487258911\n",
      "Temps écoulé : 2m 18s\n",
      "-------- > epoch 1 lot 1500 :  coût = 1.9316622018814087\n",
      "Temps écoulé : 2m 21s\n",
      "-------- > epoch 1 lot 1600 :  coût = 5.418547630310059\n",
      "Temps écoulé : 2m 24s\n",
      "-------- > epoch 1 lot 1700 :  coût = 4.827336311340332\n",
      "Temps écoulé : 2m 27s\n",
      "-------- > epoch 1 lot 1800 :  coût = 5.845242977142334\n",
      "Temps écoulé : 2m 30s\n",
      "-------- > epoch 1 lot 1900 :  coût = 5.2903361320495605\n",
      "Temps écoulé : 2m 33s\n",
      "-------- > epoch 1 lot 2000 :  coût = 4.4971818923950195\n",
      "Temps écoulé : 2m 36s\n",
      "-------- > epoch 1 lot 2100 :  coût = 4.946597099304199\n",
      "Temps écoulé : 2m 40s\n",
      "-------- > epoch 1 lot 2200 :  coût = 2.6534156799316406\n",
      "Temps écoulé : 2m 43s\n",
      "-------- > epoch 1 lot 2300 :  coût = 4.978626251220703\n",
      "Temps écoulé : 2m 46s\n",
      "-------- > epoch 1 lot 2400 :  coût = 4.669942378997803\n",
      "Temps écoulé : 2m 49s\n",
      "-------- > epoch 1 lot 2500 :  coût = 5.777776718139648\n",
      "Temps écoulé : 2m 53s\n",
      "-------- > epoch 1 lot 2600 :  coût = 3.72159481048584\n",
      "Temps écoulé : 2m 56s\n",
      "-------- > epoch 1 lot 2700 :  coût = 4.83160400390625\n",
      "Temps écoulé : 2m 59s\n",
      "-------- > epoch 1 lot 2800 :  coût = 3.86801815032959\n",
      "Temps écoulé : 3m 2s\n",
      "-------- > epoch 1 lot 2900 :  coût = 3.0702202320098877\n",
      "Temps écoulé : 3m 5s\n",
      "-------- > epoch 1 lot 3000 :  coût = 4.066366672515869\n",
      "Temps écoulé : 3m 8s\n",
      "-------- > epoch 1 lot 3100 :  coût = 4.113219738006592\n",
      "Temps écoulé : 3m 11s\n",
      "-------- > epoch 1 lot 3200 :  coût = 5.471235275268555\n",
      "Temps écoulé : 3m 14s\n",
      "-------- > epoch 2 lot 0 :  coût = 5.576822280883789\n",
      "Temps écoulé : 3m 15s\n",
      "-------- > epoch 2 lot 100 :  coût = 1.9852144718170166\n",
      "Temps écoulé : 3m 17s\n",
      "-------- > epoch 2 lot 200 :  coût = 4.729917049407959\n",
      "Temps écoulé : 3m 21s\n",
      "-------- > epoch 2 lot 300 :  coût = 4.452819347381592\n",
      "Temps écoulé : 3m 24s\n",
      "-------- > epoch 2 lot 400 :  coût = 1.9756518602371216\n",
      "Temps écoulé : 3m 27s\n",
      "-------- > epoch 2 lot 500 :  coût = 1.6128580570220947\n",
      "Temps écoulé : 3m 30s\n",
      "-------- > epoch 2 lot 600 :  coût = 5.040487289428711\n",
      "Temps écoulé : 3m 33s\n",
      "-------- > epoch 2 lot 700 :  coût = 3.9936764240264893\n",
      "Temps écoulé : 3m 36s\n",
      "-------- > epoch 2 lot 800 :  coût = 4.707256317138672\n",
      "Temps écoulé : 3m 39s\n",
      "-------- > epoch 2 lot 900 :  coût = 5.041128158569336\n",
      "Temps écoulé : 3m 42s\n",
      "-------- > epoch 2 lot 1000 :  coût = 4.320450305938721\n",
      "Temps écoulé : 3m 46s\n",
      "-------- > epoch 2 lot 1100 :  coût = 4.399160385131836\n",
      "Temps écoulé : 3m 49s\n",
      "-------- > epoch 2 lot 1200 :  coût = 2.2393229007720947\n",
      "Temps écoulé : 3m 52s\n",
      "-------- > epoch 2 lot 1300 :  coût = 4.619462013244629\n",
      "Temps écoulé : 3m 55s\n",
      "-------- > epoch 2 lot 1400 :  coût = 2.000312089920044\n",
      "Temps écoulé : 3m 58s\n",
      "-------- > epoch 2 lot 1500 :  coût = 1.571903109550476\n",
      "Temps écoulé : 4m 1s\n",
      "-------- > epoch 2 lot 1600 :  coût = 4.915143966674805\n",
      "Temps écoulé : 4m 4s\n",
      "-------- > epoch 2 lot 1700 :  coût = 4.4094953536987305\n",
      "Temps écoulé : 4m 8s\n",
      "-------- > epoch 2 lot 1800 :  coût = 5.288877964019775\n",
      "Temps écoulé : 4m 11s\n",
      "-------- > epoch 2 lot 1900 :  coût = 4.749936580657959\n",
      "Temps écoulé : 4m 14s\n",
      "-------- > epoch 2 lot 2000 :  coût = 3.951005458831787\n",
      "Temps écoulé : 4m 17s\n",
      "-------- > epoch 2 lot 2100 :  coût = 4.438645362854004\n",
      "Temps écoulé : 4m 20s\n",
      "-------- > epoch 2 lot 2200 :  coût = 2.0087664127349854\n",
      "Temps écoulé : 4m 23s\n",
      "-------- > epoch 2 lot 2300 :  coût = 4.206893444061279\n",
      "Temps écoulé : 4m 27s\n",
      "-------- > epoch 2 lot 2400 :  coût = 4.422092914581299\n",
      "Temps écoulé : 4m 30s\n",
      "-------- > epoch 2 lot 2500 :  coût = 5.551848411560059\n",
      "Temps écoulé : 4m 34s\n",
      "-------- > epoch 2 lot 2600 :  coût = 3.1639702320098877\n",
      "Temps écoulé : 4m 37s\n",
      "-------- > epoch 2 lot 2700 :  coût = 4.676900386810303\n",
      "Temps écoulé : 4m 41s\n",
      "-------- > epoch 2 lot 2800 :  coût = 3.432257890701294\n",
      "Temps écoulé : 4m 44s\n",
      "-------- > epoch 2 lot 2900 :  coût = 2.3780815601348877\n",
      "Temps écoulé : 4m 48s\n",
      "-------- > epoch 2 lot 3000 :  coût = 3.729092836380005\n",
      "Temps écoulé : 4m 51s\n",
      "-------- > epoch 2 lot 3100 :  coût = 3.7750444412231445\n",
      "Temps écoulé : 4m 54s\n",
      "-------- > epoch 2 lot 3200 :  coût = 5.122806549072266\n",
      "Temps écoulé : 4m 57s\n",
      "-------- > epoch 3 lot 0 :  coût = 5.163215637207031\n",
      "Temps écoulé : 4m 58s\n",
      "-------- > epoch 3 lot 100 :  coût = 1.4352562427520752\n",
      "Temps écoulé : 5m 1s\n",
      "-------- > epoch 3 lot 200 :  coût = 4.4802165031433105\n",
      "Temps écoulé : 5m 4s\n",
      "-------- > epoch 3 lot 300 :  coût = 3.892732620239258\n",
      "Temps écoulé : 5m 7s\n",
      "-------- > epoch 3 lot 400 :  coût = 1.7261319160461426\n",
      "Temps écoulé : 5m 10s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- > epoch 3 lot 500 :  coût = 1.4800639152526855\n",
      "Temps écoulé : 5m 14s\n",
      "-------- > epoch 3 lot 600 :  coût = 4.693421363830566\n",
      "Temps écoulé : 5m 17s\n",
      "-------- > epoch 3 lot 700 :  coût = 3.6512868404388428\n",
      "Temps écoulé : 5m 20s\n",
      "-------- > epoch 3 lot 800 :  coût = 4.448758602142334\n",
      "Temps écoulé : 5m 24s\n",
      "-------- > epoch 3 lot 900 :  coût = 4.213728904724121\n",
      "Temps écoulé : 5m 27s\n",
      "-------- > epoch 3 lot 1000 :  coût = 4.041592121124268\n",
      "Temps écoulé : 5m 30s\n",
      "-------- > epoch 3 lot 1100 :  coût = 4.2008819580078125\n",
      "Temps écoulé : 5m 33s\n",
      "-------- > epoch 3 lot 1200 :  coût = 2.043600082397461\n",
      "Temps écoulé : 5m 37s\n",
      "-------- > epoch 3 lot 1300 :  coût = 4.228567600250244\n",
      "Temps écoulé : 5m 40s\n",
      "-------- > epoch 3 lot 1400 :  coût = 1.8116390705108643\n",
      "Temps écoulé : 5m 43s\n",
      "-------- > epoch 3 lot 1500 :  coût = 1.3680633306503296\n",
      "Temps écoulé : 5m 47s\n",
      "-------- > epoch 3 lot 1600 :  coût = 4.575756549835205\n",
      "Temps écoulé : 5m 50s\n",
      "-------- > epoch 3 lot 1700 :  coût = 4.172975540161133\n",
      "Temps écoulé : 5m 53s\n",
      "-------- > epoch 3 lot 1800 :  coût = 4.850123405456543\n",
      "Temps écoulé : 5m 56s\n",
      "-------- > epoch 3 lot 1900 :  coût = 4.3617048263549805\n",
      "Temps écoulé : 5m 59s\n",
      "-------- > epoch 3 lot 2000 :  coût = 3.490421772003174\n",
      "Temps écoulé : 6m 2s\n",
      "-------- > epoch 3 lot 2100 :  coût = 4.109042167663574\n",
      "Temps écoulé : 6m 5s\n",
      "-------- > epoch 3 lot 2200 :  coût = 1.7782349586486816\n",
      "Temps écoulé : 6m 8s\n",
      "-------- > epoch 3 lot 2300 :  coût = 3.573528528213501\n",
      "Temps écoulé : 6m 12s\n",
      "-------- > epoch 3 lot 2400 :  coût = 4.24667501449585\n",
      "Temps écoulé : 6m 15s\n",
      "-------- > epoch 3 lot 2500 :  coût = 5.394811630249023\n",
      "Temps écoulé : 6m 18s\n",
      "-------- > epoch 3 lot 2600 :  coût = 2.869903802871704\n",
      "Temps écoulé : 6m 21s\n",
      "-------- > epoch 3 lot 2700 :  coût = 4.588512897491455\n",
      "Temps écoulé : 6m 24s\n",
      "-------- > epoch 3 lot 2800 :  coût = 3.060039758682251\n",
      "Temps écoulé : 6m 27s\n",
      "-------- > epoch 3 lot 2900 :  coût = 2.0609540939331055\n",
      "Temps écoulé : 6m 31s\n",
      "-------- > epoch 3 lot 3000 :  coût = 3.6201131343841553\n",
      "Temps écoulé : 6m 34s\n",
      "-------- > epoch 3 lot 3100 :  coût = 3.5822415351867676\n",
      "Temps écoulé : 6m 37s\n",
      "-------- > epoch 3 lot 3200 :  coût = 4.877309322357178\n",
      "Temps écoulé : 6m 40s\n",
      "-------- > epoch 4 lot 0 :  coût = 4.835118770599365\n",
      "Temps écoulé : 6m 41s\n",
      "-------- > epoch 4 lot 100 :  coût = 1.1857514381408691\n",
      "Temps écoulé : 6m 44s\n",
      "-------- > epoch 4 lot 200 :  coût = 4.391813278198242\n",
      "Temps écoulé : 6m 48s\n",
      "-------- > epoch 4 lot 300 :  coût = 3.453148365020752\n",
      "Temps écoulé : 6m 51s\n",
      "-------- > epoch 4 lot 400 :  coût = 1.5295326709747314\n",
      "Temps écoulé : 6m 54s\n",
      "-------- > epoch 4 lot 500 :  coût = 1.4100042581558228\n",
      "Temps écoulé : 6m 57s\n",
      "-------- > epoch 4 lot 600 :  coût = 4.460429668426514\n",
      "Temps écoulé : 6m 60s\n",
      "-------- > epoch 4 lot 700 :  coût = 3.347522497177124\n",
      "Temps écoulé : 7m 3s\n",
      "-------- > epoch 4 lot 800 :  coût = 4.210769176483154\n",
      "Temps écoulé : 7m 6s\n",
      "-------- > epoch 4 lot 900 :  coût = 3.548943281173706\n",
      "Temps écoulé : 7m 10s\n",
      "-------- > epoch 4 lot 1000 :  coût = 3.8730757236480713\n",
      "Temps écoulé : 7m 13s\n",
      "-------- > epoch 4 lot 1100 :  coût = 4.059717655181885\n",
      "Temps écoulé : 7m 16s\n",
      "-------- > epoch 4 lot 1200 :  coût = 1.9293813705444336\n",
      "Temps écoulé : 7m 19s\n",
      "-------- > epoch 4 lot 1300 :  coût = 4.030027866363525\n",
      "Temps écoulé : 7m 22s\n",
      "-------- > epoch 4 lot 1400 :  coût = 1.7020622491836548\n",
      "Temps écoulé : 7m 26s\n",
      "-------- > epoch 4 lot 1500 :  coût = 1.248064637184143\n",
      "Temps écoulé : 7m 29s\n",
      "-------- > epoch 4 lot 1600 :  coût = 4.331617832183838\n",
      "Temps écoulé : 7m 32s\n",
      "-------- > epoch 4 lot 1700 :  coût = 4.0103888511657715\n",
      "Temps écoulé : 7m 35s\n",
      "-------- > epoch 4 lot 1800 :  coût = 4.573131561279297\n",
      "Temps écoulé : 7m 38s\n",
      "-------- > epoch 4 lot 1900 :  coût = 4.07698917388916\n",
      "Temps écoulé : 7m 41s\n",
      "-------- > epoch 4 lot 2000 :  coût = 3.1259829998016357\n",
      "Temps écoulé : 7m 45s\n",
      "-------- > epoch 4 lot 2100 :  coût = 3.847842216491699\n",
      "Temps écoulé : 7m 48s\n",
      "-------- > epoch 4 lot 2200 :  coût = 1.6722639799118042\n",
      "Temps écoulé : 7m 51s\n",
      "-------- > epoch 4 lot 2300 :  coût = 3.149186849594116\n",
      "Temps écoulé : 7m 54s\n",
      "-------- > epoch 4 lot 2400 :  coût = 4.105726718902588\n",
      "Temps écoulé : 7m 58s\n",
      "-------- > epoch 4 lot 2500 :  coût = 5.2858805656433105\n",
      "Temps écoulé : 8m 1s\n",
      "-------- > epoch 4 lot 2600 :  coût = 2.694413900375366\n",
      "Temps écoulé : 8m 4s\n",
      "-------- > epoch 4 lot 2700 :  coût = 4.504914283752441\n",
      "Temps écoulé : 8m 8s\n",
      "-------- > epoch 4 lot 2800 :  coût = 2.771371364593506\n",
      "Temps écoulé : 8m 11s\n",
      "-------- > epoch 4 lot 2900 :  coût = 1.8234118223190308\n",
      "Temps écoulé : 8m 14s\n",
      "-------- > epoch 4 lot 3000 :  coût = 3.5745716094970703\n",
      "Temps écoulé : 8m 17s\n",
      "-------- > epoch 4 lot 3100 :  coût = 3.439234972000122\n",
      "Temps écoulé : 8m 20s\n",
      "-------- > epoch 4 lot 3200 :  coût = 4.688960075378418\n",
      "Temps écoulé : 8m 24s\n",
      "Texte stochastique 1 : ['we', 'could', 'be', 'where', 'we', 'had', 'it', 'shout', 'say', 'my', 'name', 'back', 'oh', 'capricorn', 'aquarius', 'pisces', 'aries', 'taurus', 'gemini', 'cancer', 'youll', 'never']\n",
      "Texte stochastique 2 : ['we', 'could', 'be', 'there', 'oh', 'og', 'up', 'im', 'growing', 'on', 'up', 'the', 'time', 'the', 'world', 'call', 'the', 'world', 'there', 'like', 'the', 'twice']\n",
      "Texte stochastique 3 : ['we', 'could', 'trade', 'us', 'youll', 'never', 'let', 'you', 'go', 'on', 'fire', 'cancer', 'oh', 'ill', 'ever', 'cause', 'they', 'once', 'through', 'such', 'a', 'lonely']\n",
      "Texte max : ['we', 'could', 'be', 'a', 'sweet', 'dr', 'lil', 'wayne', 'kush', 'i', 'am', 'weak', 'a', 'ring', 'on', 'it', 'if', 'you', 'liked', 'it', 'then', 'you']\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Réseau de neurones récurrent, modèle de langue par mot, pour paroles de chansons\n",
    "Fichier lyrics-data.csv de https://www.kaggle.com/datasets/deepshah16/song-lyrics-dataset\n",
    "Version avec couche vectorisation de mots et RNN\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(0) # Pour résultats reproductibles\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "taille_sequence = 8\n",
    "nombre_textes = 5000\n",
    "\n",
    "# Déterminer si un GPU est disponible\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Entrainement sur ',device)\n",
    "\n",
    "class DatasetSherlockHolmes(torch.utils.data.Dataset):\n",
    "    \"\"\" Créer un Dataset avec les paroles de la colonne Lyric du fichier nom_fichier\n",
    "    taille_sequence : taille d'une séquence de mots pour le modèle de langue\n",
    "    Le texte est découpé en séquences de la taille taille_sequence\n",
    "    \"\"\"\n",
    "    def __init__(self, nombre_textes=100, taille_sequence=4,):\n",
    "        self.nombre_textes = nombre_textes\n",
    "        self.taille_sequence = taille_sequence\n",
    "        self.mots = self.charger_mots()\n",
    "        self.mots_uniques = self.chercher_mots_uniques()\n",
    "\n",
    "        self.index_a_mot = {index: mot for index, mot in enumerate(self.mots_uniques)}\n",
    "        self.mot_a_index = {mot: index for index, mot in enumerate(self.mots_uniques)}\n",
    "\n",
    "        self.mots_indexes = [self.mot_a_index[w] for w in self.mots]\n",
    "\n",
    "    def charger_mots(self):\n",
    "        dataframe_entrainement = pd.read_csv('lyrics-data.csv',nrows=self.nombre_textes)\n",
    "        textes_anglais = dataframe_entrainement[(dataframe_entrainement['language'] == 'en')]\n",
    "        print(\"Nombre de chansons anglaises traitées:\", textes_anglais.count())\n",
    "        texte_concatene = dataframe_entrainement[(dataframe_entrainement['language'] == 'en')].iloc[0:self.nombre_textes]['Lyric'].str.cat(sep=' ')\n",
    "        return re.sub(r'[^\\w\\s]', '', texte_concatene).lower().split()\n",
    "\n",
    "    def chercher_mots_uniques(self):\n",
    "        frequence_mot = Counter(self.mots)\n",
    "        return sorted(frequence_mot, key=frequence_mot.get, reverse=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mots_indexes) - self.taille_sequence\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            torch.tensor(self.mots_indexes[index:index+self.taille_sequence]),\n",
    "            torch.tensor(self.mots_indexes[index+1:index+self.taille_sequence+1]),\n",
    "        )\n",
    "    \n",
    "class Modele(nn.Module):\n",
    "    \"\"\"Modèle de RNR avec une couche vectorisation, suivie d'une couche RNN et d'une couche linéaire\"\"\"\n",
    "    def __init__(self, ds_paroles):\n",
    "        super(Modele, self).__init__()\n",
    "        self.taille_H_RNN = 128\n",
    "        self.taille_vectorisation_mots = 64\n",
    "        self.nombre_couches_RNR = 1\n",
    "\n",
    "        taille_vocabulaire = len(ds_paroles.mots_uniques)\n",
    "        self.vectorisation_mots = nn.Embedding(num_embeddings=taille_vocabulaire,\n",
    "            embedding_dim=self.taille_vectorisation_mots)\n",
    "        self.rnn = nn.RNN(input_size=self.taille_vectorisation_mots,hidden_size=self.taille_H_RNN,\n",
    "            num_layers=self.nombre_couches_RNR,batch_first=True)\n",
    "        self.dense_linaire = nn.Linear(self.taille_H_RNN, taille_vocabulaire)\n",
    "\n",
    "    def forward(self, lot_X, etat_0):\n",
    "        vectorisation = self.vectorisation_mots(lot_X)\n",
    "        lot_Ht, etat = self.rnn(vectorisation, etat_0)\n",
    "        lot_Yt = self.dense_linaire(lot_Ht)\n",
    "        return lot_Yt, etat\n",
    "\n",
    "    def initializer_etat(self, taille_sequence):\n",
    "        return (torch.zeros(self.nombre_couches_RNR, taille_sequence, self.taille_H_RNN))\n",
    "\n",
    "ds_paroles = DatasetParolesLyricsDataEn(nombre_textes = nombre_textes, taille_sequence=taille_sequence)\n",
    "modele = Modele(ds_paroles)\n",
    "# Placer le modèle en mode GPU si possible\n",
    "modele = modele.to(device)\n",
    "    \n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "def entrainer_RNR(ds_paroles, modele, taille_lot=32, epochs=5, taille_sequence=6):\n",
    "    debut = time.time()\n",
    "    modele.train()\n",
    "    dl_paroles = DataLoader(ds_paroles,batch_size=taille_lot)\n",
    "\n",
    "    fonction_cout = nn.CrossEntropyLoss()\n",
    "    optimizeur = optim.Adam(modele.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        for lot, (lot_X, lot_Y) in enumerate(dl_paroles):\n",
    "            lot_X = lot_X.to(device)\n",
    "            lot_Y = lot_Y.to(device)\n",
    "            etat = modele.initializer_etat(lot_X.shape[0])\n",
    "            etat = etat.to(device)\n",
    "            optimizeur.zero_grad()\n",
    "            \n",
    "            lot_Y_predictions, etat = modele(lot_X, etat)\n",
    "            cout = fonction_cout(lot_Y_predictions.transpose(1, 2), lot_Y)\n",
    "            \n",
    "            cout.backward()\n",
    "            optimizeur.step()\n",
    "            if lot%100 == 0:\n",
    "                print(f'-------- > epoch {epoch} lot {lot} :  coût = {cout.item()}')\n",
    "                temps_ecoule = time.time() - debut\n",
    "                print('Temps écoulé : {:.0f}m {:.0f}s'.format(temps_ecoule // 60, temps_ecoule % 60))\n",
    "\n",
    "\n",
    "def predire(ds, modele, debut_texte, nb_mots=20, mode =0):\n",
    "    \"\"\" Prédire une suite de nb_mots à partir de debut_texte selon le modele\"\"\"\n",
    "\n",
    "    mots = debut_texte.split(' ')\n",
    "    modele.eval()\n",
    "    etat = modele.initializer_etat(1)\n",
    "    etat = etat.to(device)\n",
    "    for i in range(0, nb_mots):\n",
    "        lot_X = torch.tensor([[ds.mot_a_index[m] for m in mots[i:]]])\n",
    "        lot_X = lot_X.to(device)\n",
    "        lot_Y_predictions, etat = modele(lot_X, etat)\n",
    "        dernier_mot_Yt = lot_Y_predictions[0][-1]\n",
    "        probs_dernier_mot = torch.nn.functional.softmax(dernier_mot_Yt, dim=0).data\n",
    "        if mode == 0 :\n",
    "            index_mot_choisi = torch.max(probs_dernier_mot, dim=0)[1].item()\n",
    "        else :\n",
    "            index_mot_choisi = torch.multinomial(probs_dernier_mot, 1)[0].item()\n",
    "        mots.append(ds.index_a_mot[index_mot_choisi])\n",
    "    return mots\n",
    "\n",
    "entrainer_RNR(ds_paroles, modele, taille_lot=32, epochs=5, taille_sequence=taille_sequence)\n",
    "print(\"Texte stochastique 1 :\",predire(ds_paroles, modele, debut_texte='we could', mode = 1))\n",
    "print(\"Texte stochastique 2 :\",predire(ds_paroles, modele, debut_texte='we could', mode = 1))\n",
    "print(\"Texte stochastique 3 :\",predire(ds_paroles, modele, debut_texte='we could', mode = 1))\n",
    "print(\"Texte max :\",predire(ds_paroles, modele, debut_texte='we could', mode = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   ALink     100 non-null    object\n",
      " 1   SName     100 non-null    object\n",
      " 2   SLink     100 non-null    object\n",
      " 3   Lyric     100 non-null    object\n",
      " 4   language  100 non-null    object\n",
      "dtypes: object(5)\n",
      "memory usage: 4.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataframe_entrainement = pd.read_csv('lyrics-data.csv',nrows=100)\n",
    "print(dataframe_entrainement.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALink</th>\n",
       "      <th>SName</th>\n",
       "      <th>SLink</th>\n",
       "      <th>Lyric</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Careless Whisper</td>\n",
       "      <td>/ivete-sangalo/careless-whisper.html</td>\n",
       "      <td>I feel so unsure\\nAs I take your hand and lead...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Could You Be Loved / Citação Musical do Rap: S...</td>\n",
       "      <td>/ivete-sangalo/could-you-be-loved-citacao-musi...</td>\n",
       "      <td>Don't let them fool, ya\\nOr even try to school...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Cruisin' (Part. Saulo)</td>\n",
       "      <td>/ivete-sangalo/cruisin-part-saulo.html</td>\n",
       "      <td>Baby, let's cruise, away from here\\nDon't be c...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ALink                                              SName  \\\n",
       "69  /ivete-sangalo/                                   Careless Whisper   \n",
       "86  /ivete-sangalo/  Could You Be Loved / Citação Musical do Rap: S...   \n",
       "88  /ivete-sangalo/                             Cruisin' (Part. Saulo)   \n",
       "\n",
       "                                                SLink  \\\n",
       "69               /ivete-sangalo/careless-whisper.html   \n",
       "86  /ivete-sangalo/could-you-be-loved-citacao-musi...   \n",
       "88             /ivete-sangalo/cruisin-part-saulo.html   \n",
       "\n",
       "                                                Lyric language  \n",
       "69  I feel so unsure\\nAs I take your hand and lead...       en  \n",
       "86  Don't let them fool, ya\\nOr even try to school...       en  \n",
       "88  Baby, let's cruise, away from here\\nDon't be c...       en  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_entrainement[(dataframe_entrainement['language'] == 'en')].iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I feel so unsure\n",
      "As I take your hand and lead you to the dance floor\n",
      "As the music dies, something in your eyes\n",
      "Calls to mind a silver screen\n",
      "And all those sad goodbyes\n",
      "\n",
      "I'm never gonna dance again\n",
      "Guilty feet have got no rhythm\n",
      "Though it's easy to pretend\n",
      "I know you're not a fool\n",
      "\n",
      "Should've known better than to cheat a friend\n",
      "And waste the chance that I've been given\n",
      "So I'm never gonna dance again\n",
      "The way I danced with you\n",
      "\n",
      "Time can never mend\n",
      "The careless whispers of a good friend\n",
      "To the heart and mind\n",
      "Ignorance is kind\n",
      "There's no comfort in the truth\n",
      "Pain is all you'll find\n",
      "\n",
      "I'm never gonna dance again\n",
      "Guilty feet have got no rhythm\n",
      "Though it's easy to pretend\n",
      "I know you're not a fool\n",
      "\n",
      "Should've known better than to cheat a friend\n",
      "And waste this chance that I've been given\n",
      "So I'm never gonna dance again\n",
      "The way I danced with you\n",
      "\n",
      "Never without your love\n",
      "\n",
      "Tonight the music seems so loud\n",
      "I wish that we could lose this crowd\n",
      "Maybe it's better this way\n",
      "We'd hurt each other with the things we'd want to say\n",
      "\n",
      "We could have been so good together\n",
      "We could have lived this dance forever\n",
      "But now who's gonna dance with me?\n",
      "Please stay\n",
      "\n",
      "And I'm never gonna dance again\n",
      "Guilty feet have got no rhythm\n",
      "Though it's easy to pretend\n",
      "I know you're not a fool\n",
      "\n",
      "Should've known better than to cheat a friend\n",
      "And waste the chance that I've been given\n",
      "So I'm never gonna dance again\n",
      "The way I danced with you\n",
      "\n",
      "(Now that you're gone) Now that you're gone\n",
      "(Now that you're gone) What I did's so wrong, so wrong\n",
      "That you had to leave me alone? Don't let them fool, ya\n",
      "Or even try to school, ya! Oh, no!\n",
      "We've got a mind of our own\n",
      "So go to hell if what you? re thinking is not right!\n",
      "Love would never leave us alone\n",
      "A-yin the darkness there must come out to light\n",
      "\n",
      "Could you be loved and be loved?\n",
      "Could you be loved and be loved?\n",
      "\n",
      "Don't let them change ya, oh!\n",
      "Or even rearrange ya! Oh, no!\n",
      "We've got a life to live\n",
      "They say: only, only\n",
      "Only the fittest of the fittest shall survive\n",
      "Stay alive! Oh!\n",
      "\n",
      "Could you be loved and be loved?\n",
      "Could you be loved, wo now! And be loved?\n",
      "\n",
      "Could you be\n",
      "Could you be\n",
      "Could you be loved?\n",
      "\n",
      "Say something!\n",
      "\n",
      "Se ligue na ternura\n",
      "Se ligue no amor\n",
      "Se ligue na ternura\n",
      "Se ligue na cor\n",
      "Se ligue na alegria\n",
      "Se ligue no prazer\n",
      "Se ligue, fique atento, se ligue, fique astral\n",
      "\n",
      "Could you be loved and be loved?\n"
     ]
    }
   ],
   "source": [
    "texte_concatene = dataframe_entrainement[(dataframe_entrainement['language'] == 'en')].iloc[0:2]['Lyric'].str.cat(sep=' ')\n",
    "print(texte_concatene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'texte_concatene' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-f4c6339ce136>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtexte_concatene\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'[^\\w\\s]'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtexte_concatene\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexte_concatene\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'texte_concatene' is not defined"
     ]
    }
   ],
   "source": [
    "import re\n",
    "texte_concatene=re.sub(r'[^\\w\\s]', '', texte_concatene)\n",
    "print(texte_concatene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'feel', 'so', 'unsure', 'as', 'i', 'take', 'your', 'hand', 'and', 'lead', 'you', 'to', 'the', 'dance', 'floor', 'as', 'the', 'music', 'dies', 'something', 'in', 'your', 'eyes', 'calls', 'to', 'mind', 'a', 'silver', 'screen', 'and', 'all', 'those', 'sad', 'goodbyes', 'im', 'never', 'gonna', 'dance', 'again', 'guilty', 'feet', 'have', 'got', 'no', 'rhythm', 'though', 'its', 'easy', 'to', 'pretend', 'i', 'know', 'youre', 'not', 'a', 'fool', 'shouldve', 'known', 'better', 'than', 'to', 'cheat', 'a', 'friend', 'and', 'waste', 'the', 'chance', 'that', 'ive', 'been', 'given', 'so', 'im', 'never', 'gonna', 'dance', 'again', 'the', 'way', 'i', 'danced', 'with', 'you', 'time', 'can', 'never', 'mend', 'the', 'careless', 'whispers', 'of', 'a', 'good', 'friend', 'to', 'the', 'heart', 'and', 'mind', 'ignorance', 'is', 'kind', 'theres', 'no', 'comfort', 'in', 'the', 'truth', 'pain', 'is', 'all', 'youll', 'find', 'im', 'never', 'gonna', 'dance', 'again', 'guilty', 'feet', 'have', 'got', 'no', 'rhythm', 'though', 'its', 'easy', 'to', 'pretend', 'i', 'know', 'youre', 'not', 'a', 'fool', 'shouldve', 'known', 'better', 'than', 'to', 'cheat', 'a', 'friend', 'and', 'waste', 'this', 'chance', 'that', 'ive', 'been', 'given', 'so', 'im', 'never', 'gonna', 'dance', 'again', 'the', 'way', 'i', 'danced', 'with', 'you', 'never', 'without', 'your', 'love', 'tonight', 'the', 'music', 'seems', 'so', 'loud', 'i', 'wish', 'that', 'we', 'could', 'lose', 'this', 'crowd', 'maybe', 'its', 'better', 'this', 'way', 'wed', 'hurt', 'each', 'other', 'with', 'the', 'things', 'wed', 'want', 'to', 'say', 'we', 'could', 'have', 'been', 'so', 'good', 'together', 'we', 'could', 'have', 'lived', 'this', 'dance', 'forever', 'but', 'now', 'whos', 'gonna', 'dance', 'with', 'me', 'please', 'stay', 'and', 'im', 'never', 'gonna', 'dance', 'again', 'guilty', 'feet', 'have', 'got', 'no', 'rhythm', 'though', 'its', 'easy', 'to', 'pretend', 'i', 'know', 'youre', 'not', 'a', 'fool', 'shouldve', 'known', 'better', 'than', 'to', 'cheat', 'a', 'friend', 'and', 'waste', 'the', 'chance', 'that', 'ive', 'been', 'given', 'so', 'im', 'never', 'gonna', 'dance', 'again', 'the', 'way', 'i', 'danced', 'with', 'you', 'now', 'that', 'youre', 'gone', 'now', 'that', 'youre', 'gone', 'now', 'that', 'youre', 'gone', 'what', 'i', 'dids', 'so', 'wrong', 'so', 'wrong', 'that', 'you', 'had', 'to', 'leave', 'me', 'alone', 'dont', 'let', 'them', 'fool', 'ya', 'or', 'even', 'try', 'to', 'school', 'ya', 'oh', 'no', 'weve', 'got', 'a', 'mind', 'of', 'our', 'own', 'so', 'go', 'to', 'hell', 'if', 'what', 'you', 're', 'thinking', 'is', 'not', 'right', 'love', 'would', 'never', 'leave', 'us', 'alone', 'ayin', 'the', 'darkness', 'there', 'must', 'come', 'out', 'to', 'light', 'could', 'you', 'be', 'loved', 'and', 'be', 'loved', 'could', 'you', 'be', 'loved', 'and', 'be', 'loved', 'dont', 'let', 'them', 'change', 'ya', 'oh', 'or', 'even', 'rearrange', 'ya', 'oh', 'no', 'weve', 'got', 'a', 'life', 'to', 'live', 'they', 'say', 'only', 'only', 'only', 'the', 'fittest', 'of', 'the', 'fittest', 'shall', 'survive', 'stay', 'alive', 'oh', 'could', 'you', 'be', 'loved', 'and', 'be', 'loved', 'could', 'you', 'be', 'loved', 'wo', 'now', 'and', 'be', 'loved', 'could', 'you', 'be', 'could', 'you', 'be', 'could', 'you', 'be', 'loved', 'say', 'something', 'se', 'ligue', 'na', 'ternura', 'se', 'ligue', 'no', 'amor', 'se', 'ligue', 'na', 'ternura', 'se', 'ligue', 'na', 'cor', 'se', 'ligue', 'na', 'alegria', 'se', 'ligue', 'no', 'prazer', 'se', 'ligue', 'fique', 'atento', 'se', 'ligue', 'fique', 'astral', 'could', 'you', 'be', 'loved', 'and', 'be', 'loved']\n"
     ]
    }
   ],
   "source": [
    "print(texte_concatene.lower().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'feel',\n",
       " 'so',\n",
       " 'unsure',\n",
       " 'as',\n",
       " 'i',\n",
       " 'take',\n",
       " 'your',\n",
       " 'hand',\n",
       " 'and',\n",
       " 'lead',\n",
       " 'you',\n",
       " 'to',\n",
       " 'the',\n",
       " 'dance',\n",
       " 'floor',\n",
       " 'as',\n",
       " 'the',\n",
       " 'music',\n",
       " 'dies',\n",
       " 'something',\n",
       " 'in',\n",
       " 'your',\n",
       " 'eyes',\n",
       " 'calls',\n",
       " 'to',\n",
       " 'mind',\n",
       " 'a',\n",
       " 'silver',\n",
       " 'screen',\n",
       " 'and',\n",
       " 'all',\n",
       " 'those',\n",
       " 'sad',\n",
       " 'goodbyes',\n",
       " 'im',\n",
       " 'never',\n",
       " 'gonna',\n",
       " 'dance',\n",
       " 'again',\n",
       " 'guilty',\n",
       " 'feet',\n",
       " 'have',\n",
       " 'got',\n",
       " 'no',\n",
       " 'rhythm',\n",
       " 'though',\n",
       " 'its',\n",
       " 'easy',\n",
       " 'to',\n",
       " 'pretend',\n",
       " 'i',\n",
       " 'know',\n",
       " 'youre',\n",
       " 'not',\n",
       " 'a',\n",
       " 'fool',\n",
       " 'shouldve',\n",
       " 'known',\n",
       " 'better',\n",
       " 'than',\n",
       " 'to',\n",
       " 'cheat',\n",
       " 'a',\n",
       " 'friend',\n",
       " 'and',\n",
       " 'waste',\n",
       " 'the',\n",
       " 'chance',\n",
       " 'that',\n",
       " 'ive',\n",
       " 'been',\n",
       " 'given',\n",
       " 'so',\n",
       " 'im',\n",
       " 'never',\n",
       " 'gonna',\n",
       " 'dance',\n",
       " 'again',\n",
       " 'the',\n",
       " 'way',\n",
       " 'i',\n",
       " 'danced',\n",
       " 'with',\n",
       " 'you',\n",
       " 'time',\n",
       " 'can',\n",
       " 'never',\n",
       " 'mend',\n",
       " 'the',\n",
       " 'careless',\n",
       " 'whispers',\n",
       " 'of',\n",
       " 'a',\n",
       " 'good',\n",
       " 'friend',\n",
       " 'to',\n",
       " 'the',\n",
       " 'heart',\n",
       " 'and',\n",
       " 'mind',\n",
       " 'ignorance',\n",
       " 'is',\n",
       " 'kind',\n",
       " 'theres',\n",
       " 'no',\n",
       " 'comfort',\n",
       " 'in',\n",
       " 'the',\n",
       " 'truth',\n",
       " 'pain',\n",
       " 'is',\n",
       " 'all',\n",
       " 'youll',\n",
       " 'find',\n",
       " 'im',\n",
       " 'never',\n",
       " 'gonna',\n",
       " 'dance',\n",
       " 'again',\n",
       " 'guilty',\n",
       " 'feet',\n",
       " 'have',\n",
       " 'got',\n",
       " 'no',\n",
       " 'rhythm',\n",
       " 'though',\n",
       " 'its',\n",
       " 'easy',\n",
       " 'to',\n",
       " 'pretend',\n",
       " 'i',\n",
       " 'know',\n",
       " 'youre',\n",
       " 'not',\n",
       " 'a',\n",
       " 'fool',\n",
       " 'shouldve',\n",
       " 'known',\n",
       " 'better',\n",
       " 'than',\n",
       " 'to',\n",
       " 'cheat',\n",
       " 'a',\n",
       " 'friend',\n",
       " 'and',\n",
       " 'waste',\n",
       " 'this',\n",
       " 'chance',\n",
       " 'that',\n",
       " 'ive',\n",
       " 'been',\n",
       " 'given',\n",
       " 'so',\n",
       " 'im',\n",
       " 'never',\n",
       " 'gonna',\n",
       " 'dance',\n",
       " 'again',\n",
       " 'the',\n",
       " 'way',\n",
       " 'i',\n",
       " 'danced',\n",
       " 'with',\n",
       " 'you',\n",
       " 'never',\n",
       " 'without',\n",
       " 'your',\n",
       " 'love',\n",
       " 'tonight',\n",
       " 'the',\n",
       " 'music',\n",
       " 'seems',\n",
       " 'so',\n",
       " 'loud',\n",
       " 'i',\n",
       " 'wish',\n",
       " 'that',\n",
       " 'we',\n",
       " 'could',\n",
       " 'lose',\n",
       " 'this',\n",
       " 'crowd',\n",
       " 'maybe',\n",
       " 'its',\n",
       " 'better',\n",
       " 'this',\n",
       " 'way',\n",
       " 'wed',\n",
       " 'hurt',\n",
       " 'each',\n",
       " 'other',\n",
       " 'with',\n",
       " 'the',\n",
       " 'things',\n",
       " 'wed',\n",
       " 'want',\n",
       " 'to',\n",
       " 'say',\n",
       " 'we',\n",
       " 'could',\n",
       " 'have',\n",
       " 'been',\n",
       " 'so',\n",
       " 'good',\n",
       " 'together',\n",
       " 'we',\n",
       " 'could',\n",
       " 'have',\n",
       " 'lived',\n",
       " 'this',\n",
       " 'dance',\n",
       " 'forever',\n",
       " 'but',\n",
       " 'now',\n",
       " 'whos',\n",
       " 'gonna',\n",
       " 'dance',\n",
       " 'with',\n",
       " 'me',\n",
       " 'please',\n",
       " 'stay',\n",
       " 'and',\n",
       " 'im',\n",
       " 'never',\n",
       " 'gonna',\n",
       " 'dance',\n",
       " 'again',\n",
       " 'guilty',\n",
       " 'feet',\n",
       " 'have',\n",
       " 'got',\n",
       " 'no',\n",
       " 'rhythm',\n",
       " 'though',\n",
       " 'its',\n",
       " 'easy',\n",
       " 'to',\n",
       " 'pretend',\n",
       " 'i',\n",
       " 'know',\n",
       " 'youre',\n",
       " 'not',\n",
       " 'a',\n",
       " 'fool',\n",
       " 'shouldve',\n",
       " 'known',\n",
       " 'better',\n",
       " 'than',\n",
       " 'to',\n",
       " 'cheat',\n",
       " 'a',\n",
       " 'friend',\n",
       " 'and',\n",
       " 'waste',\n",
       " 'the',\n",
       " 'chance',\n",
       " 'that',\n",
       " 'ive',\n",
       " 'been',\n",
       " 'given',\n",
       " 'so',\n",
       " 'im',\n",
       " 'never',\n",
       " 'gonna',\n",
       " 'dance',\n",
       " 'again',\n",
       " 'the',\n",
       " 'way',\n",
       " 'i',\n",
       " 'danced',\n",
       " 'with',\n",
       " 'you',\n",
       " 'now',\n",
       " 'that',\n",
       " 'youre',\n",
       " 'gone',\n",
       " 'now',\n",
       " 'that',\n",
       " 'youre',\n",
       " 'gone',\n",
       " 'now',\n",
       " 'that',\n",
       " 'youre',\n",
       " 'gone',\n",
       " 'what',\n",
       " 'i',\n",
       " 'dids',\n",
       " 'so',\n",
       " 'wrong',\n",
       " 'so',\n",
       " 'wrong',\n",
       " 'that',\n",
       " 'you',\n",
       " 'had',\n",
       " 'to',\n",
       " 'leave',\n",
       " 'me',\n",
       " 'alone',\n",
       " 'dont',\n",
       " 'let',\n",
       " 'them',\n",
       " 'fool',\n",
       " 'ya',\n",
       " 'or',\n",
       " 'even',\n",
       " 'try',\n",
       " 'to',\n",
       " 'school',\n",
       " 'ya',\n",
       " 'oh',\n",
       " 'no',\n",
       " 'weve',\n",
       " 'got',\n",
       " 'a',\n",
       " 'mind',\n",
       " 'of',\n",
       " 'our',\n",
       " 'own',\n",
       " 'so',\n",
       " 'go',\n",
       " 'to',\n",
       " 'hell',\n",
       " 'if',\n",
       " 'what',\n",
       " 'you',\n",
       " 're',\n",
       " 'thinking',\n",
       " 'is',\n",
       " 'not',\n",
       " 'right',\n",
       " 'love',\n",
       " 'would',\n",
       " 'never',\n",
       " 'leave',\n",
       " 'us',\n",
       " 'alone',\n",
       " 'ayin',\n",
       " 'the',\n",
       " 'darkness',\n",
       " 'there',\n",
       " 'must',\n",
       " 'come',\n",
       " 'out',\n",
       " 'to',\n",
       " 'light',\n",
       " 'could',\n",
       " 'you',\n",
       " 'be',\n",
       " 'loved',\n",
       " 'and',\n",
       " 'be',\n",
       " 'loved',\n",
       " 'could',\n",
       " 'you',\n",
       " 'be',\n",
       " 'loved',\n",
       " 'and',\n",
       " 'be',\n",
       " 'loved',\n",
       " 'dont',\n",
       " 'let',\n",
       " 'them',\n",
       " 'change',\n",
       " 'ya',\n",
       " 'oh',\n",
       " 'or',\n",
       " 'even',\n",
       " 'rearrange',\n",
       " 'ya',\n",
       " 'oh',\n",
       " 'no',\n",
       " 'weve',\n",
       " 'got',\n",
       " 'a',\n",
       " 'life',\n",
       " 'to',\n",
       " 'live',\n",
       " 'they',\n",
       " 'say',\n",
       " 'only',\n",
       " 'only',\n",
       " 'only',\n",
       " 'the',\n",
       " 'fittest',\n",
       " 'of',\n",
       " 'the',\n",
       " 'fittest',\n",
       " 'shall',\n",
       " 'survive',\n",
       " 'stay',\n",
       " 'alive',\n",
       " 'oh',\n",
       " 'could',\n",
       " 'you',\n",
       " 'be',\n",
       " 'loved',\n",
       " 'and',\n",
       " 'be',\n",
       " 'loved',\n",
       " 'could',\n",
       " 'you',\n",
       " 'be',\n",
       " 'loved',\n",
       " 'wo',\n",
       " 'now',\n",
       " 'and',\n",
       " 'be',\n",
       " 'loved',\n",
       " 'could',\n",
       " 'you',\n",
       " 'be',\n",
       " 'could',\n",
       " 'you',\n",
       " 'be',\n",
       " 'could',\n",
       " 'you',\n",
       " 'be',\n",
       " 'loved',\n",
       " 'say',\n",
       " 'something',\n",
       " 'se',\n",
       " 'ligue',\n",
       " 'na',\n",
       " 'ternura',\n",
       " 'se',\n",
       " 'ligue',\n",
       " 'no',\n",
       " 'amor',\n",
       " 'se',\n",
       " 'ligue',\n",
       " 'na',\n",
       " 'ternura',\n",
       " 'se',\n",
       " 'ligue',\n",
       " 'na',\n",
       " 'cor',\n",
       " 'se',\n",
       " 'ligue',\n",
       " 'na',\n",
       " 'alegria',\n",
       " 'se',\n",
       " 'ligue',\n",
       " 'no',\n",
       " 'prazer',\n",
       " 'se',\n",
       " 'ligue',\n",
       " 'fique',\n",
       " 'atento',\n",
       " 'se',\n",
       " 'ligue',\n",
       " 'fique',\n",
       " 'astral',\n",
       " 'could',\n",
       " 'you',\n",
       " 'be',\n",
       " 'loved',\n",
       " 'and',\n",
       " 'be',\n",
       " 'loved']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texte_concatene = dataframe_entrainement[(dataframe_entrainement['language'] == 'en')].iloc[0:2]['Lyric'].str.cat(sep=' ')\n",
    "re.sub(r'[^\\w\\s]', '', texte_concatene).lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de chansons anglaises traitées: ALink       270\n",
      "SName       270\n",
      "SLink       270\n",
      "Lyric       270\n",
      "language    270\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "ds_paroles = DatasetParolesLyricsDataEn(nombre_textes = nombre_textes, taille_sequence=taille_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([   1,   56,   21, 3031,  146,    1,   66,   13]),\n",
       " tensor([  56,   21, 3031,  146,    1,   66,   13,  273]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_paroles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
