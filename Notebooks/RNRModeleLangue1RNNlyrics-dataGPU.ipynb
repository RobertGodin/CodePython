{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrainement sur  cpu\n",
      "-------- > epoch 0 lot 0 :  coût = 7.972325801849365\n",
      "Temps écoulé : 0m 0s\n",
      "-------- > epoch 0 lot 100 :  coût = 5.107701778411865\n",
      "Temps écoulé : 0m 2s\n",
      "-------- > epoch 0 lot 200 :  coût = 6.186596870422363\n",
      "Temps écoulé : 0m 5s\n",
      "-------- > epoch 0 lot 300 :  coût = 6.162123680114746\n",
      "Temps écoulé : 0m 7s\n",
      "-------- > epoch 0 lot 400 :  coût = 5.290503025054932\n",
      "Temps écoulé : 0m 10s\n",
      "-------- > epoch 0 lot 500 :  coût = 3.3843472003936768\n",
      "Temps écoulé : 0m 12s\n",
      "-------- > epoch 0 lot 600 :  coût = 6.347045421600342\n",
      "Temps écoulé : 0m 14s\n",
      "-------- > epoch 0 lot 700 :  coût = 5.083999156951904\n",
      "Temps écoulé : 0m 17s\n",
      "-------- > epoch 0 lot 800 :  coût = 5.900958061218262\n",
      "Temps écoulé : 0m 19s\n",
      "-------- > epoch 0 lot 900 :  coût = 6.766435623168945\n",
      "Temps écoulé : 0m 21s\n",
      "-------- > epoch 0 lot 1000 :  coût = 5.8724517822265625\n",
      "Temps écoulé : 0m 24s\n",
      "-------- > epoch 1 lot 0 :  coût = 5.9766106605529785\n",
      "Temps écoulé : 0m 25s\n",
      "-------- > epoch 1 lot 100 :  coût = 2.891873836517334\n",
      "Temps écoulé : 0m 28s\n",
      "-------- > epoch 1 lot 200 :  coût = 5.097067832946777\n",
      "Temps écoulé : 0m 30s\n",
      "-------- > epoch 1 lot 300 :  coût = 5.332547664642334\n",
      "Temps écoulé : 0m 33s\n",
      "-------- > epoch 1 lot 400 :  coût = 2.737173080444336\n",
      "Temps écoulé : 0m 35s\n",
      "-------- > epoch 1 lot 500 :  coût = 2.2369675636291504\n",
      "Temps écoulé : 0m 38s\n",
      "-------- > epoch 1 lot 600 :  coût = 6.071279048919678\n",
      "Temps écoulé : 0m 40s\n",
      "-------- > epoch 1 lot 700 :  coût = 4.139906883239746\n",
      "Temps écoulé : 0m 43s\n",
      "-------- > epoch 1 lot 800 :  coût = 5.339705944061279\n",
      "Temps écoulé : 0m 45s\n",
      "-------- > epoch 1 lot 900 :  coût = 5.53289794921875\n",
      "Temps écoulé : 0m 48s\n",
      "-------- > epoch 1 lot 1000 :  coût = 4.644636631011963\n",
      "Temps écoulé : 0m 50s\n",
      "-------- > epoch 2 lot 0 :  coût = 5.592682838439941\n",
      "Temps écoulé : 0m 52s\n",
      "-------- > epoch 2 lot 100 :  coût = 1.673472285270691\n",
      "Temps écoulé : 0m 54s\n",
      "-------- > epoch 2 lot 200 :  coût = 4.682059288024902\n",
      "Temps écoulé : 0m 57s\n",
      "-------- > epoch 2 lot 300 :  coût = 4.855927467346191\n",
      "Temps écoulé : 0m 59s\n",
      "-------- > epoch 2 lot 400 :  coût = 2.332932710647583\n",
      "Temps écoulé : 1m 2s\n",
      "-------- > epoch 2 lot 500 :  coût = 1.726752758026123\n",
      "Temps écoulé : 1m 5s\n",
      "-------- > epoch 2 lot 600 :  coût = 5.772730827331543\n",
      "Temps écoulé : 1m 7s\n",
      "-------- > epoch 2 lot 700 :  coût = 3.6218838691711426\n",
      "Temps écoulé : 1m 10s\n",
      "-------- > epoch 2 lot 800 :  coût = 4.90578556060791\n",
      "Temps écoulé : 1m 12s\n",
      "-------- > epoch 2 lot 900 :  coût = 4.655130386352539\n",
      "Temps écoulé : 1m 15s\n",
      "-------- > epoch 2 lot 1000 :  coût = 3.9059109687805176\n",
      "Temps écoulé : 1m 17s\n",
      "-------- > epoch 3 lot 0 :  coût = 5.194221496582031\n",
      "Temps écoulé : 1m 19s\n",
      "-------- > epoch 3 lot 100 :  coût = 1.2253001928329468\n",
      "Temps écoulé : 1m 21s\n",
      "-------- > epoch 3 lot 200 :  coût = 4.429529666900635\n",
      "Temps écoulé : 1m 24s\n",
      "-------- > epoch 3 lot 300 :  coût = 4.374758720397949\n",
      "Temps écoulé : 1m 26s\n",
      "-------- > epoch 3 lot 400 :  coût = 2.197388172149658\n",
      "Temps écoulé : 1m 29s\n",
      "-------- > epoch 3 lot 500 :  coût = 1.5502283573150635\n",
      "Temps écoulé : 1m 31s\n",
      "-------- > epoch 3 lot 600 :  coût = 5.481668472290039\n",
      "Temps écoulé : 1m 34s\n",
      "-------- > epoch 3 lot 700 :  coût = 3.2429795265197754\n",
      "Temps écoulé : 1m 37s\n",
      "-------- > epoch 3 lot 800 :  coût = 4.539795875549316\n",
      "Temps écoulé : 1m 39s\n",
      "-------- > epoch 3 lot 900 :  coût = 3.89591646194458\n",
      "Temps écoulé : 1m 41s\n",
      "-------- > epoch 3 lot 1000 :  coût = 3.401129722595215\n",
      "Temps écoulé : 1m 44s\n",
      "-------- > epoch 4 lot 0 :  coût = 4.819510459899902\n",
      "Temps écoulé : 1m 45s\n",
      "-------- > epoch 4 lot 100 :  coût = 1.0050240755081177\n",
      "Temps écoulé : 1m 48s\n",
      "-------- > epoch 4 lot 200 :  coût = 4.239857196807861\n",
      "Temps écoulé : 1m 50s\n",
      "-------- > epoch 4 lot 300 :  coût = 3.883131742477417\n",
      "Temps écoulé : 1m 53s\n",
      "-------- > epoch 4 lot 400 :  coût = 2.0298707485198975\n",
      "Temps écoulé : 1m 55s\n",
      "-------- > epoch 4 lot 500 :  coût = 1.4634524583816528\n",
      "Temps écoulé : 1m 58s\n",
      "-------- > epoch 4 lot 600 :  coût = 5.2272868156433105\n",
      "Temps écoulé : 2m 0s\n",
      "-------- > epoch 4 lot 700 :  coût = 2.956352710723877\n",
      "Temps écoulé : 2m 3s\n",
      "-------- > epoch 4 lot 800 :  coût = 4.251155853271484\n",
      "Temps écoulé : 2m 5s\n",
      "-------- > epoch 4 lot 900 :  coût = 3.254307508468628\n",
      "Temps écoulé : 2m 7s\n",
      "-------- > epoch 4 lot 1000 :  coût = 3.088444232940674\n",
      "Temps écoulé : 2m 10s\n",
      "Texte stochastique 1 : ['we', 'could', 'speck', 'each', 'other', 'thank', 'god', 'you', 'dont', 'know', 'give', 'you', 'hey', 'ill', 'you', 'want', 'stay', 'day', 'lonely', 'we', 'are', 'black']\n",
      "Texte stochastique 2 : ['we', 'could', 'way', 'you', 'oh', 'oh', 'oh', 'oh', 'ohoh', 'oh', 'oh', 'it', 'when', 'you', 'i', 'dont', 'believe', 'colombiana', 'long', 'not', 'be', 'the']\n",
      "Texte stochastique 3 : ['we', 'could', 'care', 'black', 'you', 'to', 'on', 'the', 'wall', 'is', 'known', 'baby', 'good', 'lookin', 'out', 'two', 'teach', 'tell', 'your', 'actual', 'i', 'miss']\n",
      "Texte max : ['we', 'could', 'live', 'the', 'riddle', 'the', 'flavor', 'mmh', 'baby', 'wont', 'you', 'hold', 'on', 'to', 'me', 'hold', 'on', 'to', 'me', 'hold', 'on', 'to']\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Réseau de neurones récurrent, modèle de langue par mot, pour paroles de chansons\n",
    "Fichier lyrics-data.csv de https://www.kaggle.com/datasets/deepshah16/song-lyrics-dataset\n",
    "Version avec couche vectorisation de mots et RNN\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(0) # Pour résultats reproductibles\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "taille_sequence = 8\n",
    "nombre_textes = 100\n",
    "\n",
    "# Déterminer si un GPU est disponible\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Entrainement sur ',device)\n",
    "\n",
    "class DatasetParolesLyricsDataEn(torch.utils.data.Dataset):\n",
    "    \"\"\" Créer un Dataset avec les paroles de la colonne Lyric du fichier nom_fichier\n",
    "    taille_sequence : taille d'une séquence de mots pour le modèle de langue\n",
    "    Le texte est découpé en séquences de la taille taille_sequence\n",
    "    \"\"\"\n",
    "    def __init__(self, nombre_textes=100, taille_sequence=4,):\n",
    "        self.nombre_textes = nombre_textes\n",
    "        self.taille_sequence = taille_sequence\n",
    "        self.mots = self.charger_mots()\n",
    "        self.mots_uniques = self.chercher_mots_uniques()\n",
    "\n",
    "        self.index_a_mot = {index: mot for index, mot in enumerate(self.mots_uniques)}\n",
    "        self.mot_a_index = {mot: index for index, mot in enumerate(self.mots_uniques)}\n",
    "\n",
    "        self.mots_indexes = [self.mot_a_index[w] for w in self.mots]\n",
    "\n",
    "    def charger_mots(self):\n",
    "        dataframe_entrainement = pd.read_csv('lyrics-data.csv')\n",
    "        texte_concatene = dataframe_entrainement[(dataframe_entrainement['language'] == 'en')].iloc[0:self.nombre_textes]['Lyric'].str.cat(sep=' ')\n",
    "        return re.sub(r'[^\\w\\s]', '', texte_concatene).lower().split()\n",
    "\n",
    "    def chercher_mots_uniques(self):\n",
    "        frequence_mot = Counter(self.mots)\n",
    "        return sorted(frequence_mot, key=frequence_mot.get, reverse=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mots_indexes) - self.taille_sequence\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            torch.tensor(self.mots_indexes[index:index+self.taille_sequence]),\n",
    "            torch.tensor(self.mots_indexes[index+1:index+self.taille_sequence+1]),\n",
    "        )\n",
    "    \n",
    "class Modele(nn.Module):\n",
    "    \"\"\"Modèle de RNR avec une couche vectorisation, suivie d'une couche RNN et d'une couche linéaire\"\"\"\n",
    "    def __init__(self, ds_paroles):\n",
    "        super(Modele, self).__init__()\n",
    "        self.taille_H_RNN = 128\n",
    "        self.taille_vectorisation_mots = 64\n",
    "        self.nombre_couches_RNR = 1\n",
    "\n",
    "        taille_vocabulaire = len(ds_paroles.mots_uniques)\n",
    "        self.vectorisation_mots = nn.Embedding(num_embeddings=taille_vocabulaire,\n",
    "            embedding_dim=self.taille_vectorisation_mots)\n",
    "        self.rnn = nn.RNN(input_size=self.taille_vectorisation_mots,hidden_size=self.taille_H_RNN,\n",
    "            num_layers=self.nombre_couches_RNR,batch_first=True)\n",
    "        self.dense_linaire = nn.Linear(self.taille_H_RNN, taille_vocabulaire)\n",
    "\n",
    "    def forward(self, lot_X, etat_0):\n",
    "        vectorisation = self.vectorisation_mots(lot_X)\n",
    "        lot_Ht, etat = self.rnn(vectorisation, etat_0)\n",
    "        lot_Yt = self.dense_linaire(lot_Ht)\n",
    "        return lot_Yt, etat\n",
    "\n",
    "    def initializer_etat(self, taille_sequence):\n",
    "        return (torch.zeros(self.nombre_couches_RNR, taille_sequence, self.taille_H_RNN))\n",
    "\n",
    "ds_paroles = DatasetParolesLyricsDataEn(nombre_textes = nombre_textes, taille_sequence=taille_sequence)\n",
    "modele = Modele(ds_paroles)\n",
    "# Placer le modèle en mode GPU si possible\n",
    "modele = modele.to(device)\n",
    "    \n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "def entrainer_RNR(ds_paroles, modele, taille_lot=32, epochs=5, taille_sequence=6):\n",
    "    debut = time.time()\n",
    "    modele.train()\n",
    "    dl_paroles = DataLoader(ds_paroles,batch_size=taille_lot)\n",
    "\n",
    "    fonction_cout = nn.CrossEntropyLoss()\n",
    "    optimizeur = optim.Adam(modele.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        for lot, (lot_X, lot_Y) in enumerate(dl_paroles):\n",
    "            lot_X = lot_X.to(device)\n",
    "            lot_Y = lot_Y.to(device)\n",
    "            etat = modele.initializer_etat(lot_X.shape[0])\n",
    "            etat = etat.to(device)\n",
    "            optimizeur.zero_grad()\n",
    "            \n",
    "            lot_Y_predictions, etat = modele(lot_X, etat)\n",
    "            cout = fonction_cout(lot_Y_predictions.transpose(1, 2), lot_Y)\n",
    "            \n",
    "            cout.backward()\n",
    "            optimizeur.step()\n",
    "            if lot%100 == 0:\n",
    "                print(f'-------- > epoch {epoch} lot {lot} :  coût = {cout.item()}')\n",
    "                temps_ecoule = time.time() - debut\n",
    "                print('Temps écoulé : {:.0f}m {:.0f}s'.format(temps_ecoule // 60, temps_ecoule % 60))\n",
    "\n",
    "\n",
    "def predire(ds, modele, debut_texte, nb_mots=20, mode =0):\n",
    "    \"\"\" Prédire une suite de nb_mots à partir de debut_texte selon le modele\"\"\"\n",
    "\n",
    "    mots = debut_texte.split(' ')\n",
    "    modele.eval()\n",
    "    etat = modele.initializer_etat(1)\n",
    "    etat = etat.to(device)\n",
    "    for i in range(0, nb_mots):\n",
    "        lot_X = torch.tensor([[ds.mot_a_index[m] for m in mots[i:]]])\n",
    "        lot_X = lot_X.to(device)\n",
    "        lot_Y_predictions, etat = modele(lot_X, etat)\n",
    "        dernier_mot_Yt = lot_Y_predictions[0][-1]\n",
    "        probs_dernier_mot = torch.nn.functional.softmax(dernier_mot_Yt, dim=0).data\n",
    "        if mode == 0 :\n",
    "            index_mot_choisi = torch.max(probs_dernier_mot, dim=0)[1].item()\n",
    "        else :\n",
    "            index_mot_choisi = torch.multinomial(probs_dernier_mot, 1)[0].item()\n",
    "        mots.append(ds.index_a_mot[index_mot_choisi])\n",
    "    return mots\n",
    "\n",
    "entrainer_RNR(ds_paroles, modele, taille_lot=32, epochs=5, taille_sequence=taille_sequence)\n",
    "print(\"Texte stochastique 1 :\",predire(ds_paroles, modele, debut_texte='we could', mode = 1))\n",
    "print(\"Texte stochastique 2 :\",predire(ds_paroles, modele, debut_texte='we could', mode = 1))\n",
    "print(\"Texte stochastique 3 :\",predire(ds_paroles, modele, debut_texte='we could', mode = 1))\n",
    "print(\"Texte max :\",predire(ds_paroles, modele, debut_texte='we could', mode = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 379931 entries, 0 to 379930\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   ALink     379930 non-null  object\n",
      " 1   SName     379928 non-null  object\n",
      " 2   SLink     379930 non-null  object\n",
      " 3   Lyric     379854 non-null  object\n",
      " 4   language  365296 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 14.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataframe_entrainement = pd.read_csv('lyrics-data.csv')\n",
    "print(dataframe_entrainement.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALink</th>\n",
       "      <th>SName</th>\n",
       "      <th>SLink</th>\n",
       "      <th>Lyric</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Careless Whisper</td>\n",
       "      <td>/ivete-sangalo/careless-whisper.html</td>\n",
       "      <td>I feel so unsure\\nAs I take your hand and lead...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Could You Be Loved / Citação Musical do Rap: S...</td>\n",
       "      <td>/ivete-sangalo/could-you-be-loved-citacao-musi...</td>\n",
       "      <td>Don't let them fool, ya\\nOr even try to school...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Cruisin' (Part. Saulo)</td>\n",
       "      <td>/ivete-sangalo/cruisin-part-saulo.html</td>\n",
       "      <td>Baby, let's cruise, away from here\\nDon't be c...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Easy</td>\n",
       "      <td>/ivete-sangalo/easy.html</td>\n",
       "      <td>Know it sounds funny\\nBut, I just can't stand ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>For Your Babies (The Voice cover)</td>\n",
       "      <td>/ivete-sangalo/for-your-babies-the-voice-cover...</td>\n",
       "      <td>You've got that look again\\nThe one I hoped I ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Human Nature</td>\n",
       "      <td>/ivete-sangalo/human-nature.html</td>\n",
       "      <td>Looking out\\nAcross the night time\\nThe city w...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Losing Control (Miss Cady feat. Ivete Sangalo)</td>\n",
       "      <td>/ivete-sangalo/losing-control-miss-cady-feat-i...</td>\n",
       "      <td>Uh, yeah.\\nGo, go, go.\\nUh, yeah.\\nUh, Uh, Uhh...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Master Blaster (Jammin')</td>\n",
       "      <td>/ivete-sangalo/master-blaster-jammin.html</td>\n",
       "      <td>Everyone's feeling pretty\\nIt's hotter than Ju...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>More Than Words</td>\n",
       "      <td>/ivete-sangalo/more-than-words.html</td>\n",
       "      <td>Saying 'I Love you'\\nIs not the words I want t...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Natural Collie</td>\n",
       "      <td>/ivete-sangalo/natural-collie.html</td>\n",
       "      <td>Been down in the valley\\nSmoking natural colli...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ALink                                              SName  \\\n",
       "69   /ivete-sangalo/                                   Careless Whisper   \n",
       "86   /ivete-sangalo/  Could You Be Loved / Citação Musical do Rap: S...   \n",
       "88   /ivete-sangalo/                             Cruisin' (Part. Saulo)   \n",
       "111  /ivete-sangalo/                                               Easy   \n",
       "140  /ivete-sangalo/                  For Your Babies (The Voice cover)   \n",
       "147  /ivete-sangalo/                                       Human Nature   \n",
       "159  /ivete-sangalo/     Losing Control (Miss Cady feat. Ivete Sangalo)   \n",
       "168  /ivete-sangalo/                           Master Blaster (Jammin')   \n",
       "187  /ivete-sangalo/                                    More Than Words   \n",
       "207  /ivete-sangalo/                                     Natural Collie   \n",
       "\n",
       "                                                 SLink  \\\n",
       "69                /ivete-sangalo/careless-whisper.html   \n",
       "86   /ivete-sangalo/could-you-be-loved-citacao-musi...   \n",
       "88              /ivete-sangalo/cruisin-part-saulo.html   \n",
       "111                           /ivete-sangalo/easy.html   \n",
       "140  /ivete-sangalo/for-your-babies-the-voice-cover...   \n",
       "147                   /ivete-sangalo/human-nature.html   \n",
       "159  /ivete-sangalo/losing-control-miss-cady-feat-i...   \n",
       "168          /ivete-sangalo/master-blaster-jammin.html   \n",
       "187                /ivete-sangalo/more-than-words.html   \n",
       "207                 /ivete-sangalo/natural-collie.html   \n",
       "\n",
       "                                                 Lyric language  \n",
       "69   I feel so unsure\\nAs I take your hand and lead...       en  \n",
       "86   Don't let them fool, ya\\nOr even try to school...       en  \n",
       "88   Baby, let's cruise, away from here\\nDon't be c...       en  \n",
       "111  Know it sounds funny\\nBut, I just can't stand ...       en  \n",
       "140  You've got that look again\\nThe one I hoped I ...       en  \n",
       "147  Looking out\\nAcross the night time\\nThe city w...       en  \n",
       "159  Uh, yeah.\\nGo, go, go.\\nUh, yeah.\\nUh, Uh, Uhh...       en  \n",
       "168  Everyone's feeling pretty\\nIt's hotter than Ju...       en  \n",
       "187  Saying 'I Love you'\\nIs not the words I want t...       en  \n",
       "207  Been down in the valley\\nSmoking natural colli...       en  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_entrainement[(dataframe_entrainement['language'] == 'en')].iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I feel so unsure\n",
      "As I take your hand and lead you to the dance floor\n",
      "As the music dies, something in your eyes\n",
      "Calls to mind a silver screen\n",
      "And all those sad goodbyes\n",
      "\n",
      "I'm never gonna dance again\n",
      "Guilty feet have got no rhythm\n",
      "Though it's easy to pretend\n",
      "I know you're not a fool\n",
      "\n",
      "Should've known better than to cheat a friend\n",
      "And waste the chance that I've been given\n",
      "So I'm never gonna dance again\n",
      "The way I danced with you\n",
      "\n",
      "Time can never mend\n",
      "The careless whispers of a good friend\n",
      "To the heart and mind\n",
      "Ignorance is kind\n",
      "There's no comfort in the truth\n",
      "Pain is all you'll find\n",
      "\n",
      "I'm never gonna dance again\n",
      "Guilty feet have got no rhythm\n",
      "Though it's easy to pretend\n",
      "I know you're not a fool\n",
      "\n",
      "Should've known better than to cheat a friend\n",
      "And waste this chance that I've been given\n",
      "So I'm never gonna dance again\n",
      "The way I danced with you\n",
      "\n",
      "Never without your love\n",
      "\n",
      "Tonight the music seems so loud\n",
      "I wish that we could lose this crowd\n",
      "Maybe it's better this way\n",
      "We'd hurt each other with the things we'd want to say\n",
      "\n",
      "We could have been so good together\n",
      "We could have lived this dance forever\n",
      "But now who's gonna dance with me?\n",
      "Please stay\n",
      "\n",
      "And I'm never gonna dance again\n",
      "Guilty feet have got no rhythm\n",
      "Though it's easy to pretend\n",
      "I know you're not a fool\n",
      "\n",
      "Should've known better than to cheat a friend\n",
      "And waste the chance that I've been given\n",
      "So I'm never gonna dance again\n",
      "The way I danced with you\n",
      "\n",
      "(Now that you're gone) Now that you're gone\n",
      "(Now that you're gone) What I did's so wrong, so wrong\n",
      "That you had to leave me alone? Don't let them fool, ya\n",
      "Or even try to school, ya! Oh, no!\n",
      "We've got a mind of our own\n",
      "So go to hell if what you? re thinking is not right!\n",
      "Love would never leave us alone\n",
      "A-yin the darkness there must come out to light\n",
      "\n",
      "Could you be loved and be loved?\n",
      "Could you be loved and be loved?\n",
      "\n",
      "Don't let them change ya, oh!\n",
      "Or even rearrange ya! Oh, no!\n",
      "We've got a life to live\n",
      "They say: only, only\n",
      "Only the fittest of the fittest shall survive\n",
      "Stay alive! Oh!\n",
      "\n",
      "Could you be loved and be loved?\n",
      "Could you be loved, wo now! And be loved?\n",
      "\n",
      "Could you be\n",
      "Could you be\n",
      "Could you be loved?\n",
      "\n",
      "Say something!\n",
      "\n",
      "Se ligue na ternura\n",
      "Se ligue no amor\n",
      "Se ligue na ternura\n",
      "Se ligue na cor\n",
      "Se ligue na alegria\n",
      "Se ligue no prazer\n",
      "Se ligue, fique atento, se ligue, fique astral\n",
      "\n",
      "Could you be loved and be loved?\n"
     ]
    }
   ],
   "source": [
    "texte_concatene = dataframe_entrainement[(dataframe_entrainement['language'] == 'en')].iloc[0:2]['Lyric'].str.cat(sep=' ')\n",
    "print(texte_concatene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I feel so unsure\n",
      "As I take your hand and lead you to the dance floor\n",
      "As the music dies something in your eyes\n",
      "Calls to mind a silver screen\n",
      "And all those sad goodbyes\n",
      "\n",
      "Im never gonna dance again\n",
      "Guilty feet have got no rhythm\n",
      "Though its easy to pretend\n",
      "I know youre not a fool\n",
      "\n",
      "Shouldve known better than to cheat a friend\n",
      "And waste the chance that Ive been given\n",
      "So Im never gonna dance again\n",
      "The way I danced with you\n",
      "\n",
      "Time can never mend\n",
      "The careless whispers of a good friend\n",
      "To the heart and mind\n",
      "Ignorance is kind\n",
      "Theres no comfort in the truth\n",
      "Pain is all youll find\n",
      "\n",
      "Im never gonna dance again\n",
      "Guilty feet have got no rhythm\n",
      "Though its easy to pretend\n",
      "I know youre not a fool\n",
      "\n",
      "Shouldve known better than to cheat a friend\n",
      "And waste this chance that Ive been given\n",
      "So Im never gonna dance again\n",
      "The way I danced with you\n",
      "\n",
      "Never without your love\n",
      "\n",
      "Tonight the music seems so loud\n",
      "I wish that we could lose this crowd\n",
      "Maybe its better this way\n",
      "Wed hurt each other with the things wed want to say\n",
      "\n",
      "We could have been so good together\n",
      "We could have lived this dance forever\n",
      "But now whos gonna dance with me\n",
      "Please stay\n",
      "\n",
      "And Im never gonna dance again\n",
      "Guilty feet have got no rhythm\n",
      "Though its easy to pretend\n",
      "I know youre not a fool\n",
      "\n",
      "Shouldve known better than to cheat a friend\n",
      "And waste the chance that Ive been given\n",
      "So Im never gonna dance again\n",
      "The way I danced with you\n",
      "\n",
      "Now that youre gone Now that youre gone\n",
      "Now that youre gone What I dids so wrong so wrong\n",
      "That you had to leave me alone Dont let them fool ya\n",
      "Or even try to school ya Oh no\n",
      "Weve got a mind of our own\n",
      "So go to hell if what you re thinking is not right\n",
      "Love would never leave us alone\n",
      "Ayin the darkness there must come out to light\n",
      "\n",
      "Could you be loved and be loved\n",
      "Could you be loved and be loved\n",
      "\n",
      "Dont let them change ya oh\n",
      "Or even rearrange ya Oh no\n",
      "Weve got a life to live\n",
      "They say only only\n",
      "Only the fittest of the fittest shall survive\n",
      "Stay alive Oh\n",
      "\n",
      "Could you be loved and be loved\n",
      "Could you be loved wo now And be loved\n",
      "\n",
      "Could you be\n",
      "Could you be\n",
      "Could you be loved\n",
      "\n",
      "Say something\n",
      "\n",
      "Se ligue na ternura\n",
      "Se ligue no amor\n",
      "Se ligue na ternura\n",
      "Se ligue na cor\n",
      "Se ligue na alegria\n",
      "Se ligue no prazer\n",
      "Se ligue fique atento se ligue fique astral\n",
      "\n",
      "Could you be loved and be loved\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "texte_concatene=re.sub(r'[^\\w\\s]', '', texte_concatene)\n",
    "print(texte_concatene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'feel', 'so', 'unsure', 'as', 'i', 'take', 'your', 'hand', 'and', 'lead', 'you', 'to', 'the', 'dance', 'floor', 'as', 'the', 'music', 'dies', 'something', 'in', 'your', 'eyes', 'calls', 'to', 'mind', 'a', 'silver', 'screen', 'and', 'all', 'those', 'sad', 'goodbyes', 'im', 'never', 'gonna', 'dance', 'again', 'guilty', 'feet', 'have', 'got', 'no', 'rhythm', 'though', 'its', 'easy', 'to', 'pretend', 'i', 'know', 'youre', 'not', 'a', 'fool', 'shouldve', 'known', 'better', 'than', 'to', 'cheat', 'a', 'friend', 'and', 'waste', 'the', 'chance', 'that', 'ive', 'been', 'given', 'so', 'im', 'never', 'gonna', 'dance', 'again', 'the', 'way', 'i', 'danced', 'with', 'you', 'time', 'can', 'never', 'mend', 'the', 'careless', 'whispers', 'of', 'a', 'good', 'friend', 'to', 'the', 'heart', 'and', 'mind', 'ignorance', 'is', 'kind', 'theres', 'no', 'comfort', 'in', 'the', 'truth', 'pain', 'is', 'all', 'youll', 'find', 'im', 'never', 'gonna', 'dance', 'again', 'guilty', 'feet', 'have', 'got', 'no', 'rhythm', 'though', 'its', 'easy', 'to', 'pretend', 'i', 'know', 'youre', 'not', 'a', 'fool', 'shouldve', 'known', 'better', 'than', 'to', 'cheat', 'a', 'friend', 'and', 'waste', 'this', 'chance', 'that', 'ive', 'been', 'given', 'so', 'im', 'never', 'gonna', 'dance', 'again', 'the', 'way', 'i', 'danced', 'with', 'you', 'never', 'without', 'your', 'love', 'tonight', 'the', 'music', 'seems', 'so', 'loud', 'i', 'wish', 'that', 'we', 'could', 'lose', 'this', 'crowd', 'maybe', 'its', 'better', 'this', 'way', 'wed', 'hurt', 'each', 'other', 'with', 'the', 'things', 'wed', 'want', 'to', 'say', 'we', 'could', 'have', 'been', 'so', 'good', 'together', 'we', 'could', 'have', 'lived', 'this', 'dance', 'forever', 'but', 'now', 'whos', 'gonna', 'dance', 'with', 'me', 'please', 'stay', 'and', 'im', 'never', 'gonna', 'dance', 'again', 'guilty', 'feet', 'have', 'got', 'no', 'rhythm', 'though', 'its', 'easy', 'to', 'pretend', 'i', 'know', 'youre', 'not', 'a', 'fool', 'shouldve', 'known', 'better', 'than', 'to', 'cheat', 'a', 'friend', 'and', 'waste', 'the', 'chance', 'that', 'ive', 'been', 'given', 'so', 'im', 'never', 'gonna', 'dance', 'again', 'the', 'way', 'i', 'danced', 'with', 'you', 'now', 'that', 'youre', 'gone', 'now', 'that', 'youre', 'gone', 'now', 'that', 'youre', 'gone', 'what', 'i', 'dids', 'so', 'wrong', 'so', 'wrong', 'that', 'you', 'had', 'to', 'leave', 'me', 'alone', 'dont', 'let', 'them', 'fool', 'ya', 'or', 'even', 'try', 'to', 'school', 'ya', 'oh', 'no', 'weve', 'got', 'a', 'mind', 'of', 'our', 'own', 'so', 'go', 'to', 'hell', 'if', 'what', 'you', 're', 'thinking', 'is', 'not', 'right', 'love', 'would', 'never', 'leave', 'us', 'alone', 'ayin', 'the', 'darkness', 'there', 'must', 'come', 'out', 'to', 'light', 'could', 'you', 'be', 'loved', 'and', 'be', 'loved', 'could', 'you', 'be', 'loved', 'and', 'be', 'loved', 'dont', 'let', 'them', 'change', 'ya', 'oh', 'or', 'even', 'rearrange', 'ya', 'oh', 'no', 'weve', 'got', 'a', 'life', 'to', 'live', 'they', 'say', 'only', 'only', 'only', 'the', 'fittest', 'of', 'the', 'fittest', 'shall', 'survive', 'stay', 'alive', 'oh', 'could', 'you', 'be', 'loved', 'and', 'be', 'loved', 'could', 'you', 'be', 'loved', 'wo', 'now', 'and', 'be', 'loved', 'could', 'you', 'be', 'could', 'you', 'be', 'could', 'you', 'be', 'loved', 'say', 'something', 'se', 'ligue', 'na', 'ternura', 'se', 'ligue', 'no', 'amor', 'se', 'ligue', 'na', 'ternura', 'se', 'ligue', 'na', 'cor', 'se', 'ligue', 'na', 'alegria', 'se', 'ligue', 'no', 'prazer', 'se', 'ligue', 'fique', 'atento', 'se', 'ligue', 'fique', 'astral', 'could', 'you', 'be', 'loved', 'and', 'be', 'loved']\n"
     ]
    }
   ],
   "source": [
    "print(texte_concatene.lower().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'feel',\n",
       " 'so',\n",
       " 'unsure',\n",
       " 'as',\n",
       " 'i',\n",
       " 'take',\n",
       " 'your',\n",
       " 'hand',\n",
       " 'and',\n",
       " 'lead',\n",
       " 'you',\n",
       " 'to',\n",
       " 'the',\n",
       " 'dance',\n",
       " 'floor',\n",
       " 'as',\n",
       " 'the',\n",
       " 'music',\n",
       " 'dies',\n",
       " 'something',\n",
       " 'in',\n",
       " 'your',\n",
       " 'eyes',\n",
       " 'calls',\n",
       " 'to',\n",
       " 'mind',\n",
       " 'a',\n",
       " 'silver',\n",
       " 'screen',\n",
       " 'and',\n",
       " 'all',\n",
       " 'those',\n",
       " 'sad',\n",
       " 'goodbyes',\n",
       " 'im',\n",
       " 'never',\n",
       " 'gonna',\n",
       " 'dance',\n",
       " 'again',\n",
       " 'guilty',\n",
       " 'feet',\n",
       " 'have',\n",
       " 'got',\n",
       " 'no',\n",
       " 'rhythm',\n",
       " 'though',\n",
       " 'its',\n",
       " 'easy',\n",
       " 'to',\n",
       " 'pretend',\n",
       " 'i',\n",
       " 'know',\n",
       " 'youre',\n",
       " 'not',\n",
       " 'a',\n",
       " 'fool',\n",
       " 'shouldve',\n",
       " 'known',\n",
       " 'better',\n",
       " 'than',\n",
       " 'to',\n",
       " 'cheat',\n",
       " 'a',\n",
       " 'friend',\n",
       " 'and',\n",
       " 'waste',\n",
       " 'the',\n",
       " 'chance',\n",
       " 'that',\n",
       " 'ive',\n",
       " 'been',\n",
       " 'given',\n",
       " 'so',\n",
       " 'im',\n",
       " 'never',\n",
       " 'gonna',\n",
       " 'dance',\n",
       " 'again',\n",
       " 'the',\n",
       " 'way',\n",
       " 'i',\n",
       " 'danced',\n",
       " 'with',\n",
       " 'you',\n",
       " 'time',\n",
       " 'can',\n",
       " 'never',\n",
       " 'mend',\n",
       " 'the',\n",
       " 'careless',\n",
       " 'whispers',\n",
       " 'of',\n",
       " 'a',\n",
       " 'good',\n",
       " 'friend',\n",
       " 'to',\n",
       " 'the',\n",
       " 'heart',\n",
       " 'and',\n",
       " 'mind',\n",
       " 'ignorance',\n",
       " 'is',\n",
       " 'kind',\n",
       " 'theres',\n",
       " 'no',\n",
       " 'comfort',\n",
       " 'in',\n",
       " 'the',\n",
       " 'truth',\n",
       " 'pain',\n",
       " 'is',\n",
       " 'all',\n",
       " 'youll',\n",
       " 'find',\n",
       " 'im',\n",
       " 'never',\n",
       " 'gonna',\n",
       " 'dance',\n",
       " 'again',\n",
       " 'guilty',\n",
       " 'feet',\n",
       " 'have',\n",
       " 'got',\n",
       " 'no',\n",
       " 'rhythm',\n",
       " 'though',\n",
       " 'its',\n",
       " 'easy',\n",
       " 'to',\n",
       " 'pretend',\n",
       " 'i',\n",
       " 'know',\n",
       " 'youre',\n",
       " 'not',\n",
       " 'a',\n",
       " 'fool',\n",
       " 'shouldve',\n",
       " 'known',\n",
       " 'better',\n",
       " 'than',\n",
       " 'to',\n",
       " 'cheat',\n",
       " 'a',\n",
       " 'friend',\n",
       " 'and',\n",
       " 'waste',\n",
       " 'this',\n",
       " 'chance',\n",
       " 'that',\n",
       " 'ive',\n",
       " 'been',\n",
       " 'given',\n",
       " 'so',\n",
       " 'im',\n",
       " 'never',\n",
       " 'gonna',\n",
       " 'dance',\n",
       " 'again',\n",
       " 'the',\n",
       " 'way',\n",
       " 'i',\n",
       " 'danced',\n",
       " 'with',\n",
       " 'you',\n",
       " 'never',\n",
       " 'without',\n",
       " 'your',\n",
       " 'love',\n",
       " 'tonight',\n",
       " 'the',\n",
       " 'music',\n",
       " 'seems',\n",
       " 'so',\n",
       " 'loud',\n",
       " 'i',\n",
       " 'wish',\n",
       " 'that',\n",
       " 'we',\n",
       " 'could',\n",
       " 'lose',\n",
       " 'this',\n",
       " 'crowd',\n",
       " 'maybe',\n",
       " 'its',\n",
       " 'better',\n",
       " 'this',\n",
       " 'way',\n",
       " 'wed',\n",
       " 'hurt',\n",
       " 'each',\n",
       " 'other',\n",
       " 'with',\n",
       " 'the',\n",
       " 'things',\n",
       " 'wed',\n",
       " 'want',\n",
       " 'to',\n",
       " 'say',\n",
       " 'we',\n",
       " 'could',\n",
       " 'have',\n",
       " 'been',\n",
       " 'so',\n",
       " 'good',\n",
       " 'together',\n",
       " 'we',\n",
       " 'could',\n",
       " 'have',\n",
       " 'lived',\n",
       " 'this',\n",
       " 'dance',\n",
       " 'forever',\n",
       " 'but',\n",
       " 'now',\n",
       " 'whos',\n",
       " 'gonna',\n",
       " 'dance',\n",
       " 'with',\n",
       " 'me',\n",
       " 'please',\n",
       " 'stay',\n",
       " 'and',\n",
       " 'im',\n",
       " 'never',\n",
       " 'gonna',\n",
       " 'dance',\n",
       " 'again',\n",
       " 'guilty',\n",
       " 'feet',\n",
       " 'have',\n",
       " 'got',\n",
       " 'no',\n",
       " 'rhythm',\n",
       " 'though',\n",
       " 'its',\n",
       " 'easy',\n",
       " 'to',\n",
       " 'pretend',\n",
       " 'i',\n",
       " 'know',\n",
       " 'youre',\n",
       " 'not',\n",
       " 'a',\n",
       " 'fool',\n",
       " 'shouldve',\n",
       " 'known',\n",
       " 'better',\n",
       " 'than',\n",
       " 'to',\n",
       " 'cheat',\n",
       " 'a',\n",
       " 'friend',\n",
       " 'and',\n",
       " 'waste',\n",
       " 'the',\n",
       " 'chance',\n",
       " 'that',\n",
       " 'ive',\n",
       " 'been',\n",
       " 'given',\n",
       " 'so',\n",
       " 'im',\n",
       " 'never',\n",
       " 'gonna',\n",
       " 'dance',\n",
       " 'again',\n",
       " 'the',\n",
       " 'way',\n",
       " 'i',\n",
       " 'danced',\n",
       " 'with',\n",
       " 'you',\n",
       " 'now',\n",
       " 'that',\n",
       " 'youre',\n",
       " 'gone',\n",
       " 'now',\n",
       " 'that',\n",
       " 'youre',\n",
       " 'gone',\n",
       " 'now',\n",
       " 'that',\n",
       " 'youre',\n",
       " 'gone',\n",
       " 'what',\n",
       " 'i',\n",
       " 'dids',\n",
       " 'so',\n",
       " 'wrong',\n",
       " 'so',\n",
       " 'wrong',\n",
       " 'that',\n",
       " 'you',\n",
       " 'had',\n",
       " 'to',\n",
       " 'leave',\n",
       " 'me',\n",
       " 'alone',\n",
       " 'dont',\n",
       " 'let',\n",
       " 'them',\n",
       " 'fool',\n",
       " 'ya',\n",
       " 'or',\n",
       " 'even',\n",
       " 'try',\n",
       " 'to',\n",
       " 'school',\n",
       " 'ya',\n",
       " 'oh',\n",
       " 'no',\n",
       " 'weve',\n",
       " 'got',\n",
       " 'a',\n",
       " 'mind',\n",
       " 'of',\n",
       " 'our',\n",
       " 'own',\n",
       " 'so',\n",
       " 'go',\n",
       " 'to',\n",
       " 'hell',\n",
       " 'if',\n",
       " 'what',\n",
       " 'you',\n",
       " 're',\n",
       " 'thinking',\n",
       " 'is',\n",
       " 'not',\n",
       " 'right',\n",
       " 'love',\n",
       " 'would',\n",
       " 'never',\n",
       " 'leave',\n",
       " 'us',\n",
       " 'alone',\n",
       " 'ayin',\n",
       " 'the',\n",
       " 'darkness',\n",
       " 'there',\n",
       " 'must',\n",
       " 'come',\n",
       " 'out',\n",
       " 'to',\n",
       " 'light',\n",
       " 'could',\n",
       " 'you',\n",
       " 'be',\n",
       " 'loved',\n",
       " 'and',\n",
       " 'be',\n",
       " 'loved',\n",
       " 'could',\n",
       " 'you',\n",
       " 'be',\n",
       " 'loved',\n",
       " 'and',\n",
       " 'be',\n",
       " 'loved',\n",
       " 'dont',\n",
       " 'let',\n",
       " 'them',\n",
       " 'change',\n",
       " 'ya',\n",
       " 'oh',\n",
       " 'or',\n",
       " 'even',\n",
       " 'rearrange',\n",
       " 'ya',\n",
       " 'oh',\n",
       " 'no',\n",
       " 'weve',\n",
       " 'got',\n",
       " 'a',\n",
       " 'life',\n",
       " 'to',\n",
       " 'live',\n",
       " 'they',\n",
       " 'say',\n",
       " 'only',\n",
       " 'only',\n",
       " 'only',\n",
       " 'the',\n",
       " 'fittest',\n",
       " 'of',\n",
       " 'the',\n",
       " 'fittest',\n",
       " 'shall',\n",
       " 'survive',\n",
       " 'stay',\n",
       " 'alive',\n",
       " 'oh',\n",
       " 'could',\n",
       " 'you',\n",
       " 'be',\n",
       " 'loved',\n",
       " 'and',\n",
       " 'be',\n",
       " 'loved',\n",
       " 'could',\n",
       " 'you',\n",
       " 'be',\n",
       " 'loved',\n",
       " 'wo',\n",
       " 'now',\n",
       " 'and',\n",
       " 'be',\n",
       " 'loved',\n",
       " 'could',\n",
       " 'you',\n",
       " 'be',\n",
       " 'could',\n",
       " 'you',\n",
       " 'be',\n",
       " 'could',\n",
       " 'you',\n",
       " 'be',\n",
       " 'loved',\n",
       " 'say',\n",
       " 'something',\n",
       " 'se',\n",
       " 'ligue',\n",
       " 'na',\n",
       " 'ternura',\n",
       " 'se',\n",
       " 'ligue',\n",
       " 'no',\n",
       " 'amor',\n",
       " 'se',\n",
       " 'ligue',\n",
       " 'na',\n",
       " 'ternura',\n",
       " 'se',\n",
       " 'ligue',\n",
       " 'na',\n",
       " 'cor',\n",
       " 'se',\n",
       " 'ligue',\n",
       " 'na',\n",
       " 'alegria',\n",
       " 'se',\n",
       " 'ligue',\n",
       " 'no',\n",
       " 'prazer',\n",
       " 'se',\n",
       " 'ligue',\n",
       " 'fique',\n",
       " 'atento',\n",
       " 'se',\n",
       " 'ligue',\n",
       " 'fique',\n",
       " 'astral',\n",
       " 'could',\n",
       " 'you',\n",
       " 'be',\n",
       " 'loved',\n",
       " 'and',\n",
       " 'be',\n",
       " 'loved']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texte_concatene = dataframe_entrainement[(dataframe_entrainement['language'] == 'en')].iloc[0:2]['Lyric'].str.cat(sep=' ')\n",
    "re.sub(r'[^\\w\\s]', '', texte_concatene).lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_paroles = DatasetParolesLyricsDataEn(nombre_textes = nombre_textes, taille_sequence=taille_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([   1,   67,   20, 1610,  184,    1,   74,   14]),\n",
       " tensor([  67,   20, 1610,  184,    1,   74,   14,  318]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_paroles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
