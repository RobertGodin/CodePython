{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrainement sur  cpu\n",
      "-------- > epoch 0 lot 0 :  coût = 8.440169334411621\n",
      "Temps écoulé : 0m 0s\n",
      "-------- > epoch 0 lot 100 :  coût = 7.938192367553711\n",
      "Temps écoulé : 0m 7s\n",
      "-------- > epoch 0 lot 200 :  coût = 6.283443450927734\n",
      "Temps écoulé : 0m 13s\n",
      "-------- > epoch 0 lot 300 :  coût = 7.379206657409668\n",
      "Temps écoulé : 0m 20s\n",
      "-------- > epoch 0 lot 400 :  coût = 7.359987735748291\n",
      "Temps écoulé : 0m 26s\n",
      "-------- > epoch 0 lot 500 :  coût = 8.55333423614502\n",
      "Temps écoulé : 0m 33s\n",
      "-------- > epoch 0 lot 600 :  coût = 7.464532375335693\n",
      "Temps écoulé : 0m 40s\n",
      "-------- > epoch 1 lot 0 :  coût = 5.841742515563965\n",
      "Temps écoulé : 0m 40s\n",
      "-------- > epoch 1 lot 100 :  coût = 6.307178020477295\n",
      "Temps écoulé : 0m 46s\n",
      "-------- > epoch 1 lot 200 :  coût = 4.941400051116943\n",
      "Temps écoulé : 0m 53s\n",
      "-------- > epoch 1 lot 300 :  coût = 6.401119232177734\n",
      "Temps écoulé : 0m 60s\n",
      "-------- > epoch 1 lot 400 :  coût = 6.042225360870361\n",
      "Temps écoulé : 1m 6s\n",
      "-------- > epoch 1 lot 500 :  coût = 7.430727005004883\n",
      "Temps écoulé : 1m 13s\n",
      "-------- > epoch 1 lot 600 :  coût = 5.523373603820801\n",
      "Temps écoulé : 1m 19s\n",
      "-------- > epoch 2 lot 0 :  coût = 4.109131336212158\n",
      "Temps écoulé : 1m 20s\n",
      "-------- > epoch 2 lot 100 :  coût = 5.063242435455322\n",
      "Temps écoulé : 1m 26s\n",
      "-------- > epoch 2 lot 200 :  coût = 3.5803542137145996\n",
      "Temps écoulé : 1m 33s\n",
      "-------- > epoch 2 lot 300 :  coût = 5.6082844734191895\n",
      "Temps écoulé : 1m 39s\n",
      "-------- > epoch 2 lot 400 :  coût = 5.1644415855407715\n",
      "Temps écoulé : 1m 46s\n",
      "-------- > epoch 2 lot 500 :  coût = 6.248290538787842\n",
      "Temps écoulé : 1m 52s\n",
      "-------- > epoch 2 lot 600 :  coût = 3.416558265686035\n",
      "Temps écoulé : 1m 59s\n",
      "-------- > epoch 3 lot 0 :  coût = 2.7074203491210938\n",
      "Temps écoulé : 1m 59s\n",
      "-------- > epoch 3 lot 100 :  coût = 3.6720058917999268\n",
      "Temps écoulé : 2m 5s\n",
      "-------- > epoch 3 lot 200 :  coût = 2.5674407482147217\n",
      "Temps écoulé : 2m 12s\n",
      "-------- > epoch 3 lot 300 :  coût = 4.908510208129883\n",
      "Temps écoulé : 2m 18s\n",
      "-------- > epoch 3 lot 400 :  coût = 4.371950626373291\n",
      "Temps écoulé : 2m 25s\n",
      "-------- > epoch 3 lot 500 :  coût = 5.013559818267822\n",
      "Temps écoulé : 2m 31s\n",
      "-------- > epoch 3 lot 600 :  coût = 2.2750349044799805\n",
      "Temps écoulé : 2m 38s\n",
      "-------- > epoch 4 lot 0 :  coût = 1.7823070287704468\n",
      "Temps écoulé : 2m 38s\n",
      "-------- > epoch 4 lot 100 :  coût = 2.5020360946655273\n",
      "Temps écoulé : 2m 44s\n",
      "-------- > epoch 4 lot 200 :  coût = 1.8807250261306763\n",
      "Temps écoulé : 2m 51s\n",
      "-------- > epoch 4 lot 300 :  coût = 4.289813041687012\n",
      "Temps écoulé : 2m 57s\n",
      "-------- > epoch 4 lot 400 :  coût = 3.6712067127227783\n",
      "Temps écoulé : 3m 3s\n",
      "-------- > epoch 4 lot 500 :  coût = 3.829683303833008\n",
      "Temps écoulé : 3m 10s\n",
      "-------- > epoch 4 lot 600 :  coût = 1.6618553400039673\n",
      "Temps écoulé : 3m 16s\n",
      "['There', 'was', 'born', 'for', 'low..', 'grown.', 'the', 'any', 'misty', 'These', 'are', 'growing', 'hazy.', \"'cos\", 'and', 'nowhere', 'lungs', 'and', 'his', 'claws', 'on', 'bread']\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Réseau de neurones récurrent, modèle de langue par mot, pour paroles de chansons\n",
    "Version avec couche vectorisation de mots et GRU \n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(0) # Pour résultats reproductibles\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "taille_sequence = 8\n",
    "\n",
    "# Déterminer si un GPU est disponible\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Entrainement sur ',device)\n",
    "\n",
    "class DatasetParoles(torch.utils.data.Dataset):\n",
    "    \"\"\" Créer un Dataset avec les paroles de la colonne Lyric du fichier \n",
    "    https://www.kaggle.com/neisse/scrapped-lyrics-from-6-genres?select=lyrics-data.csv\n",
    "    taille_sequence : taille d'une séquence de mots pour le modèle de langue\n",
    "    Le texte est découpé en séquences de la taille taille_sequence\n",
    "    \"\"\"\n",
    "    def __init__(self,taille_sequence=4):\n",
    "        self.taille_sequence = taille_sequence\n",
    "        self.mots = self.charger_mots()\n",
    "        self.mots_uniques = self.chercher_mots_uniques()\n",
    "\n",
    "        self.index_a_mot = {index: mot for index, mot in enumerate(self.mots_uniques)}\n",
    "        self.mot_a_index = {mot: index for index, mot in enumerate(self.mots_uniques)}\n",
    "\n",
    "        self.mots_indexes = [self.mot_a_index[w] for w in self.mots]\n",
    "\n",
    "    def charger_mots(self):\n",
    "        dataframe_entrainement = pd.read_csv('lyrics-data.csv')\n",
    "        texte_concatene = dataframe_entrainement.iloc[0:100]['Lyric'].str.cat(sep=' ')\n",
    "        return texte_concatene.split(' ')\n",
    "\n",
    "    def chercher_mots_uniques(self):\n",
    "        frequence_mot = Counter(self.mots)\n",
    "        return sorted(frequence_mot, key=frequence_mot.get, reverse=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mots_indexes) - self.taille_sequence\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            torch.tensor(self.mots_indexes[index:index+self.taille_sequence]),\n",
    "            torch.tensor(self.mots_indexes[index+1:index+self.taille_sequence+1]),\n",
    "        )\n",
    "    \n",
    "class Modele(nn.Module):\n",
    "    \"\"\"Modèle de RNR avec une couche vectorisation, suivie d'une couche GRU et d'une couche linéaire\"\"\"\n",
    "    def __init__(self, ds_paroles):\n",
    "        super(Modele, self).__init__()\n",
    "        self.taille_H_RNN = 128\n",
    "        self.taille_vectorisation_mots = 64\n",
    "        self.nombre_couches_RNR = 1\n",
    "\n",
    "        taille_vocabulaire = len(ds_paroles.mots_uniques)\n",
    "        self.vectorisation_mots = nn.Embedding(num_embeddings=taille_vocabulaire,\n",
    "            embedding_dim=self.taille_vectorisation_mots)\n",
    "        self.gru = nn.GRU(input_size=self.taille_vectorisation_mots,hidden_size=self.taille_H_RNN,\n",
    "            num_layers=self.nombre_couches_RNR,batch_first=True)\n",
    "        self.dense_linaire = nn.Linear(self.taille_H_RNN, taille_vocabulaire)\n",
    "\n",
    "    def forward(self, lot_X, etat_0):\n",
    "        vectorisation = self.vectorisation_mots(lot_X)\n",
    "        lot_Ht, etat = self.gru(vectorisation, etat_0)\n",
    "        lot_Yt = self.dense_linaire(lot_Ht)\n",
    "        return lot_Yt, etat\n",
    "\n",
    "    def initializer_etat(self, taille_sequence):\n",
    "        return (torch.zeros(self.nombre_couches_RNR, taille_sequence, self.taille_H_RNN))\n",
    "\n",
    "ds_paroles = DatasetParoles(taille_sequence=taille_sequence)\n",
    "modele = Modele(ds_paroles)\n",
    "# Placer le modèle en mode GPU si possible\n",
    "modele = modele.to(device)\n",
    "    \n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "def entrainer_RNR(ds_paroles, modele, taille_lot=32, epochs=10, taille_sequence=6):\n",
    "    debut = time.time()\n",
    "    modele.train()\n",
    "    dl_paroles = DataLoader(ds_paroles,batch_size=taille_lot)\n",
    "\n",
    "    fonction_cout = nn.CrossEntropyLoss()\n",
    "    optimizeur = optim.Adam(modele.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        for lot, (lot_X, lot_Y) in enumerate(dl_paroles):\n",
    "            lot_X = lot_X.to(device)\n",
    "            lot_Y = lot_Y.to(device)\n",
    "            etat = modele.initializer_etat(lot_X.shape[0])\n",
    "            etat = etat.to(device)\n",
    "            optimizeur.zero_grad()\n",
    "            \n",
    "            lot_Y_predictions, etat = modele(lot_X, etat)\n",
    "            cout = fonction_cout(lot_Y_predictions.transpose(1, 2), lot_Y)\n",
    "            \n",
    "            cout.backward()\n",
    "            optimizeur.step()\n",
    "            if lot%100 == 0:\n",
    "                print(f'-------- > epoch {epoch} lot {lot} :  coût = {cout.item()}')\n",
    "                temps_ecoule = time.time() - debut\n",
    "                print('Temps écoulé : {:.0f}m {:.0f}s'.format(temps_ecoule // 60, temps_ecoule % 60))\n",
    "\n",
    "\n",
    "def predire(ds, modele, debut_texte, nb_mots=20):\n",
    "    \"\"\" Prédire une suite de nb_mots à partir de debut_texte selon le modele\"\"\"\n",
    "    mots = debut_texte.split(' ')\n",
    "    modele.eval()\n",
    "    etat = modele.initializer_etat(1)\n",
    "    etat = etat.to(device)\n",
    "    for i in range(0, nb_mots):\n",
    "        lot_X = torch.tensor([[ds.mot_a_index[m] for m in mots[i:]]])\n",
    "        lot_X = lot_X.to(device)\n",
    "        lot_Y_predictions, etat = modele(lot_X, etat)\n",
    "        dernier_mot_Yt = lot_Y_predictions[0][-1]\n",
    "        probs_dernier_mot = torch.nn.functional.softmax(dernier_mot_Yt, dim=0).data\n",
    "        #index_mot_choisi = torch.max(probs_dernier_mot, dim=0)[1].item()\n",
    "        index_mot_choisi = torch.multinomial(probs_dernier_mot, 1)[0].item()\n",
    "        mots.append(ds.index_a_mot[index_mot_choisi])\n",
    "    return mots\n",
    "\n",
    "entrainer_RNR(ds_paroles, modele, taille_lot=32, epochs=5, taille_sequence=taille_sequence)\n",
    "print(predire(ds_paroles, modele, debut_texte='There was'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
